WARNING:tensorflow:From /home/projects/ku_00062/envs/marvl/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/marvl/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /home/projects/ku_00062/envs/marvl/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.

07/28/2021 05:43:05 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False
07/28/2021 05:43:07 - INFO - volta.task_utils -   Loading NLVR2 Dataset with batch size 32
07/28/2021 05:43:07 - INFO - volta.datasets.nlvr2_dataset -   Loading from /home/projects/ku_00062/data/nlvr2/annotations/cache/NLVR2_train_roberta_80.pkl
07/28/2021 05:43:36 - INFO - volta.datasets.nlvr2_dataset -   Loading from /home/projects/ku_00062/data/nlvr2/annotations/cache/NLVR2_dev_roberta_80.pkl
07/28/2021 05:43:38 - INFO - volta.train_utils -   logging file at: /home/projects/ku_00062/logs/mlvr/ctrl_xuniter_base/NLVR2_ctrl_xuniter_base
07/28/2021 05:43:38 - INFO - volta.utils -   loading weights file /home/projects/ku_00062/checkpoints/mlvr/ctrl_xuniter/conceptual_captions_wikipedia03/ctrl_xuniter_base/pytorch_model_9.bin
07/28/2021 05:43:48 - INFO - volta.utils -   
07/28/2021 05:43:48 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK12.logit_fc.0.weight', 'clfs_dict.TASK12.logit_fc.0.bias', 'clfs_dict.TASK12.logit_fc.2.weight', 'clfs_dict.TASK12.logit_fc.2.bias', 'clfs_dict.TASK12.logit_fc.3.weight', 'clfs_dict.TASK12.logit_fc.3.bias']
07/28/2021 05:43:48 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
07/28/2021 05:43:59 - INFO - __main__ -   ** ** * Saving model * ** ** 
07/28/2021 05:44:05 - INFO - __main__ -   >> Parameters:
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |Name                                                       |Dtype            |Shape            |#Params      |Trainable|
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.word_embeddings.weight                     |torch.float32    |(250002, 768)    |192001536    |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.position_embeddings.weight                 |torch.float32    |(514, 768)       |394752       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.token_type_embeddings.weight               |torch.float32    |(1, 768)         |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.LayerNorm.weight                           |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.LayerNorm.bias                             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)      |1572864      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.image_embeddings.bias                      |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)         |3840         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.image_location_embeddings.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.image_token_type_embeddings.weight         |torch.float32    |(1, 768)         |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.image_layer_norm.weight                    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.image_layer_norm.bias                      |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.weight           |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.image_location_layer_norm.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.weight                         |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.embeddings.v_LayerNorm.bias                           |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.0.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.2.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.4.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.6.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.query.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.weight             |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.key.bias               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.weight           |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_self.value.bias             |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.weight         |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.dense.bias           |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.weight     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.8.attention_output.LayerNorm.bias       |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.10.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.12.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.13.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.13.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.13.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.14.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.15.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.15.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.15.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.16.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.17.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.17.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.17.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.18.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.19.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.19.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.19.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.20.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.21.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.21.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.21.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.query.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.weight            |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.key.bias              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.weight          |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_self.value.bias            |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.weight        |torch.float32    |(768, 768)       |589824       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.dense.bias          |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.weight    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.22.attention_output.LayerNorm.bias      |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.weight            |torch.float32    |(3072, 768)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.23.intermediate.dense.bias              |torch.float32    |(3072,)          |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.weight                  |torch.float32    |(768, 3072)      |2359296      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.23.output.dense.bias                    |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.weight              |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.encoder.layer.23.output.LayerNorm.bias                |torch.float32    |(768,)           |768          |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.t_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.t_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.v_pooler.dense.weight                                 |torch.float32    |(1024, 768)      |786432       |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |bert.v_pooler.dense.bias                                   |torch.float32    |(1024,)          |1024         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.weight                         |torch.float32    |(1536, 2048)     |3145728      |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.0.bias                           |torch.float32    |(1536,)          |1536         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.weight                         |torch.float32    |(1536,)          |1536         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.2.bias                           |torch.float32    |(1536,)          |1536         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.weight                         |torch.float32    |(2, 1536)        |3072         |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   |clfs_dict.TASK12.logit_fc.3.bias                           |torch.float32    |(2,)             |2            |True    |
07/28/2021 05:44:05 - INFO - __main__ -   ------------------------------------------------------------------------------------------------------------------------
07/28/2021 05:44:05 - INFO - __main__ -   >> # TrainableParams:       	283.76	M
07/28/2021 05:44:05 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
07/28/2021 05:44:05 - INFO - __main__ -   >> # TotalParams:           	283.76	M

Epoch:   0%|          | 0/20 [00:00<?, ?it/s]07/28/2021 05:44:59 - INFO - volta.train_utils -   [NLVR2]: iter 40 Ep: 0.01 loss 0.192 score 0.252 lr 1.94444e-08 
07/28/2021 05:45:38 - INFO - volta.train_utils -   [NLVR2]: iter 80 Ep: 0.03 loss 0.184 score 0.256 lr 5.64815e-08 
07/28/2021 05:46:12 - INFO - volta.train_utils -   [NLVR2]: iter 120 Ep: 0.04 loss 0.191 score 0.243 lr 9.35185e-08 
07/28/2021 05:46:51 - INFO - volta.train_utils -   [NLVR2]: iter 160 Ep: 0.06 loss 0.186 score 0.254 lr 1.30556e-07 
07/28/2021 05:47:24 - INFO - volta.train_utils -   [NLVR2]: iter 200 Ep: 0.07 loss 0.189 score 0.236 lr 1.67593e-07 
07/28/2021 05:48:04 - INFO - volta.train_utils -   [NLVR2]: iter 240 Ep: 0.09 loss 0.186 score 0.252 lr 2.0463e-07 
07/28/2021 05:48:37 - INFO - volta.train_utils -   [NLVR2]: iter 280 Ep: 0.10 loss 0.185 score 0.252 lr 2.41667e-07 
07/28/2021 05:49:13 - INFO - volta.train_utils -   [NLVR2]: iter 320 Ep: 0.12 loss 0.185 score 0.247 lr 2.78704e-07 
07/28/2021 05:49:43 - INFO - volta.train_utils -   [NLVR2]: iter 360 Ep: 0.13 loss 0.183 score 0.251 lr 3.15741e-07 
07/28/2021 05:50:30 - INFO - volta.train_utils -   [NLVR2]: iter 400 Ep: 0.15 loss 0.182 score 0.253 lr 3.52778e-07 
07/28/2021 05:51:07 - INFO - volta.train_utils -   [NLVR2]: iter 440 Ep: 0.16 loss 0.184 score 0.254 lr 3.89815e-07 
07/28/2021 05:51:35 - INFO - volta.train_utils -   [NLVR2]: iter 480 Ep: 0.18 loss 0.184 score 0.257 lr 4.26852e-07 
07/28/2021 05:52:11 - INFO - volta.train_utils -   [NLVR2]: iter 520 Ep: 0.19 loss 0.182 score 0.251 lr 4.63889e-07 
07/28/2021 05:52:42 - INFO - volta.train_utils -   [NLVR2]: iter 560 Ep: 0.21 loss 0.184 score 0.246 lr 5.00926e-07 
07/28/2021 05:53:16 - INFO - volta.train_utils -   [NLVR2]: iter 600 Ep: 0.22 loss 0.184 score 0.235 lr 5.37963e-07 
07/28/2021 05:53:46 - INFO - volta.train_utils -   [NLVR2]: iter 640 Ep: 0.24 loss 0.181 score 0.255 lr 5.75e-07 
07/28/2021 05:54:22 - INFO - volta.train_utils -   [NLVR2]: iter 680 Ep: 0.25 loss 0.182 score 0.253 lr 6.12037e-07 
07/28/2021 05:54:51 - INFO - volta.train_utils -   [NLVR2]: iter 720 Ep: 0.27 loss 0.179 score 0.256 lr 6.49074e-07 
07/28/2021 05:55:25 - INFO - volta.train_utils -   [NLVR2]: iter 760 Ep: 0.28 loss 0.178 score 0.261 lr 6.86111e-07 
07/28/2021 05:56:07 - INFO - volta.train_utils -   [NLVR2]: iter 800 Ep: 0.30 loss 0.181 score 0.248 lr 7.23148e-07 
07/28/2021 05:56:40 - INFO - volta.train_utils -   [NLVR2]: iter 840 Ep: 0.31 loss 0.179 score 0.259 lr 7.60185e-07 
07/28/2021 05:57:08 - INFO - volta.train_utils -   [NLVR2]: iter 880 Ep: 0.33 loss 0.177 score 0.270 lr 7.97222e-07 
07/28/2021 05:57:41 - INFO - volta.train_utils -   [NLVR2]: iter 920 Ep: 0.34 loss 0.180 score 0.246 lr 8.34259e-07 
07/28/2021 05:58:07 - INFO - volta.train_utils -   [NLVR2]: iter 960 Ep: 0.36 loss 0.181 score 0.257 lr 8.71296e-07 
07/28/2021 05:58:38 - INFO - volta.train_utils -   [NLVR2]: iter 1000 Ep: 0.37 loss 0.181 score 0.246 lr 9.08333e-07 
07/28/2021 05:59:06 - INFO - volta.train_utils -   [NLVR2]: iter 1040 Ep: 0.39 loss 0.177 score 0.268 lr 9.4537e-07 
07/28/2021 05:59:37 - INFO - volta.train_utils -   [NLVR2]: iter 1080 Ep: 0.40 loss 0.180 score 0.245 lr 9.82407e-07 
07/28/2021 06:00:14 - INFO - volta.train_utils -   [NLVR2]: iter 1120 Ep: 0.41 loss 0.176 score 0.262 lr 1.01944e-06 
07/28/2021 06:00:45 - INFO - volta.train_utils -   [NLVR2]: iter 1160 Ep: 0.43 loss 0.183 score 0.252 lr 1.05648e-06 
07/28/2021 06:01:12 - INFO - volta.train_utils -   [NLVR2]: iter 1200 Ep: 0.44 loss 0.177 score 0.259 lr 1.09352e-06 
07/28/2021 06:01:45 - INFO - volta.train_utils -   [NLVR2]: iter 1240 Ep: 0.46 loss 0.177 score 0.270 lr 1.13056e-06 
07/28/2021 06:02:11 - INFO - volta.train_utils -   [NLVR2]: iter 1280 Ep: 0.47 loss 0.178 score 0.263 lr 1.16759e-06 
07/28/2021 06:02:40 - INFO - volta.train_utils -   [NLVR2]: iter 1320 Ep: 0.49 loss 0.175 score 0.271 lr 1.20463e-06 
07/28/2021 06:03:08 - INFO - volta.train_utils -   [NLVR2]: iter 1360 Ep: 0.50 loss 0.176 score 0.262 lr 1.24167e-06 
07/28/2021 06:03:47 - INFO - volta.train_utils -   [NLVR2]: iter 1400 Ep: 0.52 loss 0.174 score 0.272 lr 1.2787e-06 
07/28/2021 06:04:14 - INFO - volta.train_utils -   [NLVR2]: iter 1440 Ep: 0.53 loss 0.174 score 0.271 lr 1.31574e-06 
07/28/2021 06:04:43 - INFO - volta.train_utils -   [NLVR2]: iter 1480 Ep: 0.55 loss 0.177 score 0.269 lr 1.35278e-06 
07/28/2021 06:05:08 - INFO - volta.train_utils -   [NLVR2]: iter 1520 Ep: 0.56 loss 0.176 score 0.273 lr 1.38981e-06 
07/28/2021 06:05:37 - INFO - volta.train_utils -   [NLVR2]: iter 1560 Ep: 0.58 loss 0.177 score 0.276 lr 1.42685e-06 
07/28/2021 06:06:05 - INFO - volta.train_utils -   [NLVR2]: iter 1600 Ep: 0.59 loss 0.174 score 0.260 lr 1.46389e-06 
07/28/2021 06:06:38 - INFO - volta.train_utils -   [NLVR2]: iter 1640 Ep: 0.61 loss 0.177 score 0.270 lr 1.50093e-06 
07/28/2021 06:07:03 - INFO - volta.train_utils -   [NLVR2]: iter 1680 Ep: 0.62 loss 0.175 score 0.261 lr 1.53796e-06 
07/28/2021 06:07:31 - INFO - volta.train_utils -   [NLVR2]: iter 1720 Ep: 0.64 loss 0.172 score 0.278 lr 1.575e-06 
07/28/2021 06:07:59 - INFO - volta.train_utils -   [NLVR2]: iter 1760 Ep: 0.65 loss 0.174 score 0.264 lr 1.61204e-06 
07/28/2021 06:08:27 - INFO - volta.train_utils -   [NLVR2]: iter 1800 Ep: 0.67 loss 0.173 score 0.263 lr 1.64907e-06 
07/28/2021 06:08:55 - INFO - volta.train_utils -   [NLVR2]: iter 1840 Ep: 0.68 loss 0.174 score 0.271 lr 1.68611e-06 
07/28/2021 06:09:20 - INFO - volta.train_utils -   [NLVR2]: iter 1880 Ep: 0.70 loss 0.173 score 0.271 lr 1.72315e-06 
07/28/2021 06:09:47 - INFO - volta.train_utils -   [NLVR2]: iter 1920 Ep: 0.71 loss 0.175 score 0.270 lr 1.76019e-06 
07/28/2021 06:10:13 - INFO - volta.train_utils -   [NLVR2]: iter 1960 Ep: 0.73 loss 0.174 score 0.270 lr 1.79722e-06 
07/28/2021 06:10:42 - INFO - volta.train_utils -   [NLVR2]: iter 2000 Ep: 0.74 loss 0.173 score 0.268 lr 1.83426e-06 
07/28/2021 06:11:08 - INFO - volta.train_utils -   [NLVR2]: iter 2040 Ep: 0.76 loss 0.170 score 0.282 lr 1.8713e-06 
07/28/2021 06:11:34 - INFO - volta.train_utils -   [NLVR2]: iter 2080 Ep: 0.77 loss 0.174 score 0.263 lr 1.90833e-06 
07/28/2021 06:12:00 - INFO - volta.train_utils -   [NLVR2]: iter 2120 Ep: 0.79 loss 0.171 score 0.283 lr 1.94537e-06 
07/28/2021 06:12:27 - INFO - volta.train_utils -   [NLVR2]: iter 2160 Ep: 0.80 loss 0.172 score 0.274 lr 1.98241e-06 
07/28/2021 06:12:53 - INFO - volta.train_utils -   [NLVR2]: iter 2200 Ep: 0.81 loss 0.173 score 0.271 lr 2.01944e-06 
07/28/2021 06:13:18 - INFO - volta.train_utils -   [NLVR2]: iter 2240 Ep: 0.83 loss 0.172 score 0.285 lr 2.05648e-06 
07/28/2021 06:13:44 - INFO - volta.train_utils -   [NLVR2]: iter 2280 Ep: 0.84 loss 0.173 score 0.275 lr 2.09352e-06 
07/28/2021 06:14:10 - INFO - volta.train_utils -   [NLVR2]: iter 2320 Ep: 0.86 loss 0.170 score 0.283 lr 2.13056e-06 
07/28/2021 06:14:35 - INFO - volta.train_utils -   [NLVR2]: iter 2360 Ep: 0.87 loss 0.174 score 0.273 lr 2.16759e-06 
07/28/2021 06:15:03 - INFO - volta.train_utils -   [NLVR2]: iter 2400 Ep: 0.89 loss 0.169 score 0.284 lr 2.20463e-06 
07/28/2021 06:15:27 - INFO - volta.train_utils -   [NLVR2]: iter 2440 Ep: 0.90 loss 0.174 score 0.273 lr 2.24167e-06 
07/28/2021 06:15:53 - INFO - volta.train_utils -   [NLVR2]: iter 2480 Ep: 0.92 loss 0.170 score 0.274 lr 2.2787e-06 
07/28/2021 06:16:17 - INFO - volta.train_utils -   [NLVR2]: iter 2520 Ep: 0.93 loss 0.167 score 0.279 lr 2.31574e-06 
07/28/2021 06:16:44 - INFO - volta.train_utils -   [NLVR2]: iter 2560 Ep: 0.95 loss 0.169 score 0.288 lr 2.35278e-06 
07/28/2021 06:17:08 - INFO - volta.train_utils -   [NLVR2]: iter 2600 Ep: 0.96 loss 0.177 score 0.267 lr 2.38981e-06 
07/28/2021 06:17:32 - INFO - volta.train_utils -   [NLVR2]: iter 2640 Ep: 0.98 loss 0.173 score 0.278 lr 2.42685e-06 
07/28/2021 06:17:58 - INFO - volta.train_utils -   [NLVR2]: iter 2680 Ep: 0.99 loss 0.172 score 0.279 lr 2.46389e-06 
07/28/2021 06:18:10 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:   5%|▌         | 1/20 [34:16<10:51:13, 2056.50s/it]07/28/2021 06:28:53 - INFO - volta.train_utils -   Eval task TASK12 on iteration 2700 
07/28/2021 06:28:53 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.667 score 58.192 
07/28/2021 06:28:53 - INFO - __main__ -   ** ** * Saving model * ** ** 
07/28/2021 06:29:27 - INFO - volta.train_utils -   [NLVR2]: iter 2740 Ep: 1.01 loss 0.169 score 0.283 lr 2.51019e-06 
07/28/2021 06:29:48 - INFO - volta.train_utils -   [NLVR2]: iter 2780 Ep: 1.03 loss 0.168 score 0.289 lr 2.55648e-06 
07/28/2021 06:30:08 - INFO - volta.train_utils -   [NLVR2]: iter 2820 Ep: 1.04 loss 0.166 score 0.295 lr 2.59352e-06 
07/28/2021 06:30:28 - INFO - volta.train_utils -   [NLVR2]: iter 2860 Ep: 1.06 loss 0.165 score 0.302 lr 2.63056e-06 
07/28/2021 06:30:48 - INFO - volta.train_utils -   [NLVR2]: iter 2900 Ep: 1.07 loss 0.166 score 0.299 lr 2.66759e-06 
07/28/2021 06:31:09 - INFO - volta.train_utils -   [NLVR2]: iter 2940 Ep: 1.09 loss 0.167 score 0.294 lr 2.70463e-06 
07/28/2021 06:31:40 - INFO - volta.train_utils -   [NLVR2]: iter 2980 Ep: 1.10 loss 0.167 score 0.294 lr 2.74167e-06 
07/28/2021 06:32:02 - INFO - volta.train_utils -   [NLVR2]: iter 3020 Ep: 1.12 loss 0.164 score 0.304 lr 2.7787e-06 
07/28/2021 06:32:23 - INFO - volta.train_utils -   [NLVR2]: iter 3060 Ep: 1.13 loss 0.161 score 0.296 lr 2.81574e-06 
07/28/2021 06:32:43 - INFO - volta.train_utils -   [NLVR2]: iter 3100 Ep: 1.15 loss 0.167 score 0.288 lr 2.85278e-06 
07/28/2021 06:33:03 - INFO - volta.train_utils -   [NLVR2]: iter 3140 Ep: 1.16 loss 0.167 score 0.293 lr 2.88981e-06 
07/28/2021 06:33:24 - INFO - volta.train_utils -   [NLVR2]: iter 3180 Ep: 1.18 loss 0.167 score 0.294 lr 2.92685e-06 
07/28/2021 06:33:49 - INFO - volta.train_utils -   [NLVR2]: iter 3220 Ep: 1.19 loss 0.166 score 0.296 lr 2.96389e-06 
07/28/2021 06:34:11 - INFO - volta.train_utils -   [NLVR2]: iter 3260 Ep: 1.21 loss 0.168 score 0.286 lr 3.00093e-06 
07/28/2021 06:34:32 - INFO - volta.train_utils -   [NLVR2]: iter 3300 Ep: 1.22 loss 0.166 score 0.286 lr 3.03796e-06 
07/28/2021 06:34:52 - INFO - volta.train_utils -   [NLVR2]: iter 3340 Ep: 1.24 loss 0.163 score 0.299 lr 3.075e-06 
07/28/2021 06:35:14 - INFO - volta.train_utils -   [NLVR2]: iter 3380 Ep: 1.25 loss 0.166 score 0.300 lr 3.11204e-06 
07/28/2021 06:35:35 - INFO - volta.train_utils -   [NLVR2]: iter 3420 Ep: 1.27 loss 0.158 score 0.305 lr 3.14907e-06 
07/28/2021 06:35:56 - INFO - volta.train_utils -   [NLVR2]: iter 3460 Ep: 1.28 loss 0.166 score 0.296 lr 3.18611e-06 
07/28/2021 06:36:17 - INFO - volta.train_utils -   [NLVR2]: iter 3500 Ep: 1.30 loss 0.162 score 0.297 lr 3.22315e-06 
07/28/2021 06:36:38 - INFO - volta.train_utils -   [NLVR2]: iter 3540 Ep: 1.31 loss 0.162 score 0.307 lr 3.26019e-06 
07/28/2021 06:37:00 - INFO - volta.train_utils -   [NLVR2]: iter 3580 Ep: 1.33 loss 0.157 score 0.316 lr 3.29722e-06 
07/28/2021 06:37:22 - INFO - volta.train_utils -   [NLVR2]: iter 3620 Ep: 1.34 loss 0.162 score 0.300 lr 3.33426e-06 
07/28/2021 06:37:45 - INFO - volta.train_utils -   [NLVR2]: iter 3660 Ep: 1.36 loss 0.168 score 0.296 lr 3.3713e-06 
07/28/2021 06:38:07 - INFO - volta.train_utils -   [NLVR2]: iter 3700 Ep: 1.37 loss 0.159 score 0.307 lr 3.40833e-06 
07/28/2021 06:38:28 - INFO - volta.train_utils -   [NLVR2]: iter 3740 Ep: 1.39 loss 0.157 score 0.305 lr 3.44537e-06 
07/28/2021 06:38:50 - INFO - volta.train_utils -   [NLVR2]: iter 3780 Ep: 1.40 loss 0.159 score 0.300 lr 3.48241e-06 
07/28/2021 06:39:12 - INFO - volta.train_utils -   [NLVR2]: iter 3820 Ep: 1.41 loss 0.160 score 0.305 lr 3.51944e-06 
07/28/2021 06:39:35 - INFO - volta.train_utils -   [NLVR2]: iter 3860 Ep: 1.43 loss 0.161 score 0.311 lr 3.55648e-06 
07/28/2021 06:39:57 - INFO - volta.train_utils -   [NLVR2]: iter 3900 Ep: 1.44 loss 0.160 score 0.302 lr 3.59352e-06 
07/28/2021 06:40:20 - INFO - volta.train_utils -   [NLVR2]: iter 3940 Ep: 1.46 loss 0.163 score 0.298 lr 3.63056e-06 
07/28/2021 06:40:41 - INFO - volta.train_utils -   [NLVR2]: iter 3980 Ep: 1.47 loss 0.162 score 0.305 lr 3.66759e-06 
07/28/2021 06:41:05 - INFO - volta.train_utils -   [NLVR2]: iter 4020 Ep: 1.49 loss 0.162 score 0.306 lr 3.70463e-06 
07/28/2021 06:41:28 - INFO - volta.train_utils -   [NLVR2]: iter 4060 Ep: 1.50 loss 0.164 score 0.309 lr 3.74167e-06 
07/28/2021 06:41:52 - INFO - volta.train_utils -   [NLVR2]: iter 4100 Ep: 1.52 loss 0.164 score 0.310 lr 3.7787e-06 
07/28/2021 06:42:14 - INFO - volta.train_utils -   [NLVR2]: iter 4140 Ep: 1.53 loss 0.163 score 0.303 lr 3.81574e-06 
07/28/2021 06:42:39 - INFO - volta.train_utils -   [NLVR2]: iter 4180 Ep: 1.55 loss 0.157 score 0.311 lr 3.85278e-06 
07/28/2021 06:43:01 - INFO - volta.train_utils -   [NLVR2]: iter 4220 Ep: 1.56 loss 0.154 score 0.311 lr 3.88981e-06 
07/28/2021 06:43:26 - INFO - volta.train_utils -   [NLVR2]: iter 4260 Ep: 1.58 loss 0.155 score 0.309 lr 3.92685e-06 
07/28/2021 06:43:47 - INFO - volta.train_utils -   [NLVR2]: iter 4300 Ep: 1.59 loss 0.161 score 0.320 lr 3.96389e-06 
07/28/2021 06:44:13 - INFO - volta.train_utils -   [NLVR2]: iter 4340 Ep: 1.61 loss 0.160 score 0.307 lr 4.00093e-06 
07/28/2021 06:44:35 - INFO - volta.train_utils -   [NLVR2]: iter 4380 Ep: 1.62 loss 0.158 score 0.314 lr 4.03796e-06 
07/28/2021 06:44:59 - INFO - volta.train_utils -   [NLVR2]: iter 4420 Ep: 1.64 loss 0.157 score 0.311 lr 4.075e-06 
07/28/2021 06:45:22 - INFO - volta.train_utils -   [NLVR2]: iter 4460 Ep: 1.65 loss 0.154 score 0.313 lr 4.11204e-06 
07/28/2021 06:45:45 - INFO - volta.train_utils -   [NLVR2]: iter 4500 Ep: 1.67 loss 0.161 score 0.302 lr 4.14907e-06 
07/28/2021 06:46:08 - INFO - volta.train_utils -   [NLVR2]: iter 4540 Ep: 1.68 loss 0.161 score 0.314 lr 4.18611e-06 
07/28/2021 06:46:31 - INFO - volta.train_utils -   [NLVR2]: iter 4580 Ep: 1.70 loss 0.159 score 0.314 lr 4.22315e-06 
07/28/2021 06:46:53 - INFO - volta.train_utils -   [NLVR2]: iter 4620 Ep: 1.71 loss 0.160 score 0.310 lr 4.26019e-06 
07/28/2021 06:47:16 - INFO - volta.train_utils -   [NLVR2]: iter 4660 Ep: 1.73 loss 0.161 score 0.315 lr 4.29722e-06 
07/28/2021 06:47:39 - INFO - volta.train_utils -   [NLVR2]: iter 4700 Ep: 1.74 loss 0.160 score 0.310 lr 4.33426e-06 
07/28/2021 06:48:05 - INFO - volta.train_utils -   [NLVR2]: iter 4740 Ep: 1.76 loss 0.156 score 0.304 lr 4.3713e-06 
07/28/2021 06:48:27 - INFO - volta.train_utils -   [NLVR2]: iter 4780 Ep: 1.77 loss 0.160 score 0.298 lr 4.40833e-06 
07/28/2021 06:48:52 - INFO - volta.train_utils -   [NLVR2]: iter 4820 Ep: 1.79 loss 0.162 score 0.309 lr 4.44537e-06 
07/28/2021 06:49:13 - INFO - volta.train_utils -   [NLVR2]: iter 4860 Ep: 1.80 loss 0.155 score 0.317 lr 4.48241e-06 
07/28/2021 06:49:38 - INFO - volta.train_utils -   [NLVR2]: iter 4900 Ep: 1.81 loss 0.158 score 0.312 lr 4.51944e-06 
07/28/2021 06:50:01 - INFO - volta.train_utils -   [NLVR2]: iter 4940 Ep: 1.83 loss 0.159 score 0.312 lr 4.55648e-06 
07/28/2021 06:50:26 - INFO - volta.train_utils -   [NLVR2]: iter 4980 Ep: 1.84 loss 0.153 score 0.327 lr 4.59352e-06 
07/28/2021 06:50:49 - INFO - volta.train_utils -   [NLVR2]: iter 5020 Ep: 1.86 loss 0.158 score 0.309 lr 4.63056e-06 
07/28/2021 06:51:13 - INFO - volta.train_utils -   [NLVR2]: iter 5060 Ep: 1.87 loss 0.156 score 0.316 lr 4.66759e-06 
07/28/2021 06:51:36 - INFO - volta.train_utils -   [NLVR2]: iter 5100 Ep: 1.89 loss 0.156 score 0.311 lr 4.70463e-06 
07/28/2021 06:51:59 - INFO - volta.train_utils -   [NLVR2]: iter 5140 Ep: 1.90 loss 0.158 score 0.305 lr 4.74167e-06 
07/28/2021 06:52:21 - INFO - volta.train_utils -   [NLVR2]: iter 5180 Ep: 1.92 loss 0.155 score 0.302 lr 4.7787e-06 
07/28/2021 06:52:46 - INFO - volta.train_utils -   [NLVR2]: iter 5220 Ep: 1.93 loss 0.157 score 0.314 lr 4.81574e-06 
07/28/2021 06:53:09 - INFO - volta.train_utils -   [NLVR2]: iter 5260 Ep: 1.95 loss 0.157 score 0.306 lr 4.85278e-06 
07/28/2021 06:53:34 - INFO - volta.train_utils -   [NLVR2]: iter 5300 Ep: 1.96 loss 0.158 score 0.319 lr 4.88981e-06 
07/28/2021 06:53:57 - INFO - volta.train_utils -   [NLVR2]: iter 5340 Ep: 1.98 loss 0.158 score 0.307 lr 4.92685e-06 
07/28/2021 06:54:22 - INFO - volta.train_utils -   [NLVR2]: iter 5380 Ep: 1.99 loss 0.157 score 0.315 lr 4.96389e-06 
07/28/2021 06:54:32 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  10%|█         | 2/20 [1:10:37<10:28:07, 2093.74s/it]07/28/2021 07:01:11 - INFO - volta.train_utils -   Eval task TASK12 on iteration 5400 
07/28/2021 07:01:11 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.610 score 65.726 
07/28/2021 07:01:11 - INFO - __main__ -   ** ** * Saving model * ** ** 
07/28/2021 07:01:47 - INFO - volta.train_utils -   [NLVR2]: iter 5440 Ep: 2.01 loss 0.155 score 0.326 lr 4.99578e-06 
07/28/2021 07:02:07 - INFO - volta.train_utils -   [NLVR2]: iter 5480 Ep: 2.03 loss 0.147 score 0.325 lr 4.99372e-06 
07/28/2021 07:02:27 - INFO - volta.train_utils -   [NLVR2]: iter 5520 Ep: 2.04 loss 0.149 score 0.334 lr 4.98961e-06 
07/28/2021 07:02:47 - INFO - volta.train_utils -   [NLVR2]: iter 5560 Ep: 2.06 loss 0.150 score 0.335 lr 4.98549e-06 
07/28/2021 07:03:08 - INFO - volta.train_utils -   [NLVR2]: iter 5600 Ep: 2.07 loss 0.151 score 0.326 lr 4.98138e-06 
07/28/2021 07:03:28 - INFO - volta.train_utils -   [NLVR2]: iter 5640 Ep: 2.09 loss 0.142 score 0.337 lr 4.97726e-06 
07/28/2021 07:03:59 - INFO - volta.train_utils -   [NLVR2]: iter 5680 Ep: 2.10 loss 0.147 score 0.335 lr 4.97315e-06 
07/28/2021 07:04:21 - INFO - volta.train_utils -   [NLVR2]: iter 5720 Ep: 2.12 loss 0.152 score 0.316 lr 4.96903e-06 
07/28/2021 07:04:42 - INFO - volta.train_utils -   [NLVR2]: iter 5760 Ep: 2.13 loss 0.150 score 0.332 lr 4.96492e-06 
07/28/2021 07:05:02 - INFO - volta.train_utils -   [NLVR2]: iter 5800 Ep: 2.15 loss 0.146 score 0.334 lr 4.9608e-06 
07/28/2021 07:05:22 - INFO - volta.train_utils -   [NLVR2]: iter 5840 Ep: 2.16 loss 0.153 score 0.332 lr 4.95669e-06 
07/28/2021 07:05:43 - INFO - volta.train_utils -   [NLVR2]: iter 5880 Ep: 2.18 loss 0.154 score 0.314 lr 4.95257e-06 
07/28/2021 07:06:09 - INFO - volta.train_utils -   [NLVR2]: iter 5920 Ep: 2.19 loss 0.143 score 0.333 lr 4.94846e-06 
07/28/2021 07:06:30 - INFO - volta.train_utils -   [NLVR2]: iter 5960 Ep: 2.21 loss 0.143 score 0.331 lr 4.94434e-06 
07/28/2021 07:06:52 - INFO - volta.train_utils -   [NLVR2]: iter 6000 Ep: 2.22 loss 0.150 score 0.323 lr 4.94023e-06 
07/28/2021 07:07:14 - INFO - volta.train_utils -   [NLVR2]: iter 6040 Ep: 2.24 loss 0.149 score 0.324 lr 4.93611e-06 
07/28/2021 07:07:34 - INFO - volta.train_utils -   [NLVR2]: iter 6080 Ep: 2.25 loss 0.152 score 0.319 lr 4.932e-06 
07/28/2021 07:07:54 - INFO - volta.train_utils -   [NLVR2]: iter 6120 Ep: 2.27 loss 0.145 score 0.337 lr 4.92788e-06 
07/28/2021 07:08:19 - INFO - volta.train_utils -   [NLVR2]: iter 6160 Ep: 2.28 loss 0.149 score 0.334 lr 4.92377e-06 
07/28/2021 07:08:40 - INFO - volta.train_utils -   [NLVR2]: iter 6200 Ep: 2.30 loss 0.149 score 0.336 lr 4.91965e-06 
07/28/2021 07:09:01 - INFO - volta.train_utils -   [NLVR2]: iter 6240 Ep: 2.31 loss 0.153 score 0.328 lr 4.91553e-06 
07/28/2021 07:09:23 - INFO - volta.train_utils -   [NLVR2]: iter 6280 Ep: 2.33 loss 0.143 score 0.341 lr 4.91142e-06 
07/28/2021 07:09:45 - INFO - volta.train_utils -   [NLVR2]: iter 6320 Ep: 2.34 loss 0.152 score 0.336 lr 4.9073e-06 
07/28/2021 07:10:07 - INFO - volta.train_utils -   [NLVR2]: iter 6360 Ep: 2.36 loss 0.154 score 0.330 lr 4.90319e-06 
07/28/2021 07:10:30 - INFO - volta.train_utils -   [NLVR2]: iter 6400 Ep: 2.37 loss 0.159 score 0.324 lr 4.89907e-06 
07/28/2021 07:10:53 - INFO - volta.train_utils -   [NLVR2]: iter 6440 Ep: 2.39 loss 0.142 score 0.339 lr 4.89496e-06 
07/28/2021 07:11:15 - INFO - volta.train_utils -   [NLVR2]: iter 6480 Ep: 2.40 loss 0.146 score 0.339 lr 4.89084e-06 
07/28/2021 07:11:38 - INFO - volta.train_utils -   [NLVR2]: iter 6520 Ep: 2.41 loss 0.140 score 0.349 lr 4.88673e-06 
07/28/2021 07:11:59 - INFO - volta.train_utils -   [NLVR2]: iter 6560 Ep: 2.43 loss 0.140 score 0.335 lr 4.88261e-06 
07/28/2021 07:12:25 - INFO - volta.train_utils -   [NLVR2]: iter 6600 Ep: 2.44 loss 0.148 score 0.326 lr 4.8785e-06 
07/28/2021 07:12:48 - INFO - volta.train_utils -   [NLVR2]: iter 6640 Ep: 2.46 loss 0.148 score 0.343 lr 4.87438e-06 
07/28/2021 07:13:11 - INFO - volta.train_utils -   [NLVR2]: iter 6680 Ep: 2.47 loss 0.141 score 0.342 lr 4.87027e-06 
07/28/2021 07:13:32 - INFO - volta.train_utils -   [NLVR2]: iter 6720 Ep: 2.49 loss 0.146 score 0.328 lr 4.86615e-06 
07/28/2021 07:13:57 - INFO - volta.train_utils -   [NLVR2]: iter 6760 Ep: 2.50 loss 0.151 score 0.327 lr 4.86204e-06 
07/28/2021 07:14:20 - INFO - volta.train_utils -   [NLVR2]: iter 6800 Ep: 2.52 loss 0.142 score 0.336 lr 4.85792e-06 
07/28/2021 07:14:44 - INFO - volta.train_utils -   [NLVR2]: iter 6840 Ep: 2.53 loss 0.143 score 0.342 lr 4.85381e-06 
07/28/2021 07:15:06 - INFO - volta.train_utils -   [NLVR2]: iter 6880 Ep: 2.55 loss 0.150 score 0.330 lr 4.84969e-06 
07/28/2021 07:15:30 - INFO - volta.train_utils -   [NLVR2]: iter 6920 Ep: 2.56 loss 0.140 score 0.343 lr 4.84558e-06 
07/28/2021 07:15:52 - INFO - volta.train_utils -   [NLVR2]: iter 6960 Ep: 2.58 loss 0.152 score 0.328 lr 4.84146e-06 
07/28/2021 07:16:16 - INFO - volta.train_utils -   [NLVR2]: iter 7000 Ep: 2.59 loss 0.145 score 0.335 lr 4.83735e-06 
07/28/2021 07:16:39 - INFO - volta.train_utils -   [NLVR2]: iter 7040 Ep: 2.61 loss 0.146 score 0.335 lr 4.83323e-06 
07/28/2021 07:17:02 - INFO - volta.train_utils -   [NLVR2]: iter 7080 Ep: 2.62 loss 0.147 score 0.331 lr 4.82912e-06 
07/28/2021 07:17:24 - INFO - volta.train_utils -   [NLVR2]: iter 7120 Ep: 2.64 loss 0.142 score 0.336 lr 4.825e-06 
07/28/2021 07:17:48 - INFO - volta.train_utils -   [NLVR2]: iter 7160 Ep: 2.65 loss 0.149 score 0.338 lr 4.82088e-06 
07/28/2021 07:18:11 - INFO - volta.train_utils -   [NLVR2]: iter 7200 Ep: 2.67 loss 0.150 score 0.328 lr 4.81677e-06 
07/28/2021 07:18:36 - INFO - volta.train_utils -   [NLVR2]: iter 7240 Ep: 2.68 loss 0.148 score 0.340 lr 4.81265e-06 
07/28/2021 07:18:58 - INFO - volta.train_utils -   [NLVR2]: iter 7280 Ep: 2.70 loss 0.146 score 0.330 lr 4.80854e-06 
07/28/2021 07:19:21 - INFO - volta.train_utils -   [NLVR2]: iter 7320 Ep: 2.71 loss 0.146 score 0.334 lr 4.80442e-06 
07/28/2021 07:19:44 - INFO - volta.train_utils -   [NLVR2]: iter 7360 Ep: 2.73 loss 0.146 score 0.333 lr 4.80031e-06 
07/28/2021 07:20:07 - INFO - volta.train_utils -   [NLVR2]: iter 7400 Ep: 2.74 loss 0.149 score 0.334 lr 4.79619e-06 
07/28/2021 07:20:30 - INFO - volta.train_utils -   [NLVR2]: iter 7440 Ep: 2.76 loss 0.146 score 0.336 lr 4.79208e-06 
07/28/2021 07:20:55 - INFO - volta.train_utils -   [NLVR2]: iter 7480 Ep: 2.77 loss 0.140 score 0.343 lr 4.78796e-06 
07/28/2021 07:21:17 - INFO - volta.train_utils -   [NLVR2]: iter 7520 Ep: 2.79 loss 0.136 score 0.341 lr 4.78385e-06 
07/28/2021 07:21:39 - INFO - volta.train_utils -   [NLVR2]: iter 7560 Ep: 2.80 loss 0.147 score 0.348 lr 4.77973e-06 
07/28/2021 07:22:02 - INFO - volta.train_utils -   [NLVR2]: iter 7600 Ep: 2.81 loss 0.151 score 0.331 lr 4.77562e-06 
07/28/2021 07:22:26 - INFO - volta.train_utils -   [NLVR2]: iter 7640 Ep: 2.83 loss 0.143 score 0.336 lr 4.7715e-06 
07/28/2021 07:22:50 - INFO - volta.train_utils -   [NLVR2]: iter 7680 Ep: 2.84 loss 0.147 score 0.326 lr 4.76739e-06 
07/28/2021 07:23:13 - INFO - volta.train_utils -   [NLVR2]: iter 7720 Ep: 2.86 loss 0.147 score 0.332 lr 4.76327e-06 
07/28/2021 07:23:38 - INFO - volta.train_utils -   [NLVR2]: iter 7760 Ep: 2.87 loss 0.149 score 0.332 lr 4.75916e-06 
07/28/2021 07:24:01 - INFO - volta.train_utils -   [NLVR2]: iter 7800 Ep: 2.89 loss 0.145 score 0.335 lr 4.75504e-06 
07/28/2021 07:24:25 - INFO - volta.train_utils -   [NLVR2]: iter 7840 Ep: 2.90 loss 0.148 score 0.332 lr 4.75093e-06 
07/28/2021 07:24:48 - INFO - volta.train_utils -   [NLVR2]: iter 7880 Ep: 2.92 loss 0.144 score 0.330 lr 4.74681e-06 
07/28/2021 07:25:11 - INFO - volta.train_utils -   [NLVR2]: iter 7920 Ep: 2.93 loss 0.155 score 0.321 lr 4.7427e-06 
07/28/2021 07:25:36 - INFO - volta.train_utils -   [NLVR2]: iter 7960 Ep: 2.95 loss 0.142 score 0.343 lr 4.73858e-06 
07/28/2021 07:25:59 - INFO - volta.train_utils -   [NLVR2]: iter 8000 Ep: 2.96 loss 0.145 score 0.343 lr 4.73447e-06 
07/28/2021 07:26:23 - INFO - volta.train_utils -   [NLVR2]: iter 8040 Ep: 2.98 loss 0.142 score 0.338 lr 4.73035e-06 
07/28/2021 07:26:47 - INFO - volta.train_utils -   [NLVR2]: iter 8080 Ep: 2.99 loss 0.148 score 0.331 lr 4.72623e-06 
07/28/2021 07:26:57 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  15%|█▌        | 3/20 [1:43:02<9:40:39, 2049.37s/it] 07/28/2021 07:33:36 - INFO - volta.train_utils -   Eval task TASK12 on iteration 8100 
07/28/2021 07:33:36 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.582 score 67.703 
07/28/2021 07:33:36 - INFO - __main__ -   ** ** * Saving model * ** ** 
07/28/2021 07:34:10 - INFO - volta.train_utils -   [NLVR2]: iter 8140 Ep: 3.01 loss 0.145 score 0.339 lr 4.72109e-06 
07/28/2021 07:34:30 - INFO - volta.train_utils -   [NLVR2]: iter 8180 Ep: 3.03 loss 0.132 score 0.355 lr 4.71595e-06 
07/28/2021 07:34:50 - INFO - volta.train_utils -   [NLVR2]: iter 8220 Ep: 3.04 loss 0.139 score 0.354 lr 4.71183e-06 
07/28/2021 07:35:10 - INFO - volta.train_utils -   [NLVR2]: iter 8260 Ep: 3.06 loss 0.122 score 0.372 lr 4.70772e-06 
07/28/2021 07:35:31 - INFO - volta.train_utils -   [NLVR2]: iter 8300 Ep: 3.07 loss 0.128 score 0.360 lr 4.7036e-06 
07/28/2021 07:35:51 - INFO - volta.train_utils -   [NLVR2]: iter 8340 Ep: 3.09 loss 0.136 score 0.356 lr 4.69949e-06 
07/28/2021 07:36:15 - INFO - volta.train_utils -   [NLVR2]: iter 8380 Ep: 3.10 loss 0.130 score 0.351 lr 4.69537e-06 
07/28/2021 07:36:37 - INFO - volta.train_utils -   [NLVR2]: iter 8420 Ep: 3.12 loss 0.135 score 0.343 lr 4.69126e-06 
07/28/2021 07:36:58 - INFO - volta.train_utils -   [NLVR2]: iter 8460 Ep: 3.13 loss 0.143 score 0.348 lr 4.68714e-06 
07/28/2021 07:37:19 - INFO - volta.train_utils -   [NLVR2]: iter 8500 Ep: 3.15 loss 0.130 score 0.361 lr 4.68302e-06 
07/28/2021 07:37:39 - INFO - volta.train_utils -   [NLVR2]: iter 8540 Ep: 3.16 loss 0.128 score 0.368 lr 4.67891e-06 
07/28/2021 07:38:00 - INFO - volta.train_utils -   [NLVR2]: iter 8580 Ep: 3.18 loss 0.138 score 0.352 lr 4.67479e-06 
07/28/2021 07:38:24 - INFO - volta.train_utils -   [NLVR2]: iter 8620 Ep: 3.19 loss 0.127 score 0.361 lr 4.67068e-06 
07/28/2021 07:38:46 - INFO - volta.train_utils -   [NLVR2]: iter 8660 Ep: 3.21 loss 0.136 score 0.347 lr 4.66656e-06 
07/28/2021 07:39:07 - INFO - volta.train_utils -   [NLVR2]: iter 8700 Ep: 3.22 loss 0.135 score 0.360 lr 4.66245e-06 
07/28/2021 07:39:29 - INFO - volta.train_utils -   [NLVR2]: iter 8740 Ep: 3.24 loss 0.139 score 0.357 lr 4.65833e-06 
07/28/2021 07:39:50 - INFO - volta.train_utils -   [NLVR2]: iter 8780 Ep: 3.25 loss 0.134 score 0.357 lr 4.65422e-06 
07/28/2021 07:40:11 - INFO - volta.train_utils -   [NLVR2]: iter 8820 Ep: 3.27 loss 0.140 score 0.346 lr 4.6501e-06 
07/28/2021 07:40:35 - INFO - volta.train_utils -   [NLVR2]: iter 8860 Ep: 3.28 loss 0.132 score 0.357 lr 4.64599e-06 
07/28/2021 07:40:57 - INFO - volta.train_utils -   [NLVR2]: iter 8900 Ep: 3.30 loss 0.131 score 0.353 lr 4.64187e-06 
07/28/2021 07:41:19 - INFO - volta.train_utils -   [NLVR2]: iter 8940 Ep: 3.31 loss 0.132 score 0.355 lr 4.63776e-06 
07/28/2021 07:41:41 - INFO - volta.train_utils -   [NLVR2]: iter 8980 Ep: 3.33 loss 0.122 score 0.359 lr 4.63364e-06 
07/28/2021 07:42:03 - INFO - volta.train_utils -   [NLVR2]: iter 9020 Ep: 3.34 loss 0.137 score 0.353 lr 4.62953e-06 
07/28/2021 07:42:25 - INFO - volta.train_utils -   [NLVR2]: iter 9060 Ep: 3.36 loss 0.143 score 0.349 lr 4.62541e-06 
07/28/2021 07:42:48 - INFO - volta.train_utils -   [NLVR2]: iter 9100 Ep: 3.37 loss 0.133 score 0.361 lr 4.6213e-06 
07/28/2021 07:43:10 - INFO - volta.train_utils -   [NLVR2]: iter 9140 Ep: 3.39 loss 0.142 score 0.341 lr 4.61718e-06 
07/28/2021 07:43:33 - INFO - volta.train_utils -   [NLVR2]: iter 9180 Ep: 3.40 loss 0.133 score 0.357 lr 4.61307e-06 
07/28/2021 07:43:55 - INFO - volta.train_utils -   [NLVR2]: iter 9220 Ep: 3.41 loss 0.138 score 0.352 lr 4.60895e-06 
07/28/2021 07:44:19 - INFO - volta.train_utils -   [NLVR2]: iter 9260 Ep: 3.43 loss 0.132 score 0.352 lr 4.60484e-06 
07/28/2021 07:44:41 - INFO - volta.train_utils -   [NLVR2]: iter 9300 Ep: 3.44 loss 0.145 score 0.359 lr 4.60072e-06 
07/28/2021 07:45:05 - INFO - volta.train_utils -   [NLVR2]: iter 9340 Ep: 3.46 loss 0.135 score 0.348 lr 4.5966e-06 
07/28/2021 07:45:26 - INFO - volta.train_utils -   [NLVR2]: iter 9380 Ep: 3.47 loss 0.136 score 0.352 lr 4.59249e-06 
07/28/2021 07:45:49 - INFO - volta.train_utils -   [NLVR2]: iter 9420 Ep: 3.49 loss 0.136 score 0.354 lr 4.58837e-06 
07/28/2021 07:46:10 - INFO - volta.train_utils -   [NLVR2]: iter 9460 Ep: 3.50 loss 0.138 score 0.355 lr 4.58426e-06 
07/28/2021 07:46:35 - INFO - volta.train_utils -   [NLVR2]: iter 9500 Ep: 3.52 loss 0.134 score 0.364 lr 4.58014e-06 
07/28/2021 07:46:58 - INFO - volta.train_utils -   [NLVR2]: iter 9540 Ep: 3.53 loss 0.134 score 0.353 lr 4.57603e-06 
07/28/2021 07:47:22 - INFO - volta.train_utils -   [NLVR2]: iter 9580 Ep: 3.55 loss 0.138 score 0.355 lr 4.57191e-06 
07/28/2021 07:47:44 - INFO - volta.train_utils -   [NLVR2]: iter 9620 Ep: 3.56 loss 0.135 score 0.348 lr 4.5678e-06 
07/28/2021 07:48:09 - INFO - volta.train_utils -   [NLVR2]: iter 9660 Ep: 3.58 loss 0.134 score 0.357 lr 4.56368e-06 
07/28/2021 07:48:32 - INFO - volta.train_utils -   [NLVR2]: iter 9700 Ep: 3.59 loss 0.130 score 0.350 lr 4.55957e-06 
07/28/2021 07:48:56 - INFO - volta.train_utils -   [NLVR2]: iter 9740 Ep: 3.61 loss 0.126 score 0.364 lr 4.55545e-06 
07/28/2021 07:49:19 - INFO - volta.train_utils -   [NLVR2]: iter 9780 Ep: 3.62 loss 0.134 score 0.357 lr 4.55134e-06 
07/28/2021 07:49:42 - INFO - volta.train_utils -   [NLVR2]: iter 9820 Ep: 3.64 loss 0.136 score 0.356 lr 4.54722e-06 
07/28/2021 07:50:05 - INFO - volta.train_utils -   [NLVR2]: iter 9860 Ep: 3.65 loss 0.133 score 0.349 lr 4.54311e-06 
07/28/2021 07:50:28 - INFO - volta.train_utils -   [NLVR2]: iter 9900 Ep: 3.67 loss 0.133 score 0.354 lr 4.53899e-06 
07/28/2021 07:50:52 - INFO - volta.train_utils -   [NLVR2]: iter 9940 Ep: 3.68 loss 0.132 score 0.355 lr 4.53488e-06 
07/28/2021 07:51:16 - INFO - volta.train_utils -   [NLVR2]: iter 9980 Ep: 3.70 loss 0.139 score 0.351 lr 4.53076e-06 
07/28/2021 07:51:39 - INFO - volta.train_utils -   [NLVR2]: iter 10020 Ep: 3.71 loss 0.133 score 0.362 lr 4.52665e-06 
07/28/2021 07:52:03 - INFO - volta.train_utils -   [NLVR2]: iter 10060 Ep: 3.73 loss 0.131 score 0.362 lr 4.52253e-06 
07/28/2021 07:52:26 - INFO - volta.train_utils -   [NLVR2]: iter 10100 Ep: 3.74 loss 0.136 score 0.352 lr 4.51842e-06 
07/28/2021 07:52:51 - INFO - volta.train_utils -   [NLVR2]: iter 10140 Ep: 3.76 loss 0.132 score 0.359 lr 4.5143e-06 
07/28/2021 07:53:13 - INFO - volta.train_utils -   [NLVR2]: iter 10180 Ep: 3.77 loss 0.134 score 0.356 lr 4.51019e-06 
07/28/2021 07:53:37 - INFO - volta.train_utils -   [NLVR2]: iter 10220 Ep: 3.79 loss 0.135 score 0.344 lr 4.50607e-06 
07/28/2021 07:54:00 - INFO - volta.train_utils -   [NLVR2]: iter 10260 Ep: 3.80 loss 0.138 score 0.351 lr 4.50195e-06 
07/28/2021 07:54:23 - INFO - volta.train_utils -   [NLVR2]: iter 10300 Ep: 3.81 loss 0.128 score 0.374 lr 4.49784e-06 
07/28/2021 07:54:45 - INFO - volta.train_utils -   [NLVR2]: iter 10340 Ep: 3.83 loss 0.130 score 0.362 lr 4.49372e-06 
07/28/2021 07:55:09 - INFO - volta.train_utils -   [NLVR2]: iter 10380 Ep: 3.84 loss 0.135 score 0.350 lr 4.48961e-06 
07/28/2021 07:55:31 - INFO - volta.train_utils -   [NLVR2]: iter 10420 Ep: 3.86 loss 0.136 score 0.359 lr 4.48549e-06 
07/28/2021 07:55:56 - INFO - volta.train_utils -   [NLVR2]: iter 10460 Ep: 3.87 loss 0.126 score 0.357 lr 4.48138e-06 
07/28/2021 07:56:19 - INFO - volta.train_utils -   [NLVR2]: iter 10500 Ep: 3.89 loss 0.137 score 0.353 lr 4.47726e-06 
07/28/2021 07:56:43 - INFO - volta.train_utils -   [NLVR2]: iter 10540 Ep: 3.90 loss 0.136 score 0.352 lr 4.47315e-06 
07/28/2021 07:57:05 - INFO - volta.train_utils -   [NLVR2]: iter 10580 Ep: 3.92 loss 0.135 score 0.352 lr 4.46903e-06 
07/28/2021 07:57:30 - INFO - volta.train_utils -   [NLVR2]: iter 10620 Ep: 3.93 loss 0.126 score 0.364 lr 4.46492e-06 
07/28/2021 07:57:54 - INFO - volta.train_utils -   [NLVR2]: iter 10660 Ep: 3.95 loss 0.138 score 0.359 lr 4.4608e-06 
07/28/2021 07:58:18 - INFO - volta.train_utils -   [NLVR2]: iter 10700 Ep: 3.96 loss 0.129 score 0.362 lr 4.45669e-06 
07/28/2021 07:58:42 - INFO - volta.train_utils -   [NLVR2]: iter 10740 Ep: 3.98 loss 0.128 score 0.362 lr 4.45257e-06 
07/28/2021 07:59:06 - INFO - volta.train_utils -   [NLVR2]: iter 10780 Ep: 3.99 loss 0.134 score 0.351 lr 4.44846e-06 
07/28/2021 07:59:17 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  20%|██        | 4/20 [2:15:23<8:57:47, 2016.74s/it]07/28/2021 08:06:06 - INFO - volta.train_utils -   Eval task TASK12 on iteration 10800 
07/28/2021 08:06:06 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.566 score 69.550 
07/28/2021 08:06:06 - INFO - __main__ -   ** ** * Saving model * ** ** 
07/28/2021 08:06:40 - INFO - volta.train_utils -   [NLVR2]: iter 10840 Ep: 4.01 loss 0.134 score 0.363 lr 4.44331e-06 
07/28/2021 08:07:00 - INFO - volta.train_utils -   [NLVR2]: iter 10880 Ep: 4.03 loss 0.127 score 0.376 lr 4.43817e-06 
07/28/2021 08:07:20 - INFO - volta.train_utils -   [NLVR2]: iter 10920 Ep: 4.04 loss 0.120 score 0.383 lr 4.43405e-06 
07/28/2021 08:07:40 - INFO - volta.train_utils -   [NLVR2]: iter 10960 Ep: 4.06 loss 0.116 score 0.380 lr 4.42994e-06 
07/28/2021 08:08:00 - INFO - volta.train_utils -   [NLVR2]: iter 11000 Ep: 4.07 loss 0.123 score 0.376 lr 4.42582e-06 
07/28/2021 08:08:21 - INFO - volta.train_utils -   [NLVR2]: iter 11040 Ep: 4.09 loss 0.121 score 0.377 lr 4.42171e-06 
07/28/2021 08:08:47 - INFO - volta.train_utils -   [NLVR2]: iter 11080 Ep: 4.10 loss 0.122 score 0.368 lr 4.41759e-06 
07/28/2021 08:09:09 - INFO - volta.train_utils -   [NLVR2]: iter 11120 Ep: 4.12 loss 0.120 score 0.381 lr 4.41348e-06 
07/28/2021 08:09:31 - INFO - volta.train_utils -   [NLVR2]: iter 11160 Ep: 4.13 loss 0.123 score 0.375 lr 4.40936e-06 
07/28/2021 08:09:51 - INFO - volta.train_utils -   [NLVR2]: iter 11200 Ep: 4.15 loss 0.124 score 0.372 lr 4.40525e-06 
07/28/2021 08:10:12 - INFO - volta.train_utils -   [NLVR2]: iter 11240 Ep: 4.16 loss 0.116 score 0.388 lr 4.40113e-06 
07/28/2021 08:10:33 - INFO - volta.train_utils -   [NLVR2]: iter 11280 Ep: 4.18 loss 0.127 score 0.364 lr 4.39702e-06 
07/28/2021 08:10:59 - INFO - volta.train_utils -   [NLVR2]: iter 11320 Ep: 4.19 loss 0.118 score 0.374 lr 4.3929e-06 
07/28/2021 08:11:20 - INFO - volta.train_utils -   [NLVR2]: iter 11360 Ep: 4.21 loss 0.118 score 0.367 lr 4.38879e-06 
07/28/2021 08:11:40 - INFO - volta.train_utils -   [NLVR2]: iter 11400 Ep: 4.22 loss 0.129 score 0.360 lr 4.38467e-06 
07/28/2021 08:12:01 - INFO - volta.train_utils -   [NLVR2]: iter 11440 Ep: 4.24 loss 0.125 score 0.363 lr 4.38056e-06 
07/28/2021 08:12:21 - INFO - volta.train_utils -   [NLVR2]: iter 11480 Ep: 4.25 loss 0.120 score 0.377 lr 4.37644e-06 
07/28/2021 08:12:43 - INFO - volta.train_utils -   [NLVR2]: iter 11520 Ep: 4.27 loss 0.125 score 0.377 lr 4.37233e-06 
07/28/2021 08:13:07 - INFO - volta.train_utils -   [NLVR2]: iter 11560 Ep: 4.28 loss 0.127 score 0.378 lr 4.36821e-06 
07/28/2021 08:13:29 - INFO - volta.train_utils -   [NLVR2]: iter 11600 Ep: 4.30 loss 0.123 score 0.370 lr 4.36409e-06 
07/28/2021 08:13:50 - INFO - volta.train_utils -   [NLVR2]: iter 11640 Ep: 4.31 loss 0.121 score 0.364 lr 4.35998e-06 
07/28/2021 08:14:12 - INFO - volta.train_utils -   [NLVR2]: iter 11680 Ep: 4.33 loss 0.123 score 0.367 lr 4.35586e-06 
07/28/2021 08:14:35 - INFO - volta.train_utils -   [NLVR2]: iter 11720 Ep: 4.34 loss 0.127 score 0.365 lr 4.35175e-06 
07/28/2021 08:14:57 - INFO - volta.train_utils -   [NLVR2]: iter 11760 Ep: 4.36 loss 0.125 score 0.364 lr 4.34763e-06 
07/28/2021 08:15:18 - INFO - volta.train_utils -   [NLVR2]: iter 11800 Ep: 4.37 loss 0.119 score 0.380 lr 4.34352e-06 
07/28/2021 08:15:41 - INFO - volta.train_utils -   [NLVR2]: iter 11840 Ep: 4.39 loss 0.118 score 0.373 lr 4.3394e-06 
07/28/2021 08:16:03 - INFO - volta.train_utils -   [NLVR2]: iter 11880 Ep: 4.40 loss 0.123 score 0.374 lr 4.33529e-06 
07/28/2021 08:16:26 - INFO - volta.train_utils -   [NLVR2]: iter 11920 Ep: 4.41 loss 0.128 score 0.370 lr 4.33117e-06 
07/28/2021 08:16:48 - INFO - volta.train_utils -   [NLVR2]: iter 11960 Ep: 4.43 loss 0.126 score 0.374 lr 4.32706e-06 
07/28/2021 08:17:11 - INFO - volta.train_utils -   [NLVR2]: iter 12000 Ep: 4.44 loss 0.135 score 0.357 lr 4.32294e-06 
07/28/2021 08:17:33 - INFO - volta.train_utils -   [NLVR2]: iter 12040 Ep: 4.46 loss 0.122 score 0.370 lr 4.31883e-06 
07/28/2021 08:17:57 - INFO - volta.train_utils -   [NLVR2]: iter 12080 Ep: 4.47 loss 0.133 score 0.367 lr 4.31471e-06 
07/28/2021 08:18:20 - INFO - volta.train_utils -   [NLVR2]: iter 12120 Ep: 4.49 loss 0.129 score 0.359 lr 4.3106e-06 
07/28/2021 08:18:42 - INFO - volta.train_utils -   [NLVR2]: iter 12160 Ep: 4.50 loss 0.121 score 0.370 lr 4.30648e-06 
07/28/2021 08:19:03 - INFO - volta.train_utils -   [NLVR2]: iter 12200 Ep: 4.52 loss 0.128 score 0.358 lr 4.30237e-06 
07/28/2021 08:19:26 - INFO - volta.train_utils -   [NLVR2]: iter 12240 Ep: 4.53 loss 0.121 score 0.374 lr 4.29825e-06 
07/28/2021 08:19:50 - INFO - volta.train_utils -   [NLVR2]: iter 12280 Ep: 4.55 loss 0.124 score 0.366 lr 4.29414e-06 
07/28/2021 08:20:12 - INFO - volta.train_utils -   [NLVR2]: iter 12320 Ep: 4.56 loss 0.129 score 0.368 lr 4.29002e-06 
07/28/2021 08:20:36 - INFO - volta.train_utils -   [NLVR2]: iter 12360 Ep: 4.58 loss 0.129 score 0.359 lr 4.28591e-06 
07/28/2021 08:21:00 - INFO - volta.train_utils -   [NLVR2]: iter 12400 Ep: 4.59 loss 0.129 score 0.359 lr 4.28179e-06 
07/28/2021 08:21:24 - INFO - volta.train_utils -   [NLVR2]: iter 12440 Ep: 4.61 loss 0.119 score 0.369 lr 4.27767e-06 
07/28/2021 08:21:47 - INFO - volta.train_utils -   [NLVR2]: iter 12480 Ep: 4.62 loss 0.124 score 0.378 lr 4.27356e-06 
07/28/2021 08:22:11 - INFO - volta.train_utils -   [NLVR2]: iter 12520 Ep: 4.64 loss 0.128 score 0.371 lr 4.26944e-06 
07/28/2021 08:22:34 - INFO - volta.train_utils -   [NLVR2]: iter 12560 Ep: 4.65 loss 0.129 score 0.377 lr 4.26533e-06 
07/28/2021 08:22:56 - INFO - volta.train_utils -   [NLVR2]: iter 12600 Ep: 4.67 loss 0.125 score 0.376 lr 4.26121e-06 
07/28/2021 08:23:19 - INFO - volta.train_utils -   [NLVR2]: iter 12640 Ep: 4.68 loss 0.121 score 0.373 lr 4.2571e-06 
07/28/2021 08:23:44 - INFO - volta.train_utils -   [NLVR2]: iter 12680 Ep: 4.70 loss 0.129 score 0.378 lr 4.25298e-06 
07/28/2021 08:24:07 - INFO - volta.train_utils -   [NLVR2]: iter 12720 Ep: 4.71 loss 0.123 score 0.369 lr 4.24887e-06 
07/28/2021 08:24:31 - INFO - volta.train_utils -   [NLVR2]: iter 12760 Ep: 4.73 loss 0.132 score 0.369 lr 4.24475e-06 
07/28/2021 08:24:54 - INFO - volta.train_utils -   [NLVR2]: iter 12800 Ep: 4.74 loss 0.117 score 0.377 lr 4.24064e-06 
07/28/2021 08:25:17 - INFO - volta.train_utils -   [NLVR2]: iter 12840 Ep: 4.76 loss 0.129 score 0.368 lr 4.23652e-06 
07/28/2021 08:25:39 - INFO - volta.train_utils -   [NLVR2]: iter 12880 Ep: 4.77 loss 0.130 score 0.363 lr 4.23241e-06 
07/28/2021 08:26:03 - INFO - volta.train_utils -   [NLVR2]: iter 12920 Ep: 4.79 loss 0.116 score 0.379 lr 4.22829e-06 
07/28/2021 08:26:25 - INFO - volta.train_utils -   [NLVR2]: iter 12960 Ep: 4.80 loss 0.120 score 0.373 lr 4.22418e-06 
07/28/2021 08:26:49 - INFO - volta.train_utils -   [NLVR2]: iter 13000 Ep: 4.81 loss 0.120 score 0.373 lr 4.22006e-06 
07/28/2021 08:27:12 - INFO - volta.train_utils -   [NLVR2]: iter 13040 Ep: 4.83 loss 0.122 score 0.371 lr 4.21595e-06 
07/28/2021 08:27:37 - INFO - volta.train_utils -   [NLVR2]: iter 13080 Ep: 4.84 loss 0.129 score 0.373 lr 4.21183e-06 
07/28/2021 08:27:59 - INFO - volta.train_utils -   [NLVR2]: iter 13120 Ep: 4.86 loss 0.122 score 0.373 lr 4.20772e-06 
07/28/2021 08:28:21 - INFO - volta.train_utils -   [NLVR2]: iter 13160 Ep: 4.87 loss 0.122 score 0.371 lr 4.2036e-06 
07/28/2021 08:28:45 - INFO - volta.train_utils -   [NLVR2]: iter 13200 Ep: 4.89 loss 0.124 score 0.374 lr 4.19949e-06 
07/28/2021 08:29:08 - INFO - volta.train_utils -   [NLVR2]: iter 13240 Ep: 4.90 loss 0.122 score 0.371 lr 4.19537e-06 
07/28/2021 08:29:32 - INFO - volta.train_utils -   [NLVR2]: iter 13280 Ep: 4.92 loss 0.119 score 0.370 lr 4.19126e-06 
07/28/2021 08:29:55 - INFO - volta.train_utils -   [NLVR2]: iter 13320 Ep: 4.93 loss 0.124 score 0.364 lr 4.18714e-06 
07/28/2021 08:30:19 - INFO - volta.train_utils -   [NLVR2]: iter 13360 Ep: 4.95 loss 0.124 score 0.370 lr 4.18302e-06 
07/28/2021 08:30:43 - INFO - volta.train_utils -   [NLVR2]: iter 13400 Ep: 4.96 loss 0.119 score 0.378 lr 4.17891e-06 
07/28/2021 08:31:06 - INFO - volta.train_utils -   [NLVR2]: iter 13440 Ep: 4.98 loss 0.126 score 0.375 lr 4.17479e-06 
07/28/2021 08:31:31 - INFO - volta.train_utils -   [NLVR2]: iter 13480 Ep: 4.99 loss 0.119 score 0.371 lr 4.17068e-06 
07/28/2021 08:31:42 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  25%|██▌       | 5/20 [2:47:48<8:18:46, 1995.07s/it]07/28/2021 08:38:25 - INFO - volta.train_utils -   Eval task TASK12 on iteration 13500 
07/28/2021 08:38:25 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.571 score 70.209 
07/28/2021 08:38:25 - INFO - __main__ -   ** ** * Saving model * ** ** 
07/28/2021 08:39:01 - INFO - volta.train_utils -   [NLVR2]: iter 13540 Ep: 5.01 loss 0.113 score 0.383 lr 4.16553e-06 
07/28/2021 08:39:21 - INFO - volta.train_utils -   [NLVR2]: iter 13580 Ep: 5.03 loss 0.108 score 0.393 lr 4.16039e-06 
07/28/2021 08:39:41 - INFO - volta.train_utils -   [NLVR2]: iter 13620 Ep: 5.04 loss 0.117 score 0.373 lr 4.15628e-06 
07/28/2021 08:40:01 - INFO - volta.train_utils -   [NLVR2]: iter 13660 Ep: 5.06 loss 0.109 score 0.379 lr 4.15216e-06 
07/28/2021 08:40:21 - INFO - volta.train_utils -   [NLVR2]: iter 13700 Ep: 5.07 loss 0.116 score 0.382 lr 4.14805e-06 
07/28/2021 08:40:42 - INFO - volta.train_utils -   [NLVR2]: iter 13740 Ep: 5.09 loss 0.107 score 0.391 lr 4.14393e-06 
07/28/2021 08:41:11 - INFO - volta.train_utils -   [NLVR2]: iter 13780 Ep: 5.10 loss 0.106 score 0.391 lr 4.13981e-06 
07/28/2021 08:41:33 - INFO - volta.train_utils -   [NLVR2]: iter 13820 Ep: 5.12 loss 0.103 score 0.396 lr 4.1357e-06 
07/28/2021 08:41:54 - INFO - volta.train_utils -   [NLVR2]: iter 13860 Ep: 5.13 loss 0.110 score 0.391 lr 4.13158e-06 
07/28/2021 08:42:14 - INFO - volta.train_utils -   [NLVR2]: iter 13900 Ep: 5.15 loss 0.107 score 0.378 lr 4.12747e-06 
07/28/2021 08:42:36 - INFO - volta.train_utils -   [NLVR2]: iter 13940 Ep: 5.16 loss 0.110 score 0.392 lr 4.12335e-06 
07/28/2021 08:42:56 - INFO - volta.train_utils -   [NLVR2]: iter 13980 Ep: 5.18 loss 0.113 score 0.390 lr 4.11924e-06 
07/28/2021 08:43:20 - INFO - volta.train_utils -   [NLVR2]: iter 14020 Ep: 5.19 loss 0.108 score 0.379 lr 4.11512e-06 
07/28/2021 08:43:42 - INFO - volta.train_utils -   [NLVR2]: iter 14060 Ep: 5.21 loss 0.111 score 0.387 lr 4.11101e-06 
07/28/2021 08:44:03 - INFO - volta.train_utils -   [NLVR2]: iter 14100 Ep: 5.22 loss 0.108 score 0.382 lr 4.10689e-06 
07/28/2021 08:44:25 - INFO - volta.train_utils -   [NLVR2]: iter 14140 Ep: 5.24 loss 0.116 score 0.377 lr 4.10278e-06 
07/28/2021 08:44:47 - INFO - volta.train_utils -   [NLVR2]: iter 14180 Ep: 5.25 loss 0.118 score 0.379 lr 4.09866e-06 
07/28/2021 08:45:08 - INFO - volta.train_utils -   [NLVR2]: iter 14220 Ep: 5.27 loss 0.099 score 0.394 lr 4.09455e-06 
07/28/2021 08:45:31 - INFO - volta.train_utils -   [NLVR2]: iter 14260 Ep: 5.28 loss 0.111 score 0.395 lr 4.09043e-06 
07/28/2021 08:45:52 - INFO - volta.train_utils -   [NLVR2]: iter 14300 Ep: 5.30 loss 0.120 score 0.377 lr 4.08632e-06 
07/28/2021 08:46:15 - INFO - volta.train_utils -   [NLVR2]: iter 14340 Ep: 5.31 loss 0.105 score 0.396 lr 4.0822e-06 
07/28/2021 08:46:36 - INFO - volta.train_utils -   [NLVR2]: iter 14380 Ep: 5.33 loss 0.113 score 0.377 lr 4.07809e-06 
07/28/2021 08:46:56 - INFO - volta.train_utils -   [NLVR2]: iter 14420 Ep: 5.34 loss 0.105 score 0.389 lr 4.07397e-06 
07/28/2021 08:47:18 - INFO - volta.train_utils -   [NLVR2]: iter 14460 Ep: 5.36 loss 0.117 score 0.386 lr 4.06986e-06 
07/28/2021 08:47:41 - INFO - volta.train_utils -   [NLVR2]: iter 14500 Ep: 5.37 loss 0.111 score 0.386 lr 4.06574e-06 
07/28/2021 08:48:03 - INFO - volta.train_utils -   [NLVR2]: iter 14540 Ep: 5.39 loss 0.112 score 0.386 lr 4.06163e-06 
07/28/2021 08:48:25 - INFO - volta.train_utils -   [NLVR2]: iter 14580 Ep: 5.40 loss 0.118 score 0.368 lr 4.05751e-06 
07/28/2021 08:48:47 - INFO - volta.train_utils -   [NLVR2]: iter 14620 Ep: 5.41 loss 0.107 score 0.388 lr 4.0534e-06 
07/28/2021 08:49:08 - INFO - volta.train_utils -   [NLVR2]: iter 14660 Ep: 5.43 loss 0.095 score 0.401 lr 4.04928e-06 
07/28/2021 08:49:31 - INFO - volta.train_utils -   [NLVR2]: iter 14700 Ep: 5.44 loss 0.125 score 0.370 lr 4.04516e-06 
07/28/2021 08:49:54 - INFO - volta.train_utils -   [NLVR2]: iter 14740 Ep: 5.46 loss 0.108 score 0.376 lr 4.04105e-06 
07/28/2021 08:50:16 - INFO - volta.train_utils -   [NLVR2]: iter 14780 Ep: 5.47 loss 0.113 score 0.386 lr 4.03693e-06 
07/28/2021 08:50:39 - INFO - volta.train_utils -   [NLVR2]: iter 14820 Ep: 5.49 loss 0.110 score 0.382 lr 4.03282e-06 
07/28/2021 08:51:01 - INFO - volta.train_utils -   [NLVR2]: iter 14860 Ep: 5.50 loss 0.114 score 0.391 lr 4.0287e-06 
07/28/2021 08:51:24 - INFO - volta.train_utils -   [NLVR2]: iter 14900 Ep: 5.52 loss 0.108 score 0.391 lr 4.02459e-06 
07/28/2021 08:51:47 - INFO - volta.train_utils -   [NLVR2]: iter 14940 Ep: 5.53 loss 0.109 score 0.386 lr 4.02047e-06 
07/28/2021 08:52:10 - INFO - volta.train_utils -   [NLVR2]: iter 14980 Ep: 5.55 loss 0.117 score 0.379 lr 4.01636e-06 
07/28/2021 08:52:32 - INFO - volta.train_utils -   [NLVR2]: iter 15020 Ep: 5.56 loss 0.120 score 0.371 lr 4.01224e-06 
07/28/2021 08:52:55 - INFO - volta.train_utils -   [NLVR2]: iter 15060 Ep: 5.58 loss 0.118 score 0.389 lr 4.00813e-06 
07/28/2021 08:53:18 - INFO - volta.train_utils -   [NLVR2]: iter 15100 Ep: 5.59 loss 0.113 score 0.395 lr 4.00401e-06 
07/28/2021 08:53:41 - INFO - volta.train_utils -   [NLVR2]: iter 15140 Ep: 5.61 loss 0.117 score 0.378 lr 3.9999e-06 
07/28/2021 08:54:05 - INFO - volta.train_utils -   [NLVR2]: iter 15180 Ep: 5.62 loss 0.110 score 0.388 lr 3.99578e-06 
07/28/2021 08:54:28 - INFO - volta.train_utils -   [NLVR2]: iter 15220 Ep: 5.64 loss 0.108 score 0.386 lr 3.99167e-06 
07/28/2021 08:54:51 - INFO - volta.train_utils -   [NLVR2]: iter 15260 Ep: 5.65 loss 0.114 score 0.384 lr 3.98755e-06 
07/28/2021 08:55:15 - INFO - volta.train_utils -   [NLVR2]: iter 15300 Ep: 5.67 loss 0.106 score 0.395 lr 3.98344e-06 
07/28/2021 08:55:38 - INFO - volta.train_utils -   [NLVR2]: iter 15340 Ep: 5.68 loss 0.118 score 0.376 lr 3.97932e-06 
07/28/2021 08:56:01 - INFO - volta.train_utils -   [NLVR2]: iter 15380 Ep: 5.70 loss 0.123 score 0.381 lr 3.97521e-06 
07/28/2021 08:56:24 - INFO - volta.train_utils -   [NLVR2]: iter 15420 Ep: 5.71 loss 0.107 score 0.386 lr 3.97109e-06 
07/28/2021 08:56:48 - INFO - volta.train_utils -   [NLVR2]: iter 15460 Ep: 5.73 loss 0.109 score 0.391 lr 3.96698e-06 
07/28/2021 08:57:11 - INFO - volta.train_utils -   [NLVR2]: iter 15500 Ep: 5.74 loss 0.112 score 0.388 lr 3.96286e-06 
07/28/2021 08:57:34 - INFO - volta.train_utils -   [NLVR2]: iter 15540 Ep: 5.76 loss 0.117 score 0.381 lr 3.95874e-06 
07/28/2021 08:57:57 - INFO - volta.train_utils -   [NLVR2]: iter 15580 Ep: 5.77 loss 0.111 score 0.385 lr 3.95463e-06 
07/28/2021 08:58:21 - INFO - volta.train_utils -   [NLVR2]: iter 15620 Ep: 5.79 loss 0.114 score 0.380 lr 3.95051e-06 
07/28/2021 08:58:44 - INFO - volta.train_utils -   [NLVR2]: iter 15660 Ep: 5.80 loss 0.114 score 0.384 lr 3.9464e-06 
07/28/2021 08:59:09 - INFO - volta.train_utils -   [NLVR2]: iter 15700 Ep: 5.81 loss 0.119 score 0.385 lr 3.94228e-06 
07/28/2021 08:59:33 - INFO - volta.train_utils -   [NLVR2]: iter 15740 Ep: 5.83 loss 0.118 score 0.372 lr 3.93817e-06 
07/28/2021 08:59:56 - INFO - volta.train_utils -   [NLVR2]: iter 15780 Ep: 5.84 loss 0.108 score 0.392 lr 3.93405e-06 
07/28/2021 09:00:19 - INFO - volta.train_utils -   [NLVR2]: iter 15820 Ep: 5.86 loss 0.117 score 0.382 lr 3.92994e-06 
07/28/2021 09:00:41 - INFO - volta.train_utils -   [NLVR2]: iter 15860 Ep: 5.87 loss 0.117 score 0.378 lr 3.92582e-06 
07/28/2021 09:01:04 - INFO - volta.train_utils -   [NLVR2]: iter 15900 Ep: 5.89 loss 0.116 score 0.385 lr 3.92171e-06 
07/28/2021 09:01:28 - INFO - volta.train_utils -   [NLVR2]: iter 15940 Ep: 5.90 loss 0.126 score 0.375 lr 3.91759e-06 
07/28/2021 09:01:51 - INFO - volta.train_utils -   [NLVR2]: iter 15980 Ep: 5.92 loss 0.124 score 0.379 lr 3.91348e-06 
07/28/2021 09:02:16 - INFO - volta.train_utils -   [NLVR2]: iter 16020 Ep: 5.93 loss 0.114 score 0.375 lr 3.90936e-06 
07/28/2021 09:02:38 - INFO - volta.train_utils -   [NLVR2]: iter 16060 Ep: 5.95 loss 0.110 score 0.378 lr 3.90525e-06 
07/28/2021 09:03:02 - INFO - volta.train_utils -   [NLVR2]: iter 16100 Ep: 5.96 loss 0.117 score 0.385 lr 3.90113e-06 
07/28/2021 09:03:25 - INFO - volta.train_utils -   [NLVR2]: iter 16140 Ep: 5.98 loss 0.105 score 0.390 lr 3.89702e-06 
07/28/2021 09:03:50 - INFO - volta.train_utils -   [NLVR2]: iter 16180 Ep: 5.99 loss 0.110 score 0.382 lr 3.8929e-06 
07/28/2021 09:04:00 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  30%|███       | 6/20 [3:20:07<7:41:35, 1978.26s/it]07/28/2021 09:10:40 - INFO - volta.train_utils -   Eval task TASK12 on iteration 16200 
07/28/2021 09:10:40 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.592 score 70.954 
07/28/2021 09:10:40 - INFO - __main__ -   ** ** * Saving model * ** ** 
07/28/2021 09:11:15 - INFO - volta.train_utils -   [NLVR2]: iter 16240 Ep: 6.01 loss 0.108 score 0.396 lr 3.88776e-06 
07/28/2021 09:11:35 - INFO - volta.train_utils -   [NLVR2]: iter 16280 Ep: 6.03 loss 0.097 score 0.400 lr 3.88261e-06 
07/28/2021 09:11:55 - INFO - volta.train_utils -   [NLVR2]: iter 16320 Ep: 6.04 loss 0.105 score 0.395 lr 3.8785e-06 
07/28/2021 09:12:15 - INFO - volta.train_utils -   [NLVR2]: iter 16360 Ep: 6.06 loss 0.104 score 0.399 lr 3.87438e-06 
07/28/2021 09:12:36 - INFO - volta.train_utils -   [NLVR2]: iter 16400 Ep: 6.07 loss 0.102 score 0.402 lr 3.87027e-06 
07/28/2021 09:12:56 - INFO - volta.train_utils -   [NLVR2]: iter 16440 Ep: 6.09 loss 0.108 score 0.400 lr 3.86615e-06 
07/28/2021 09:13:24 - INFO - volta.train_utils -   [NLVR2]: iter 16480 Ep: 6.10 loss 0.101 score 0.403 lr 3.86204e-06 
07/28/2021 09:13:46 - INFO - volta.train_utils -   [NLVR2]: iter 16520 Ep: 6.12 loss 0.101 score 0.399 lr 3.85792e-06 
07/28/2021 09:14:07 - INFO - volta.train_utils -   [NLVR2]: iter 16560 Ep: 6.13 loss 0.101 score 0.404 lr 3.85381e-06 
07/28/2021 09:14:28 - INFO - volta.train_utils -   [NLVR2]: iter 16600 Ep: 6.15 loss 0.102 score 0.392 lr 3.84969e-06 
07/28/2021 09:14:49 - INFO - volta.train_utils -   [NLVR2]: iter 16640 Ep: 6.16 loss 0.102 score 0.393 lr 3.84558e-06 
07/28/2021 09:15:09 - INFO - volta.train_utils -   [NLVR2]: iter 16680 Ep: 6.18 loss 0.100 score 0.405 lr 3.84146e-06 
07/28/2021 09:15:32 - INFO - volta.train_utils -   [NLVR2]: iter 16720 Ep: 6.19 loss 0.101 score 0.405 lr 3.83735e-06 
07/28/2021 09:15:54 - INFO - volta.train_utils -   [NLVR2]: iter 16760 Ep: 6.21 loss 0.109 score 0.394 lr 3.83323e-06 
07/28/2021 09:16:15 - INFO - volta.train_utils -   [NLVR2]: iter 16800 Ep: 6.22 loss 0.111 score 0.395 lr 3.82912e-06 
07/28/2021 09:16:36 - INFO - volta.train_utils -   [NLVR2]: iter 16840 Ep: 6.24 loss 0.101 score 0.401 lr 3.825e-06 
07/28/2021 09:16:56 - INFO - volta.train_utils -   [NLVR2]: iter 16880 Ep: 6.25 loss 0.102 score 0.400 lr 3.82088e-06 
07/28/2021 09:17:19 - INFO - volta.train_utils -   [NLVR2]: iter 16920 Ep: 6.27 loss 0.102 score 0.389 lr 3.81677e-06 
07/28/2021 09:17:43 - INFO - volta.train_utils -   [NLVR2]: iter 16960 Ep: 6.28 loss 0.099 score 0.389 lr 3.81265e-06 
07/28/2021 09:18:04 - INFO - volta.train_utils -   [NLVR2]: iter 17000 Ep: 6.30 loss 0.104 score 0.393 lr 3.80854e-06 
07/28/2021 09:18:25 - INFO - volta.train_utils -   [NLVR2]: iter 17040 Ep: 6.31 loss 0.102 score 0.402 lr 3.80442e-06 
07/28/2021 09:18:47 - INFO - volta.train_utils -   [NLVR2]: iter 17080 Ep: 6.33 loss 0.100 score 0.397 lr 3.80031e-06 
07/28/2021 09:19:07 - INFO - volta.train_utils -   [NLVR2]: iter 17120 Ep: 6.34 loss 0.103 score 0.401 lr 3.79619e-06 
07/28/2021 09:19:28 - INFO - volta.train_utils -   [NLVR2]: iter 17160 Ep: 6.36 loss 0.121 score 0.392 lr 3.79208e-06 
07/28/2021 09:19:51 - INFO - volta.train_utils -   [NLVR2]: iter 17200 Ep: 6.37 loss 0.108 score 0.400 lr 3.78796e-06 
07/28/2021 09:20:13 - INFO - volta.train_utils -   [NLVR2]: iter 17240 Ep: 6.39 loss 0.097 score 0.405 lr 3.78385e-06 
07/28/2021 09:20:36 - INFO - volta.train_utils -   [NLVR2]: iter 17280 Ep: 6.40 loss 0.098 score 0.393 lr 3.77973e-06 
07/28/2021 09:20:58 - INFO - volta.train_utils -   [NLVR2]: iter 17320 Ep: 6.41 loss 0.112 score 0.388 lr 3.77562e-06 
07/28/2021 09:21:19 - INFO - volta.train_utils -   [NLVR2]: iter 17360 Ep: 6.43 loss 0.102 score 0.396 lr 3.7715e-06 
07/28/2021 09:21:42 - INFO - volta.train_utils -   [NLVR2]: iter 17400 Ep: 6.44 loss 0.110 score 0.389 lr 3.76739e-06 
07/28/2021 09:22:05 - INFO - volta.train_utils -   [NLVR2]: iter 17440 Ep: 6.46 loss 0.106 score 0.396 lr 3.76327e-06 
07/28/2021 09:22:28 - INFO - volta.train_utils -   [NLVR2]: iter 17480 Ep: 6.47 loss 0.101 score 0.386 lr 3.75916e-06 
07/28/2021 09:22:49 - INFO - volta.train_utils -   [NLVR2]: iter 17520 Ep: 6.49 loss 0.109 score 0.398 lr 3.75504e-06 
07/28/2021 09:23:11 - INFO - volta.train_utils -   [NLVR2]: iter 17560 Ep: 6.50 loss 0.101 score 0.396 lr 3.75093e-06 
07/28/2021 09:23:33 - INFO - volta.train_utils -   [NLVR2]: iter 17600 Ep: 6.52 loss 0.100 score 0.402 lr 3.74681e-06 
07/28/2021 09:23:56 - INFO - volta.train_utils -   [NLVR2]: iter 17640 Ep: 6.53 loss 0.112 score 0.393 lr 3.7427e-06 
07/28/2021 09:24:19 - INFO - volta.train_utils -   [NLVR2]: iter 17680 Ep: 6.55 loss 0.105 score 0.398 lr 3.73858e-06 
07/28/2021 09:24:42 - INFO - volta.train_utils -   [NLVR2]: iter 17720 Ep: 6.56 loss 0.103 score 0.402 lr 3.73447e-06 
07/28/2021 09:25:04 - INFO - volta.train_utils -   [NLVR2]: iter 17760 Ep: 6.58 loss 0.109 score 0.396 lr 3.73035e-06 
07/28/2021 09:25:28 - INFO - volta.train_utils -   [NLVR2]: iter 17800 Ep: 6.59 loss 0.100 score 0.394 lr 3.72623e-06 
07/28/2021 09:25:50 - INFO - volta.train_utils -   [NLVR2]: iter 17840 Ep: 6.61 loss 0.109 score 0.386 lr 3.72212e-06 
07/28/2021 09:26:13 - INFO - volta.train_utils -   [NLVR2]: iter 17880 Ep: 6.62 loss 0.105 score 0.391 lr 3.718e-06 
07/28/2021 09:26:36 - INFO - volta.train_utils -   [NLVR2]: iter 17920 Ep: 6.64 loss 0.103 score 0.396 lr 3.71389e-06 
07/28/2021 09:26:59 - INFO - volta.train_utils -   [NLVR2]: iter 17960 Ep: 6.65 loss 0.098 score 0.405 lr 3.70977e-06 
07/28/2021 09:27:21 - INFO - volta.train_utils -   [NLVR2]: iter 18000 Ep: 6.67 loss 0.104 score 0.392 lr 3.70566e-06 
07/28/2021 09:27:45 - INFO - volta.train_utils -   [NLVR2]: iter 18040 Ep: 6.68 loss 0.106 score 0.391 lr 3.70154e-06 
07/28/2021 09:28:09 - INFO - volta.train_utils -   [NLVR2]: iter 18080 Ep: 6.70 loss 0.099 score 0.405 lr 3.69743e-06 
07/28/2021 09:28:32 - INFO - volta.train_utils -   [NLVR2]: iter 18120 Ep: 6.71 loss 0.110 score 0.393 lr 3.69331e-06 
07/28/2021 09:28:55 - INFO - volta.train_utils -   [NLVR2]: iter 18160 Ep: 6.73 loss 0.097 score 0.404 lr 3.6892e-06 
07/28/2021 09:29:16 - INFO - volta.train_utils -   [NLVR2]: iter 18200 Ep: 6.74 loss 0.113 score 0.390 lr 3.68508e-06 
07/28/2021 09:29:40 - INFO - volta.train_utils -   [NLVR2]: iter 18240 Ep: 6.76 loss 0.107 score 0.395 lr 3.68097e-06 
07/28/2021 09:30:03 - INFO - volta.train_utils -   [NLVR2]: iter 18280 Ep: 6.77 loss 0.098 score 0.397 lr 3.67685e-06 
07/28/2021 09:30:27 - INFO - volta.train_utils -   [NLVR2]: iter 18320 Ep: 6.79 loss 0.112 score 0.385 lr 3.67274e-06 
07/28/2021 09:30:50 - INFO - volta.train_utils -   [NLVR2]: iter 18360 Ep: 6.80 loss 0.094 score 0.402 lr 3.66862e-06 
07/28/2021 09:31:13 - INFO - volta.train_utils -   [NLVR2]: iter 18400 Ep: 6.81 loss 0.104 score 0.401 lr 3.66451e-06 
07/28/2021 09:31:36 - INFO - volta.train_utils -   [NLVR2]: iter 18440 Ep: 6.83 loss 0.102 score 0.393 lr 3.66039e-06 
07/28/2021 09:32:01 - INFO - volta.train_utils -   [NLVR2]: iter 18480 Ep: 6.84 loss 0.103 score 0.395 lr 3.65628e-06 
07/28/2021 09:32:23 - INFO - volta.train_utils -   [NLVR2]: iter 18520 Ep: 6.86 loss 0.112 score 0.391 lr 3.65216e-06 
07/28/2021 09:32:47 - INFO - volta.train_utils -   [NLVR2]: iter 18560 Ep: 6.87 loss 0.112 score 0.395 lr 3.64805e-06 
07/28/2021 09:33:10 - INFO - volta.train_utils -   [NLVR2]: iter 18600 Ep: 6.89 loss 0.110 score 0.400 lr 3.64393e-06 
07/28/2021 09:33:34 - INFO - volta.train_utils -   [NLVR2]: iter 18640 Ep: 6.90 loss 0.114 score 0.381 lr 3.63981e-06 
07/28/2021 09:33:57 - INFO - volta.train_utils -   [NLVR2]: iter 18680 Ep: 6.92 loss 0.104 score 0.383 lr 3.6357e-06 
07/28/2021 09:34:21 - INFO - volta.train_utils -   [NLVR2]: iter 18720 Ep: 6.93 loss 0.097 score 0.397 lr 3.63158e-06 
07/28/2021 09:34:44 - INFO - volta.train_utils -   [NLVR2]: iter 18760 Ep: 6.95 loss 0.095 score 0.400 lr 3.62747e-06 
07/28/2021 09:35:08 - INFO - volta.train_utils -   [NLVR2]: iter 18800 Ep: 6.96 loss 0.113 score 0.384 lr 3.62335e-06 
07/28/2021 09:35:30 - INFO - volta.train_utils -   [NLVR2]: iter 18840 Ep: 6.98 loss 0.109 score 0.391 lr 3.61924e-06 
07/28/2021 09:35:54 - INFO - volta.train_utils -   [NLVR2]: iter 18880 Ep: 6.99 loss 0.108 score 0.401 lr 3.61512e-06 
07/28/2021 09:36:05 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  35%|███▌      | 7/20 [3:52:09<7:04:59, 1961.50s/it]07/28/2021 09:42:35 - INFO - volta.train_utils -   Eval task TASK12 on iteration 18900 
07/28/2021 09:42:35 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.607 score 71.527 
07/28/2021 09:42:35 - INFO - __main__ -   ** ** * Saving model * ** ** 
07/28/2021 09:43:10 - INFO - volta.train_utils -   [NLVR2]: iter 18940 Ep: 7.01 loss 0.111 score 0.390 lr 3.60998e-06 
07/28/2021 09:43:30 - INFO - volta.train_utils -   [NLVR2]: iter 18980 Ep: 7.03 loss 0.097 score 0.410 lr 3.60484e-06 
07/28/2021 09:43:50 - INFO - volta.train_utils -   [NLVR2]: iter 19020 Ep: 7.04 loss 0.102 score 0.407 lr 3.60072e-06 
07/28/2021 09:44:11 - INFO - volta.train_utils -   [NLVR2]: iter 19060 Ep: 7.06 loss 0.091 score 0.416 lr 3.5966e-06 
07/28/2021 09:44:31 - INFO - volta.train_utils -   [NLVR2]: iter 19100 Ep: 7.07 loss 0.099 score 0.411 lr 3.59249e-06 
07/28/2021 09:44:51 - INFO - volta.train_utils -   [NLVR2]: iter 19140 Ep: 7.09 loss 0.090 score 0.412 lr 3.58837e-06 
07/28/2021 09:45:13 - INFO - volta.train_utils -   [NLVR2]: iter 19180 Ep: 7.10 loss 0.091 score 0.415 lr 3.58426e-06 
07/28/2021 09:45:35 - INFO - volta.train_utils -   [NLVR2]: iter 19220 Ep: 7.12 loss 0.095 score 0.407 lr 3.58014e-06 
07/28/2021 09:45:56 - INFO - volta.train_utils -   [NLVR2]: iter 19260 Ep: 7.13 loss 0.098 score 0.411 lr 3.57603e-06 
07/28/2021 09:46:16 - INFO - volta.train_utils -   [NLVR2]: iter 19300 Ep: 7.15 loss 0.099 score 0.402 lr 3.57191e-06 
07/28/2021 09:46:38 - INFO - volta.train_utils -   [NLVR2]: iter 19340 Ep: 7.16 loss 0.102 score 0.406 lr 3.5678e-06 
07/28/2021 09:46:58 - INFO - volta.train_utils -   [NLVR2]: iter 19380 Ep: 7.18 loss 0.094 score 0.400 lr 3.56368e-06 
07/28/2021 09:47:23 - INFO - volta.train_utils -   [NLVR2]: iter 19420 Ep: 7.19 loss 0.091 score 0.410 lr 3.55957e-06 
07/28/2021 09:47:46 - INFO - volta.train_utils -   [NLVR2]: iter 19460 Ep: 7.21 loss 0.101 score 0.397 lr 3.55545e-06 
07/28/2021 09:48:06 - INFO - volta.train_utils -   [NLVR2]: iter 19500 Ep: 7.22 loss 0.090 score 0.407 lr 3.55134e-06 
07/28/2021 09:48:27 - INFO - volta.train_utils -   [NLVR2]: iter 19540 Ep: 7.24 loss 0.094 score 0.396 lr 3.54722e-06 
07/28/2021 09:48:47 - INFO - volta.train_utils -   [NLVR2]: iter 19580 Ep: 7.25 loss 0.104 score 0.408 lr 3.54311e-06 
07/28/2021 09:49:07 - INFO - volta.train_utils -   [NLVR2]: iter 19620 Ep: 7.27 loss 0.093 score 0.418 lr 3.53899e-06 
07/28/2021 09:49:30 - INFO - volta.train_utils -   [NLVR2]: iter 19660 Ep: 7.28 loss 0.096 score 0.407 lr 3.53488e-06 
07/28/2021 09:49:52 - INFO - volta.train_utils -   [NLVR2]: iter 19700 Ep: 7.30 loss 0.092 score 0.406 lr 3.53076e-06 
07/28/2021 09:50:13 - INFO - volta.train_utils -   [NLVR2]: iter 19740 Ep: 7.31 loss 0.099 score 0.409 lr 3.52665e-06 
07/28/2021 09:50:34 - INFO - volta.train_utils -   [NLVR2]: iter 19780 Ep: 7.33 loss 0.101 score 0.396 lr 3.52253e-06 
07/28/2021 09:50:56 - INFO - volta.train_utils -   [NLVR2]: iter 19820 Ep: 7.34 loss 0.098 score 0.407 lr 3.51842e-06 
07/28/2021 09:51:18 - INFO - volta.train_utils -   [NLVR2]: iter 19860 Ep: 7.36 loss 0.093 score 0.399 lr 3.5143e-06 
07/28/2021 09:51:40 - INFO - volta.train_utils -   [NLVR2]: iter 19900 Ep: 7.37 loss 0.104 score 0.396 lr 3.51019e-06 
07/28/2021 09:52:01 - INFO - volta.train_utils -   [NLVR2]: iter 19940 Ep: 7.39 loss 0.096 score 0.404 lr 3.50607e-06 
07/28/2021 09:52:25 - INFO - volta.train_utils -   [NLVR2]: iter 19980 Ep: 7.40 loss 0.099 score 0.404 lr 3.50195e-06 
07/28/2021 09:52:47 - INFO - volta.train_utils -   [NLVR2]: iter 20020 Ep: 7.41 loss 0.096 score 0.403 lr 3.49784e-06 
07/28/2021 09:53:08 - INFO - volta.train_utils -   [NLVR2]: iter 20060 Ep: 7.43 loss 0.099 score 0.398 lr 3.49372e-06 
07/28/2021 09:53:30 - INFO - volta.train_utils -   [NLVR2]: iter 20100 Ep: 7.44 loss 0.101 score 0.404 lr 3.48961e-06 
07/28/2021 09:53:52 - INFO - volta.train_utils -   [NLVR2]: iter 20140 Ep: 7.46 loss 0.093 score 0.412 lr 3.48549e-06 
07/28/2021 09:54:15 - INFO - volta.train_utils -   [NLVR2]: iter 20180 Ep: 7.47 loss 0.087 score 0.405 lr 3.48138e-06 
07/28/2021 09:54:39 - INFO - volta.train_utils -   [NLVR2]: iter 20220 Ep: 7.49 loss 0.092 score 0.406 lr 3.47726e-06 
07/28/2021 09:55:02 - INFO - volta.train_utils -   [NLVR2]: iter 20260 Ep: 7.50 loss 0.101 score 0.401 lr 3.47315e-06 
07/28/2021 09:55:24 - INFO - volta.train_utils -   [NLVR2]: iter 20300 Ep: 7.52 loss 0.108 score 0.399 lr 3.46903e-06 
07/28/2021 09:55:47 - INFO - volta.train_utils -   [NLVR2]: iter 20340 Ep: 7.53 loss 0.089 score 0.409 lr 3.46492e-06 
07/28/2021 09:56:11 - INFO - volta.train_utils -   [NLVR2]: iter 20380 Ep: 7.55 loss 0.097 score 0.415 lr 3.4608e-06 
07/28/2021 09:56:34 - INFO - volta.train_utils -   [NLVR2]: iter 20420 Ep: 7.56 loss 0.096 score 0.404 lr 3.45669e-06 
07/28/2021 09:56:56 - INFO - volta.train_utils -   [NLVR2]: iter 20460 Ep: 7.58 loss 0.093 score 0.405 lr 3.45257e-06 
07/28/2021 09:57:19 - INFO - volta.train_utils -   [NLVR2]: iter 20500 Ep: 7.59 loss 0.090 score 0.410 lr 3.44846e-06 
07/28/2021 09:57:43 - INFO - volta.train_utils -   [NLVR2]: iter 20540 Ep: 7.61 loss 0.087 score 0.416 lr 3.44434e-06 
07/28/2021 09:58:04 - INFO - volta.train_utils -   [NLVR2]: iter 20580 Ep: 7.62 loss 0.096 score 0.398 lr 3.44023e-06 
07/28/2021 09:58:28 - INFO - volta.train_utils -   [NLVR2]: iter 20620 Ep: 7.64 loss 0.094 score 0.410 lr 3.43611e-06 
07/28/2021 09:58:50 - INFO - volta.train_utils -   [NLVR2]: iter 20660 Ep: 7.65 loss 0.103 score 0.403 lr 3.432e-06 
07/28/2021 09:59:14 - INFO - volta.train_utils -   [NLVR2]: iter 20700 Ep: 7.67 loss 0.101 score 0.399 lr 3.42788e-06 
07/28/2021 09:59:36 - INFO - volta.train_utils -   [NLVR2]: iter 20740 Ep: 7.68 loss 0.092 score 0.404 lr 3.42377e-06 
07/28/2021 09:59:59 - INFO - volta.train_utils -   [NLVR2]: iter 20780 Ep: 7.70 loss 0.101 score 0.396 lr 3.41965e-06 
07/28/2021 10:00:22 - INFO - volta.train_utils -   [NLVR2]: iter 20820 Ep: 7.71 loss 0.094 score 0.405 lr 3.41553e-06 
07/28/2021 10:00:46 - INFO - volta.train_utils -   [NLVR2]: iter 20860 Ep: 7.73 loss 0.097 score 0.404 lr 3.41142e-06 
07/28/2021 10:01:10 - INFO - volta.train_utils -   [NLVR2]: iter 20900 Ep: 7.74 loss 0.100 score 0.404 lr 3.4073e-06 
07/28/2021 10:01:35 - INFO - volta.train_utils -   [NLVR2]: iter 20940 Ep: 7.76 loss 0.102 score 0.396 lr 3.40319e-06 
07/28/2021 10:01:59 - INFO - volta.train_utils -   [NLVR2]: iter 20980 Ep: 7.77 loss 0.103 score 0.395 lr 3.39907e-06 
07/28/2021 10:02:25 - INFO - volta.train_utils -   [NLVR2]: iter 21020 Ep: 7.79 loss 0.097 score 0.393 lr 3.39496e-06 
07/28/2021 10:02:49 - INFO - volta.train_utils -   [NLVR2]: iter 21060 Ep: 7.80 loss 0.096 score 0.405 lr 3.39084e-06 
07/28/2021 10:03:14 - INFO - volta.train_utils -   [NLVR2]: iter 21100 Ep: 7.81 loss 0.094 score 0.410 lr 3.38673e-06 
07/28/2021 10:03:39 - INFO - volta.train_utils -   [NLVR2]: iter 21140 Ep: 7.83 loss 0.099 score 0.402 lr 3.38261e-06 
07/28/2021 10:04:03 - INFO - volta.train_utils -   [NLVR2]: iter 21180 Ep: 7.84 loss 0.098 score 0.405 lr 3.3785e-06 
07/28/2021 10:04:27 - INFO - volta.train_utils -   [NLVR2]: iter 21220 Ep: 7.86 loss 0.101 score 0.405 lr 3.37438e-06 
07/28/2021 10:04:53 - INFO - volta.train_utils -   [NLVR2]: iter 21260 Ep: 7.87 loss 0.094 score 0.404 lr 3.37027e-06 
07/28/2021 10:05:17 - INFO - volta.train_utils -   [NLVR2]: iter 21300 Ep: 7.89 loss 0.103 score 0.397 lr 3.36615e-06 
07/28/2021 10:05:42 - INFO - volta.train_utils -   [NLVR2]: iter 21340 Ep: 7.90 loss 0.094 score 0.404 lr 3.36204e-06 
07/28/2021 10:06:05 - INFO - volta.train_utils -   [NLVR2]: iter 21380 Ep: 7.92 loss 0.093 score 0.405 lr 3.35792e-06 
07/28/2021 10:06:30 - INFO - volta.train_utils -   [NLVR2]: iter 21420 Ep: 7.93 loss 0.099 score 0.405 lr 3.35381e-06 
07/28/2021 10:06:54 - INFO - volta.train_utils -   [NLVR2]: iter 21460 Ep: 7.95 loss 0.096 score 0.408 lr 3.34969e-06 
07/28/2021 10:07:19 - INFO - volta.train_utils -   [NLVR2]: iter 21500 Ep: 7.96 loss 0.093 score 0.402 lr 3.34558e-06 
07/28/2021 10:07:41 - INFO - volta.train_utils -   [NLVR2]: iter 21540 Ep: 7.98 loss 0.099 score 0.408 lr 3.34146e-06 
07/28/2021 10:08:07 - INFO - volta.train_utils -   [NLVR2]: iter 21580 Ep: 7.99 loss 0.095 score 0.410 lr 3.33735e-06 
07/28/2021 10:08:17 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  40%|████      | 8/20 [4:24:24<6:30:41, 1953.48s/it]07/28/2021 10:15:07 - INFO - volta.train_utils -   Eval task TASK12 on iteration 21600 
07/28/2021 10:15:07 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.624 score 71.985 
07/28/2021 10:15:07 - INFO - __main__ -   ** ** * Saving model * ** ** 
07/28/2021 10:15:46 - INFO - volta.train_utils -   [NLVR2]: iter 21640 Ep: 8.01 loss 0.093 score 0.411 lr 3.3322e-06 
07/28/2021 10:16:06 - INFO - volta.train_utils -   [NLVR2]: iter 21680 Ep: 8.03 loss 0.088 score 0.424 lr 3.32706e-06 
07/28/2021 10:16:26 - INFO - volta.train_utils -   [NLVR2]: iter 21720 Ep: 8.04 loss 0.090 score 0.416 lr 3.32294e-06 
07/28/2021 10:16:47 - INFO - volta.train_utils -   [NLVR2]: iter 21760 Ep: 8.06 loss 0.083 score 0.416 lr 3.31883e-06 
07/28/2021 10:17:09 - INFO - volta.train_utils -   [NLVR2]: iter 21800 Ep: 8.07 loss 0.085 score 0.427 lr 3.31471e-06 
07/28/2021 10:17:30 - INFO - volta.train_utils -   [NLVR2]: iter 21840 Ep: 8.09 loss 0.080 score 0.424 lr 3.3106e-06 
07/28/2021 10:17:52 - INFO - volta.train_utils -   [NLVR2]: iter 21880 Ep: 8.10 loss 0.091 score 0.416 lr 3.30648e-06 
07/28/2021 10:18:25 - INFO - volta.train_utils -   [NLVR2]: iter 21920 Ep: 8.12 loss 0.096 score 0.402 lr 3.30237e-06 
07/28/2021 10:18:48 - INFO - volta.train_utils -   [NLVR2]: iter 21960 Ep: 8.13 loss 0.087 score 0.406 lr 3.29825e-06 
07/28/2021 10:19:09 - INFO - volta.train_utils -   [NLVR2]: iter 22000 Ep: 8.15 loss 0.094 score 0.413 lr 3.29414e-06 
07/28/2021 10:19:30 - INFO - volta.train_utils -   [NLVR2]: iter 22040 Ep: 8.16 loss 0.085 score 0.420 lr 3.29002e-06 
07/28/2021 10:19:53 - INFO - volta.train_utils -   [NLVR2]: iter 22080 Ep: 8.18 loss 0.090 score 0.416 lr 3.28591e-06 
07/28/2021 10:20:14 - INFO - volta.train_utils -   [NLVR2]: iter 22120 Ep: 8.19 loss 0.087 score 0.416 lr 3.28179e-06 
07/28/2021 10:20:40 - INFO - volta.train_utils -   [NLVR2]: iter 22160 Ep: 8.21 loss 0.081 score 0.423 lr 3.27767e-06 
07/28/2021 10:21:02 - INFO - volta.train_utils -   [NLVR2]: iter 22200 Ep: 8.22 loss 0.104 score 0.407 lr 3.27356e-06 
07/28/2021 10:21:23 - INFO - volta.train_utils -   [NLVR2]: iter 22240 Ep: 8.24 loss 0.094 score 0.412 lr 3.26944e-06 
07/28/2021 10:21:45 - INFO - volta.train_utils -   [NLVR2]: iter 22280 Ep: 8.25 loss 0.090 score 0.419 lr 3.26533e-06 
07/28/2021 10:22:07 - INFO - volta.train_utils -   [NLVR2]: iter 22320 Ep: 8.27 loss 0.097 score 0.416 lr 3.26121e-06 
07/28/2021 10:22:30 - INFO - volta.train_utils -   [NLVR2]: iter 22360 Ep: 8.28 loss 0.079 score 0.426 lr 3.2571e-06 
07/28/2021 10:22:54 - INFO - volta.train_utils -   [NLVR2]: iter 22400 Ep: 8.30 loss 0.085 score 0.414 lr 3.25298e-06 
07/28/2021 10:23:18 - INFO - volta.train_utils -   [NLVR2]: iter 22440 Ep: 8.31 loss 0.091 score 0.419 lr 3.24887e-06 
07/28/2021 10:23:41 - INFO - volta.train_utils -   [NLVR2]: iter 22480 Ep: 8.33 loss 0.088 score 0.415 lr 3.24475e-06 
07/28/2021 10:24:05 - INFO - volta.train_utils -   [NLVR2]: iter 22520 Ep: 8.34 loss 0.090 score 0.411 lr 3.24064e-06 
07/28/2021 10:24:27 - INFO - volta.train_utils -   [NLVR2]: iter 22560 Ep: 8.36 loss 0.090 score 0.405 lr 3.23652e-06 
07/28/2021 10:24:50 - INFO - volta.train_utils -   [NLVR2]: iter 22600 Ep: 8.37 loss 0.084 score 0.420 lr 3.23241e-06 
07/28/2021 10:25:15 - INFO - volta.train_utils -   [NLVR2]: iter 22640 Ep: 8.39 loss 0.081 score 0.421 lr 3.22829e-06 
07/28/2021 10:25:37 - INFO - volta.train_utils -   [NLVR2]: iter 22680 Ep: 8.40 loss 0.098 score 0.407 lr 3.22418e-06 
07/28/2021 10:26:00 - INFO - volta.train_utils -   [NLVR2]: iter 22720 Ep: 8.41 loss 0.094 score 0.406 lr 3.22006e-06 
07/28/2021 10:26:23 - INFO - volta.train_utils -   [NLVR2]: iter 22760 Ep: 8.43 loss 0.089 score 0.422 lr 3.21595e-06 
07/28/2021 10:26:47 - INFO - volta.train_utils -   [NLVR2]: iter 22800 Ep: 8.44 loss 0.087 score 0.417 lr 3.21183e-06 
07/28/2021 10:27:09 - INFO - volta.train_utils -   [NLVR2]: iter 22840 Ep: 8.46 loss 0.088 score 0.415 lr 3.20772e-06 
07/28/2021 10:27:35 - INFO - volta.train_utils -   [NLVR2]: iter 22880 Ep: 8.47 loss 0.086 score 0.418 lr 3.2036e-06 
07/28/2021 10:27:58 - INFO - volta.train_utils -   [NLVR2]: iter 22920 Ep: 8.49 loss 0.086 score 0.414 lr 3.19949e-06 
07/28/2021 10:28:23 - INFO - volta.train_utils -   [NLVR2]: iter 22960 Ep: 8.50 loss 0.093 score 0.406 lr 3.19537e-06 
07/28/2021 10:28:45 - INFO - volta.train_utils -   [NLVR2]: iter 23000 Ep: 8.52 loss 0.086 score 0.416 lr 3.19126e-06 
07/28/2021 10:29:09 - INFO - volta.train_utils -   [NLVR2]: iter 23040 Ep: 8.53 loss 0.087 score 0.422 lr 3.18714e-06 
07/28/2021 10:29:32 - INFO - volta.train_utils -   [NLVR2]: iter 23080 Ep: 8.55 loss 0.094 score 0.414 lr 3.18302e-06 
07/28/2021 10:29:58 - INFO - volta.train_utils -   [NLVR2]: iter 23120 Ep: 8.56 loss 0.095 score 0.411 lr 3.17891e-06 
07/28/2021 10:30:24 - INFO - volta.train_utils -   [NLVR2]: iter 23160 Ep: 8.58 loss 0.087 score 0.416 lr 3.17479e-06 
07/28/2021 10:30:48 - INFO - volta.train_utils -   [NLVR2]: iter 23200 Ep: 8.59 loss 0.078 score 0.409 lr 3.17068e-06 
07/28/2021 10:31:13 - INFO - volta.train_utils -   [NLVR2]: iter 23240 Ep: 8.61 loss 0.090 score 0.417 lr 3.16656e-06 
07/28/2021 10:31:37 - INFO - volta.train_utils -   [NLVR2]: iter 23280 Ep: 8.62 loss 0.090 score 0.411 lr 3.16245e-06 
07/28/2021 10:32:00 - INFO - volta.train_utils -   [NLVR2]: iter 23320 Ep: 8.64 loss 0.083 score 0.412 lr 3.15833e-06 
07/28/2021 10:32:26 - INFO - volta.train_utils -   [NLVR2]: iter 23360 Ep: 8.65 loss 0.089 score 0.416 lr 3.15422e-06 
07/28/2021 10:32:49 - INFO - volta.train_utils -   [NLVR2]: iter 23400 Ep: 8.67 loss 0.098 score 0.412 lr 3.1501e-06 
07/28/2021 10:33:14 - INFO - volta.train_utils -   [NLVR2]: iter 23440 Ep: 8.68 loss 0.094 score 0.414 lr 3.14599e-06 
07/28/2021 10:33:38 - INFO - volta.train_utils -   [NLVR2]: iter 23480 Ep: 8.70 loss 0.085 score 0.415 lr 3.14187e-06 
07/28/2021 10:34:04 - INFO - volta.train_utils -   [NLVR2]: iter 23520 Ep: 8.71 loss 0.091 score 0.424 lr 3.13776e-06 
07/28/2021 10:34:28 - INFO - volta.train_utils -   [NLVR2]: iter 23560 Ep: 8.73 loss 0.089 score 0.411 lr 3.13364e-06 
07/28/2021 10:34:55 - INFO - volta.train_utils -   [NLVR2]: iter 23600 Ep: 8.74 loss 0.102 score 0.401 lr 3.12953e-06 
07/28/2021 10:35:19 - INFO - volta.train_utils -   [NLVR2]: iter 23640 Ep: 8.76 loss 0.089 score 0.414 lr 3.12541e-06 
07/28/2021 10:35:45 - INFO - volta.train_utils -   [NLVR2]: iter 23680 Ep: 8.77 loss 0.092 score 0.414 lr 3.1213e-06 
07/28/2021 10:36:07 - INFO - volta.train_utils -   [NLVR2]: iter 23720 Ep: 8.79 loss 0.088 score 0.420 lr 3.11718e-06 
07/28/2021 10:36:32 - INFO - volta.train_utils -   [NLVR2]: iter 23760 Ep: 8.80 loss 0.081 score 0.425 lr 3.11307e-06 
07/28/2021 10:36:56 - INFO - volta.train_utils -   [NLVR2]: iter 23800 Ep: 8.81 loss 0.094 score 0.407 lr 3.10895e-06 
07/28/2021 10:37:22 - INFO - volta.train_utils -   [NLVR2]: iter 23840 Ep: 8.83 loss 0.093 score 0.417 lr 3.10484e-06 
07/28/2021 10:37:46 - INFO - volta.train_utils -   [NLVR2]: iter 23880 Ep: 8.84 loss 0.089 score 0.411 lr 3.10072e-06 
07/28/2021 10:38:12 - INFO - volta.train_utils -   [NLVR2]: iter 23920 Ep: 8.86 loss 0.093 score 0.409 lr 3.0966e-06 
07/28/2021 10:38:35 - INFO - volta.train_utils -   [NLVR2]: iter 23960 Ep: 8.87 loss 0.085 score 0.422 lr 3.09249e-06 
07/28/2021 10:39:00 - INFO - volta.train_utils -   [NLVR2]: iter 24000 Ep: 8.89 loss 0.096 score 0.405 lr 3.08837e-06 
07/28/2021 10:39:23 - INFO - volta.train_utils -   [NLVR2]: iter 24040 Ep: 8.90 loss 0.089 score 0.411 lr 3.08426e-06 
07/28/2021 10:39:49 - INFO - volta.train_utils -   [NLVR2]: iter 24080 Ep: 8.92 loss 0.084 score 0.421 lr 3.08014e-06 
07/28/2021 10:40:11 - INFO - volta.train_utils -   [NLVR2]: iter 24120 Ep: 8.93 loss 0.081 score 0.421 lr 3.07603e-06 
07/28/2021 10:40:37 - INFO - volta.train_utils -   [NLVR2]: iter 24160 Ep: 8.95 loss 0.080 score 0.428 lr 3.07191e-06 
07/28/2021 10:41:01 - INFO - volta.train_utils -   [NLVR2]: iter 24200 Ep: 8.96 loss 0.085 score 0.418 lr 3.0678e-06 
07/28/2021 10:41:27 - INFO - volta.train_utils -   [NLVR2]: iter 24240 Ep: 8.98 loss 0.095 score 0.409 lr 3.06368e-06 
07/28/2021 10:41:50 - INFO - volta.train_utils -   [NLVR2]: iter 24280 Ep: 8.99 loss 0.095 score 0.412 lr 3.05957e-06 
07/28/2021 10:42:01 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  45%|████▌     | 9/20 [4:58:07<6:01:57, 1974.34s/it]07/28/2021 10:48:56 - INFO - volta.train_utils -   Eval task TASK12 on iteration 24300 
07/28/2021 10:48:56 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.662 score 71.312 
07/28/2021 10:49:16 - INFO - volta.train_utils -   [NLVR2]: iter 24340 Ep: 9.01 loss 0.083 score 0.429 lr 3.05442e-06 
07/28/2021 10:49:36 - INFO - volta.train_utils -   [NLVR2]: iter 24380 Ep: 9.03 loss 0.077 score 0.429 lr 3.04928e-06 
07/28/2021 10:49:56 - INFO - volta.train_utils -   [NLVR2]: iter 24420 Ep: 9.04 loss 0.084 score 0.415 lr 3.04516e-06 
07/28/2021 10:50:17 - INFO - volta.train_utils -   [NLVR2]: iter 24460 Ep: 9.06 loss 0.088 score 0.419 lr 3.04105e-06 
07/28/2021 10:50:37 - INFO - volta.train_utils -   [NLVR2]: iter 24500 Ep: 9.07 loss 0.074 score 0.419 lr 3.03693e-06 
07/28/2021 10:50:58 - INFO - volta.train_utils -   [NLVR2]: iter 24540 Ep: 9.09 loss 0.083 score 0.432 lr 3.03282e-06 
07/28/2021 10:51:22 - INFO - volta.train_utils -   [NLVR2]: iter 24580 Ep: 9.10 loss 0.078 score 0.425 lr 3.0287e-06 
07/28/2021 10:51:47 - INFO - volta.train_utils -   [NLVR2]: iter 24620 Ep: 9.12 loss 0.081 score 0.428 lr 3.02459e-06 
07/28/2021 10:52:09 - INFO - volta.train_utils -   [NLVR2]: iter 24660 Ep: 9.13 loss 0.079 score 0.432 lr 3.02047e-06 
07/28/2021 10:52:32 - INFO - volta.train_utils -   [NLVR2]: iter 24700 Ep: 9.15 loss 0.076 score 0.426 lr 3.01636e-06 
07/28/2021 10:52:54 - INFO - volta.train_utils -   [NLVR2]: iter 24740 Ep: 9.16 loss 0.078 score 0.430 lr 3.01224e-06 
07/28/2021 10:53:16 - INFO - volta.train_utils -   [NLVR2]: iter 24780 Ep: 9.18 loss 0.086 score 0.412 lr 3.00813e-06 
07/28/2021 10:53:37 - INFO - volta.train_utils -   [NLVR2]: iter 24820 Ep: 9.19 loss 0.078 score 0.423 lr 3.00401e-06 
07/28/2021 10:54:01 - INFO - volta.train_utils -   [NLVR2]: iter 24860 Ep: 9.21 loss 0.076 score 0.432 lr 2.9999e-06 
07/28/2021 10:54:23 - INFO - volta.train_utils -   [NLVR2]: iter 24900 Ep: 9.22 loss 0.091 score 0.423 lr 2.99578e-06 
07/28/2021 10:54:45 - INFO - volta.train_utils -   [NLVR2]: iter 24940 Ep: 9.24 loss 0.083 score 0.419 lr 2.99167e-06 
07/28/2021 10:55:08 - INFO - volta.train_utils -   [NLVR2]: iter 24980 Ep: 9.25 loss 0.083 score 0.421 lr 2.98755e-06 
07/28/2021 10:55:30 - INFO - volta.train_utils -   [NLVR2]: iter 25020 Ep: 9.27 loss 0.077 score 0.428 lr 2.98344e-06 
07/28/2021 10:55:51 - INFO - volta.train_utils -   [NLVR2]: iter 25060 Ep: 9.28 loss 0.079 score 0.427 lr 2.97932e-06 
07/28/2021 10:56:15 - INFO - volta.train_utils -   [NLVR2]: iter 25100 Ep: 9.30 loss 0.093 score 0.425 lr 2.97521e-06 
07/28/2021 10:56:39 - INFO - volta.train_utils -   [NLVR2]: iter 25140 Ep: 9.31 loss 0.095 score 0.415 lr 2.97109e-06 
07/28/2021 10:57:01 - INFO - volta.train_utils -   [NLVR2]: iter 25180 Ep: 9.33 loss 0.084 score 0.425 lr 2.96698e-06 
07/28/2021 10:57:24 - INFO - volta.train_utils -   [NLVR2]: iter 25220 Ep: 9.34 loss 0.080 score 0.424 lr 2.96286e-06 
07/28/2021 10:57:46 - INFO - volta.train_utils -   [NLVR2]: iter 25260 Ep: 9.36 loss 0.084 score 0.421 lr 2.95874e-06 
07/28/2021 10:58:06 - INFO - volta.train_utils -   [NLVR2]: iter 25300 Ep: 9.37 loss 0.077 score 0.420 lr 2.95463e-06 
07/28/2021 10:58:31 - INFO - volta.train_utils -   [NLVR2]: iter 25340 Ep: 9.39 loss 0.075 score 0.423 lr 2.95051e-06 
07/28/2021 10:58:54 - INFO - volta.train_utils -   [NLVR2]: iter 25380 Ep: 9.40 loss 0.076 score 0.422 lr 2.9464e-06 
07/28/2021 10:59:17 - INFO - volta.train_utils -   [NLVR2]: iter 25420 Ep: 9.41 loss 0.090 score 0.418 lr 2.94228e-06 
07/28/2021 10:59:40 - INFO - volta.train_utils -   [NLVR2]: iter 25460 Ep: 9.43 loss 0.080 score 0.422 lr 2.93817e-06 
07/28/2021 11:00:04 - INFO - volta.train_utils -   [NLVR2]: iter 25500 Ep: 9.44 loss 0.087 score 0.419 lr 2.93405e-06 
07/28/2021 11:00:27 - INFO - volta.train_utils -   [NLVR2]: iter 25540 Ep: 9.46 loss 0.089 score 0.423 lr 2.92994e-06 
07/28/2021 11:00:52 - INFO - volta.train_utils -   [NLVR2]: iter 25580 Ep: 9.47 loss 0.084 score 0.414 lr 2.92582e-06 
07/28/2021 11:01:14 - INFO - volta.train_utils -   [NLVR2]: iter 25620 Ep: 9.49 loss 0.077 score 0.433 lr 2.92171e-06 
07/28/2021 11:01:37 - INFO - volta.train_utils -   [NLVR2]: iter 25660 Ep: 9.50 loss 0.093 score 0.416 lr 2.91759e-06 
07/28/2021 11:02:02 - INFO - volta.train_utils -   [NLVR2]: iter 25700 Ep: 9.52 loss 0.092 score 0.422 lr 2.91348e-06 
07/28/2021 11:02:26 - INFO - volta.train_utils -   [NLVR2]: iter 25740 Ep: 9.53 loss 0.088 score 0.421 lr 2.90936e-06 
07/28/2021 11:02:49 - INFO - volta.train_utils -   [NLVR2]: iter 25780 Ep: 9.55 loss 0.075 score 0.420 lr 2.90525e-06 
07/28/2021 11:03:16 - INFO - volta.train_utils -   [NLVR2]: iter 25820 Ep: 9.56 loss 0.084 score 0.427 lr 2.90113e-06 
07/28/2021 11:03:40 - INFO - volta.train_utils -   [NLVR2]: iter 25860 Ep: 9.58 loss 0.088 score 0.419 lr 2.89702e-06 
07/28/2021 11:04:06 - INFO - volta.train_utils -   [NLVR2]: iter 25900 Ep: 9.59 loss 0.076 score 0.424 lr 2.8929e-06 
07/28/2021 11:04:30 - INFO - volta.train_utils -   [NLVR2]: iter 25940 Ep: 9.61 loss 0.089 score 0.416 lr 2.88879e-06 
07/28/2021 11:04:55 - INFO - volta.train_utils -   [NLVR2]: iter 25980 Ep: 9.62 loss 0.090 score 0.425 lr 2.88467e-06 
07/28/2021 11:05:18 - INFO - volta.train_utils -   [NLVR2]: iter 26020 Ep: 9.64 loss 0.076 score 0.432 lr 2.88056e-06 
07/28/2021 11:05:44 - INFO - volta.train_utils -   [NLVR2]: iter 26060 Ep: 9.65 loss 0.087 score 0.418 lr 2.87644e-06 
07/28/2021 11:06:08 - INFO - volta.train_utils -   [NLVR2]: iter 26100 Ep: 9.67 loss 0.087 score 0.419 lr 2.87233e-06 
07/28/2021 11:06:33 - INFO - volta.train_utils -   [NLVR2]: iter 26140 Ep: 9.68 loss 0.077 score 0.428 lr 2.86821e-06 
07/28/2021 11:06:56 - INFO - volta.train_utils -   [NLVR2]: iter 26180 Ep: 9.70 loss 0.086 score 0.421 lr 2.86409e-06 
07/28/2021 11:07:20 - INFO - volta.train_utils -   [NLVR2]: iter 26220 Ep: 9.71 loss 0.085 score 0.419 lr 2.85998e-06 
07/28/2021 11:07:44 - INFO - volta.train_utils -   [NLVR2]: iter 26260 Ep: 9.73 loss 0.089 score 0.425 lr 2.85586e-06 
07/28/2021 11:08:09 - INFO - volta.train_utils -   [NLVR2]: iter 26300 Ep: 9.74 loss 0.081 score 0.422 lr 2.85175e-06 
07/28/2021 11:08:32 - INFO - volta.train_utils -   [NLVR2]: iter 26340 Ep: 9.76 loss 0.080 score 0.417 lr 2.84763e-06 
07/28/2021 11:08:57 - INFO - volta.train_utils -   [NLVR2]: iter 26380 Ep: 9.77 loss 0.081 score 0.418 lr 2.84352e-06 
07/28/2021 11:09:21 - INFO - volta.train_utils -   [NLVR2]: iter 26420 Ep: 9.79 loss 0.082 score 0.418 lr 2.8394e-06 
07/28/2021 11:09:47 - INFO - volta.train_utils -   [NLVR2]: iter 26460 Ep: 9.80 loss 0.079 score 0.419 lr 2.83529e-06 
07/28/2021 11:10:10 - INFO - volta.train_utils -   [NLVR2]: iter 26500 Ep: 9.81 loss 0.086 score 0.415 lr 2.83117e-06 
07/28/2021 11:10:36 - INFO - volta.train_utils -   [NLVR2]: iter 26540 Ep: 9.83 loss 0.085 score 0.411 lr 2.82706e-06 
07/28/2021 11:11:00 - INFO - volta.train_utils -   [NLVR2]: iter 26580 Ep: 9.84 loss 0.085 score 0.420 lr 2.82294e-06 
07/28/2021 11:11:25 - INFO - volta.train_utils -   [NLVR2]: iter 26620 Ep: 9.86 loss 0.088 score 0.422 lr 2.81883e-06 
07/28/2021 11:11:49 - INFO - volta.train_utils -   [NLVR2]: iter 26660 Ep: 9.87 loss 0.089 score 0.418 lr 2.81471e-06 
07/28/2021 11:12:15 - INFO - volta.train_utils -   [NLVR2]: iter 26700 Ep: 9.89 loss 0.083 score 0.425 lr 2.8106e-06 
07/28/2021 11:12:39 - INFO - volta.train_utils -   [NLVR2]: iter 26740 Ep: 9.90 loss 0.081 score 0.417 lr 2.80648e-06 
07/28/2021 11:13:04 - INFO - volta.train_utils -   [NLVR2]: iter 26780 Ep: 9.92 loss 0.081 score 0.427 lr 2.80237e-06 
07/28/2021 11:13:28 - INFO - volta.train_utils -   [NLVR2]: iter 26820 Ep: 9.93 loss 0.085 score 0.421 lr 2.79825e-06 
07/28/2021 11:13:53 - INFO - volta.train_utils -   [NLVR2]: iter 26860 Ep: 9.95 loss 0.076 score 0.425 lr 2.79414e-06 
07/28/2021 11:14:18 - INFO - volta.train_utils -   [NLVR2]: iter 26900 Ep: 9.96 loss 0.090 score 0.419 lr 2.79002e-06 
07/28/2021 11:14:42 - INFO - volta.train_utils -   [NLVR2]: iter 26940 Ep: 9.98 loss 0.082 score 0.414 lr 2.78591e-06 
07/28/2021 11:15:05 - INFO - volta.train_utils -   [NLVR2]: iter 26980 Ep: 9.99 loss 0.079 score 0.420 lr 2.78179e-06 
07/28/2021 11:15:16 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  50%|█████     | 10/20 [5:31:23<5:30:10, 1981.00s/it]07/28/2021 11:22:16 - INFO - volta.train_utils -   Eval task TASK12 on iteration 27000 
07/28/2021 11:22:16 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.685 score 71.985 
07/28/2021 11:22:36 - INFO - volta.train_utils -   [NLVR2]: iter 27040 Ep: 10.01 loss 0.076 score 0.423 lr 2.77665e-06 
07/28/2021 11:22:56 - INFO - volta.train_utils -   [NLVR2]: iter 27080 Ep: 10.03 loss 0.071 score 0.424 lr 2.7715e-06 
07/28/2021 11:23:16 - INFO - volta.train_utils -   [NLVR2]: iter 27120 Ep: 10.04 loss 0.074 score 0.438 lr 2.76739e-06 
07/28/2021 11:23:37 - INFO - volta.train_utils -   [NLVR2]: iter 27160 Ep: 10.06 loss 0.073 score 0.423 lr 2.76327e-06 
07/28/2021 11:23:59 - INFO - volta.train_utils -   [NLVR2]: iter 27200 Ep: 10.07 loss 0.074 score 0.428 lr 2.75916e-06 
07/28/2021 11:24:23 - INFO - volta.train_utils -   [NLVR2]: iter 27240 Ep: 10.09 loss 0.064 score 0.441 lr 2.75504e-06 
07/28/2021 11:24:48 - INFO - volta.train_utils -   [NLVR2]: iter 27280 Ep: 10.10 loss 0.067 score 0.437 lr 2.75093e-06 
07/28/2021 11:25:13 - INFO - volta.train_utils -   [NLVR2]: iter 27320 Ep: 10.12 loss 0.078 score 0.425 lr 2.74681e-06 
07/28/2021 11:25:33 - INFO - volta.train_utils -   [NLVR2]: iter 27360 Ep: 10.13 loss 0.073 score 0.430 lr 2.7427e-06 
07/28/2021 11:25:56 - INFO - volta.train_utils -   [NLVR2]: iter 27400 Ep: 10.15 loss 0.083 score 0.429 lr 2.73858e-06 
07/28/2021 11:26:17 - INFO - volta.train_utils -   [NLVR2]: iter 27440 Ep: 10.16 loss 0.078 score 0.418 lr 2.73447e-06 
07/28/2021 11:26:40 - INFO - volta.train_utils -   [NLVR2]: iter 27480 Ep: 10.18 loss 0.080 score 0.427 lr 2.73035e-06 
07/28/2021 11:27:03 - INFO - volta.train_utils -   [NLVR2]: iter 27520 Ep: 10.19 loss 0.080 score 0.423 lr 2.72623e-06 
07/28/2021 11:27:27 - INFO - volta.train_utils -   [NLVR2]: iter 27560 Ep: 10.21 loss 0.073 score 0.427 lr 2.72212e-06 
07/28/2021 11:27:50 - INFO - volta.train_utils -   [NLVR2]: iter 27600 Ep: 10.22 loss 0.076 score 0.426 lr 2.718e-06 
07/28/2021 11:28:11 - INFO - volta.train_utils -   [NLVR2]: iter 27640 Ep: 10.24 loss 0.077 score 0.434 lr 2.71389e-06 
07/28/2021 11:28:32 - INFO - volta.train_utils -   [NLVR2]: iter 27680 Ep: 10.25 loss 0.070 score 0.436 lr 2.70977e-06 
07/28/2021 11:28:53 - INFO - volta.train_utils -   [NLVR2]: iter 27720 Ep: 10.27 loss 0.076 score 0.429 lr 2.70566e-06 
07/28/2021 11:29:15 - INFO - volta.train_utils -   [NLVR2]: iter 27760 Ep: 10.28 loss 0.075 score 0.432 lr 2.70154e-06 
07/28/2021 11:29:41 - INFO - volta.train_utils -   [NLVR2]: iter 27800 Ep: 10.30 loss 0.074 score 0.427 lr 2.69743e-06 
07/28/2021 11:30:04 - INFO - volta.train_utils -   [NLVR2]: iter 27840 Ep: 10.31 loss 0.073 score 0.434 lr 2.69331e-06 
07/28/2021 11:30:26 - INFO - volta.train_utils -   [NLVR2]: iter 27880 Ep: 10.33 loss 0.077 score 0.424 lr 2.6892e-06 
07/28/2021 11:30:48 - INFO - volta.train_utils -   [NLVR2]: iter 27920 Ep: 10.34 loss 0.072 score 0.430 lr 2.68508e-06 
07/28/2021 11:31:12 - INFO - volta.train_utils -   [NLVR2]: iter 27960 Ep: 10.36 loss 0.070 score 0.429 lr 2.68097e-06 
07/28/2021 11:31:35 - INFO - volta.train_utils -   [NLVR2]: iter 28000 Ep: 10.37 loss 0.082 score 0.431 lr 2.67685e-06 
07/28/2021 11:31:59 - INFO - volta.train_utils -   [NLVR2]: iter 28040 Ep: 10.39 loss 0.076 score 0.432 lr 2.67274e-06 
07/28/2021 11:32:23 - INFO - volta.train_utils -   [NLVR2]: iter 28080 Ep: 10.40 loss 0.064 score 0.439 lr 2.66862e-06 
07/28/2021 11:32:46 - INFO - volta.train_utils -   [NLVR2]: iter 28120 Ep: 10.41 loss 0.066 score 0.441 lr 2.66451e-06 
07/28/2021 11:33:10 - INFO - volta.train_utils -   [NLVR2]: iter 28160 Ep: 10.43 loss 0.078 score 0.423 lr 2.66039e-06 
07/28/2021 11:33:33 - INFO - volta.train_utils -   [NLVR2]: iter 28200 Ep: 10.44 loss 0.072 score 0.439 lr 2.65628e-06 
07/28/2021 11:33:55 - INFO - volta.train_utils -   [NLVR2]: iter 28240 Ep: 10.46 loss 0.079 score 0.429 lr 2.65216e-06 
07/28/2021 11:34:18 - INFO - volta.train_utils -   [NLVR2]: iter 28280 Ep: 10.47 loss 0.078 score 0.425 lr 2.64805e-06 
07/28/2021 11:34:42 - INFO - volta.train_utils -   [NLVR2]: iter 28320 Ep: 10.49 loss 0.073 score 0.428 lr 2.64393e-06 
07/28/2021 11:35:06 - INFO - volta.train_utils -   [NLVR2]: iter 28360 Ep: 10.50 loss 0.066 score 0.437 lr 2.63981e-06 
07/28/2021 11:35:30 - INFO - volta.train_utils -   [NLVR2]: iter 28400 Ep: 10.52 loss 0.075 score 0.436 lr 2.6357e-06 
07/28/2021 11:35:54 - INFO - volta.train_utils -   [NLVR2]: iter 28440 Ep: 10.53 loss 0.075 score 0.431 lr 2.63158e-06 
07/28/2021 11:36:18 - INFO - volta.train_utils -   [NLVR2]: iter 28480 Ep: 10.55 loss 0.070 score 0.427 lr 2.62747e-06 
07/28/2021 11:36:43 - INFO - volta.train_utils -   [NLVR2]: iter 28520 Ep: 10.56 loss 0.080 score 0.429 lr 2.62335e-06 
07/28/2021 11:37:07 - INFO - volta.train_utils -   [NLVR2]: iter 28560 Ep: 10.58 loss 0.084 score 0.418 lr 2.61924e-06 
07/28/2021 11:37:32 - INFO - volta.train_utils -   [NLVR2]: iter 28600 Ep: 10.59 loss 0.070 score 0.435 lr 2.61512e-06 
07/28/2021 11:37:55 - INFO - volta.train_utils -   [NLVR2]: iter 28640 Ep: 10.61 loss 0.079 score 0.432 lr 2.61101e-06 
07/28/2021 11:38:19 - INFO - volta.train_utils -   [NLVR2]: iter 28680 Ep: 10.62 loss 0.081 score 0.431 lr 2.60689e-06 
07/28/2021 11:38:43 - INFO - volta.train_utils -   [NLVR2]: iter 28720 Ep: 10.64 loss 0.083 score 0.423 lr 2.60278e-06 
07/28/2021 11:39:08 - INFO - volta.train_utils -   [NLVR2]: iter 28760 Ep: 10.65 loss 0.080 score 0.426 lr 2.59866e-06 
07/28/2021 11:39:32 - INFO - volta.train_utils -   [NLVR2]: iter 28800 Ep: 10.67 loss 0.076 score 0.432 lr 2.59455e-06 
07/28/2021 11:39:56 - INFO - volta.train_utils -   [NLVR2]: iter 28840 Ep: 10.68 loss 0.078 score 0.438 lr 2.59043e-06 
07/28/2021 11:40:21 - INFO - volta.train_utils -   [NLVR2]: iter 28880 Ep: 10.70 loss 0.075 score 0.434 lr 2.58632e-06 
07/28/2021 11:40:45 - INFO - volta.train_utils -   [NLVR2]: iter 28920 Ep: 10.71 loss 0.079 score 0.431 lr 2.5822e-06 
07/28/2021 11:41:10 - INFO - volta.train_utils -   [NLVR2]: iter 28960 Ep: 10.73 loss 0.087 score 0.417 lr 2.57809e-06 
07/28/2021 11:41:33 - INFO - volta.train_utils -   [NLVR2]: iter 29000 Ep: 10.74 loss 0.075 score 0.431 lr 2.57397e-06 
07/28/2021 11:41:59 - INFO - volta.train_utils -   [NLVR2]: iter 29040 Ep: 10.76 loss 0.080 score 0.435 lr 2.56986e-06 
07/28/2021 11:42:23 - INFO - volta.train_utils -   [NLVR2]: iter 29080 Ep: 10.77 loss 0.085 score 0.429 lr 2.56574e-06 
07/28/2021 11:42:49 - INFO - volta.train_utils -   [NLVR2]: iter 29120 Ep: 10.79 loss 0.083 score 0.421 lr 2.56163e-06 
07/28/2021 11:43:14 - INFO - volta.train_utils -   [NLVR2]: iter 29160 Ep: 10.80 loss 0.073 score 0.430 lr 2.55751e-06 
07/28/2021 11:43:40 - INFO - volta.train_utils -   [NLVR2]: iter 29200 Ep: 10.81 loss 0.069 score 0.430 lr 2.5534e-06 
07/28/2021 11:44:03 - INFO - volta.train_utils -   [NLVR2]: iter 29240 Ep: 10.83 loss 0.079 score 0.430 lr 2.54928e-06 
07/28/2021 11:44:27 - INFO - volta.train_utils -   [NLVR2]: iter 29280 Ep: 10.84 loss 0.082 score 0.420 lr 2.54516e-06 
07/28/2021 11:44:50 - INFO - volta.train_utils -   [NLVR2]: iter 29320 Ep: 10.86 loss 0.075 score 0.430 lr 2.54105e-06 
07/28/2021 11:45:14 - INFO - volta.train_utils -   [NLVR2]: iter 29360 Ep: 10.87 loss 0.085 score 0.427 lr 2.53693e-06 
07/28/2021 11:45:38 - INFO - volta.train_utils -   [NLVR2]: iter 29400 Ep: 10.89 loss 0.080 score 0.425 lr 2.53282e-06 
07/28/2021 11:46:04 - INFO - volta.train_utils -   [NLVR2]: iter 29440 Ep: 10.90 loss 0.079 score 0.429 lr 2.5287e-06 
07/28/2021 11:46:28 - INFO - volta.train_utils -   [NLVR2]: iter 29480 Ep: 10.92 loss 0.073 score 0.434 lr 2.52459e-06 
07/28/2021 11:46:52 - INFO - volta.train_utils -   [NLVR2]: iter 29520 Ep: 10.93 loss 0.074 score 0.425 lr 2.52047e-06 
07/28/2021 11:47:16 - INFO - volta.train_utils -   [NLVR2]: iter 29560 Ep: 10.95 loss 0.082 score 0.424 lr 2.51636e-06 
07/28/2021 11:47:41 - INFO - volta.train_utils -   [NLVR2]: iter 29600 Ep: 10.96 loss 0.073 score 0.430 lr 2.51224e-06 
07/28/2021 11:48:04 - INFO - volta.train_utils -   [NLVR2]: iter 29640 Ep: 10.98 loss 0.077 score 0.431 lr 2.50813e-06 
07/28/2021 11:48:28 - INFO - volta.train_utils -   [NLVR2]: iter 29680 Ep: 10.99 loss 0.081 score 0.430 lr 2.50401e-06 
07/28/2021 11:48:39 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  55%|█████▌    | 11/20 [6:04:48<4:58:12, 1988.11s/it]07/28/2021 11:55:41 - INFO - volta.train_utils -   Eval task TASK12 on iteration 29700 
07/28/2021 11:55:41 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.748 score 71.111 
07/28/2021 11:56:01 - INFO - volta.train_utils -   [NLVR2]: iter 29740 Ep: 11.01 loss 0.069 score 0.435 lr 2.49887e-06 
07/28/2021 11:56:21 - INFO - volta.train_utils -   [NLVR2]: iter 29780 Ep: 11.03 loss 0.065 score 0.442 lr 2.49372e-06 
07/28/2021 11:56:41 - INFO - volta.train_utils -   [NLVR2]: iter 29820 Ep: 11.04 loss 0.066 score 0.439 lr 2.48961e-06 
07/28/2021 11:57:02 - INFO - volta.train_utils -   [NLVR2]: iter 29860 Ep: 11.06 loss 0.073 score 0.432 lr 2.48549e-06 
07/28/2021 11:57:22 - INFO - volta.train_utils -   [NLVR2]: iter 29900 Ep: 11.07 loss 0.074 score 0.436 lr 2.48138e-06 
07/28/2021 11:57:46 - INFO - volta.train_utils -   [NLVR2]: iter 29940 Ep: 11.09 loss 0.063 score 0.441 lr 2.47726e-06 
07/28/2021 11:58:09 - INFO - volta.train_utils -   [NLVR2]: iter 29980 Ep: 11.10 loss 0.066 score 0.439 lr 2.47315e-06 
07/28/2021 11:58:35 - INFO - volta.train_utils -   [NLVR2]: iter 30020 Ep: 11.12 loss 0.070 score 0.438 lr 2.46903e-06 
07/28/2021 11:58:56 - INFO - volta.train_utils -   [NLVR2]: iter 30060 Ep: 11.13 loss 0.069 score 0.433 lr 2.46492e-06 
07/28/2021 11:59:17 - INFO - volta.train_utils -   [NLVR2]: iter 30100 Ep: 11.15 loss 0.067 score 0.444 lr 2.4608e-06 
07/28/2021 11:59:40 - INFO - volta.train_utils -   [NLVR2]: iter 30140 Ep: 11.16 loss 0.069 score 0.429 lr 2.45669e-06 
07/28/2021 12:00:00 - INFO - volta.train_utils -   [NLVR2]: iter 30180 Ep: 11.18 loss 0.067 score 0.438 lr 2.45257e-06 
07/28/2021 12:00:22 - INFO - volta.train_utils -   [NLVR2]: iter 30220 Ep: 11.19 loss 0.070 score 0.439 lr 2.44846e-06 
07/28/2021 12:00:46 - INFO - volta.train_utils -   [NLVR2]: iter 30260 Ep: 11.21 loss 0.067 score 0.431 lr 2.44434e-06 
07/28/2021 12:01:08 - INFO - volta.train_utils -   [NLVR2]: iter 30300 Ep: 11.22 loss 0.068 score 0.443 lr 2.44023e-06 
07/28/2021 12:01:29 - INFO - volta.train_utils -   [NLVR2]: iter 30340 Ep: 11.24 loss 0.078 score 0.432 lr 2.43611e-06 
07/28/2021 12:01:51 - INFO - volta.train_utils -   [NLVR2]: iter 30380 Ep: 11.25 loss 0.075 score 0.433 lr 2.432e-06 
07/28/2021 12:02:14 - INFO - volta.train_utils -   [NLVR2]: iter 30420 Ep: 11.27 loss 0.070 score 0.441 lr 2.42788e-06 
07/28/2021 12:02:36 - INFO - volta.train_utils -   [NLVR2]: iter 30460 Ep: 11.28 loss 0.073 score 0.439 lr 2.42377e-06 
07/28/2021 12:03:00 - INFO - volta.train_utils -   [NLVR2]: iter 30500 Ep: 11.30 loss 0.078 score 0.434 lr 2.41965e-06 
07/28/2021 12:03:22 - INFO - volta.train_utils -   [NLVR2]: iter 30540 Ep: 11.31 loss 0.072 score 0.435 lr 2.41553e-06 
07/28/2021 12:03:45 - INFO - volta.train_utils -   [NLVR2]: iter 30580 Ep: 11.33 loss 0.066 score 0.434 lr 2.41142e-06 
07/28/2021 12:04:07 - INFO - volta.train_utils -   [NLVR2]: iter 30620 Ep: 11.34 loss 0.071 score 0.438 lr 2.4073e-06 
07/28/2021 12:04:30 - INFO - volta.train_utils -   [NLVR2]: iter 30660 Ep: 11.36 loss 0.071 score 0.436 lr 2.40319e-06 
07/28/2021 12:04:52 - INFO - volta.train_utils -   [NLVR2]: iter 30700 Ep: 11.37 loss 0.068 score 0.438 lr 2.39907e-06 
07/28/2021 12:05:15 - INFO - volta.train_utils -   [NLVR2]: iter 30740 Ep: 11.39 loss 0.067 score 0.439 lr 2.39496e-06 
07/28/2021 12:05:38 - INFO - volta.train_utils -   [NLVR2]: iter 30780 Ep: 11.40 loss 0.075 score 0.434 lr 2.39084e-06 
07/28/2021 12:06:04 - INFO - volta.train_utils -   [NLVR2]: iter 30820 Ep: 11.41 loss 0.073 score 0.438 lr 2.38673e-06 
07/28/2021 12:06:24 - INFO - volta.train_utils -   [NLVR2]: iter 30860 Ep: 11.43 loss 0.062 score 0.433 lr 2.38261e-06 
07/28/2021 12:06:50 - INFO - volta.train_utils -   [NLVR2]: iter 30900 Ep: 11.44 loss 0.073 score 0.440 lr 2.3785e-06 
07/28/2021 12:07:12 - INFO - volta.train_utils -   [NLVR2]: iter 30940 Ep: 11.46 loss 0.069 score 0.435 lr 2.37438e-06 
07/28/2021 12:07:38 - INFO - volta.train_utils -   [NLVR2]: iter 30980 Ep: 11.47 loss 0.064 score 0.440 lr 2.37027e-06 
07/28/2021 12:08:01 - INFO - volta.train_utils -   [NLVR2]: iter 31020 Ep: 11.49 loss 0.059 score 0.443 lr 2.36615e-06 
07/28/2021 12:08:23 - INFO - volta.train_utils -   [NLVR2]: iter 31060 Ep: 11.50 loss 0.068 score 0.440 lr 2.36204e-06 
07/28/2021 12:08:47 - INFO - volta.train_utils -   [NLVR2]: iter 31100 Ep: 11.52 loss 0.067 score 0.441 lr 2.35792e-06 
07/28/2021 12:09:12 - INFO - volta.train_utils -   [NLVR2]: iter 31140 Ep: 11.53 loss 0.075 score 0.427 lr 2.35381e-06 
07/28/2021 12:09:34 - INFO - volta.train_utils -   [NLVR2]: iter 31180 Ep: 11.55 loss 0.073 score 0.435 lr 2.34969e-06 
07/28/2021 12:09:57 - INFO - volta.train_utils -   [NLVR2]: iter 31220 Ep: 11.56 loss 0.069 score 0.434 lr 2.34558e-06 
07/28/2021 12:10:22 - INFO - volta.train_utils -   [NLVR2]: iter 31260 Ep: 11.58 loss 0.074 score 0.433 lr 2.34146e-06 
07/28/2021 12:10:44 - INFO - volta.train_utils -   [NLVR2]: iter 31300 Ep: 11.59 loss 0.068 score 0.437 lr 2.33735e-06 
07/28/2021 12:11:07 - INFO - volta.train_utils -   [NLVR2]: iter 31340 Ep: 11.61 loss 0.073 score 0.434 lr 2.33323e-06 
07/28/2021 12:11:32 - INFO - volta.train_utils -   [NLVR2]: iter 31380 Ep: 11.62 loss 0.067 score 0.427 lr 2.32912e-06 
07/28/2021 12:11:57 - INFO - volta.train_utils -   [NLVR2]: iter 31420 Ep: 11.64 loss 0.076 score 0.434 lr 2.325e-06 
07/28/2021 12:12:21 - INFO - volta.train_utils -   [NLVR2]: iter 31460 Ep: 11.65 loss 0.074 score 0.438 lr 2.32088e-06 
07/28/2021 12:12:45 - INFO - volta.train_utils -   [NLVR2]: iter 31500 Ep: 11.67 loss 0.073 score 0.427 lr 2.31677e-06 
07/28/2021 12:13:07 - INFO - volta.train_utils -   [NLVR2]: iter 31540 Ep: 11.68 loss 0.067 score 0.432 lr 2.31265e-06 
07/28/2021 12:13:31 - INFO - volta.train_utils -   [NLVR2]: iter 31580 Ep: 11.70 loss 0.080 score 0.436 lr 2.30854e-06 
07/28/2021 12:13:56 - INFO - volta.train_utils -   [NLVR2]: iter 31620 Ep: 11.71 loss 0.065 score 0.437 lr 2.30442e-06 
07/28/2021 12:14:20 - INFO - volta.train_utils -   [NLVR2]: iter 31660 Ep: 11.73 loss 0.071 score 0.438 lr 2.30031e-06 
07/28/2021 12:14:44 - INFO - volta.train_utils -   [NLVR2]: iter 31700 Ep: 11.74 loss 0.067 score 0.436 lr 2.29619e-06 
07/28/2021 12:15:09 - INFO - volta.train_utils -   [NLVR2]: iter 31740 Ep: 11.76 loss 0.060 score 0.437 lr 2.29208e-06 
07/28/2021 12:15:32 - INFO - volta.train_utils -   [NLVR2]: iter 31780 Ep: 11.77 loss 0.079 score 0.433 lr 2.28796e-06 
07/28/2021 12:15:56 - INFO - volta.train_utils -   [NLVR2]: iter 31820 Ep: 11.79 loss 0.072 score 0.436 lr 2.28385e-06 
07/28/2021 12:16:17 - INFO - volta.train_utils -   [NLVR2]: iter 31860 Ep: 11.80 loss 0.065 score 0.436 lr 2.27973e-06 
07/28/2021 12:16:41 - INFO - volta.train_utils -   [NLVR2]: iter 31900 Ep: 11.81 loss 0.073 score 0.430 lr 2.27562e-06 
07/28/2021 12:17:04 - INFO - volta.train_utils -   [NLVR2]: iter 31940 Ep: 11.83 loss 0.068 score 0.436 lr 2.2715e-06 
07/28/2021 12:17:28 - INFO - volta.train_utils -   [NLVR2]: iter 31980 Ep: 11.84 loss 0.075 score 0.427 lr 2.26739e-06 
07/28/2021 12:17:53 - INFO - volta.train_utils -   [NLVR2]: iter 32020 Ep: 11.86 loss 0.066 score 0.439 lr 2.26327e-06 
07/28/2021 12:18:17 - INFO - volta.train_utils -   [NLVR2]: iter 32060 Ep: 11.87 loss 0.068 score 0.432 lr 2.25916e-06 
07/28/2021 12:18:39 - INFO - volta.train_utils -   [NLVR2]: iter 32100 Ep: 11.89 loss 0.072 score 0.439 lr 2.25504e-06 
07/28/2021 12:19:04 - INFO - volta.train_utils -   [NLVR2]: iter 32140 Ep: 11.90 loss 0.064 score 0.437 lr 2.25093e-06 
07/28/2021 12:19:27 - INFO - volta.train_utils -   [NLVR2]: iter 32180 Ep: 11.92 loss 0.073 score 0.429 lr 2.24681e-06 
07/28/2021 12:19:51 - INFO - volta.train_utils -   [NLVR2]: iter 32220 Ep: 11.93 loss 0.076 score 0.426 lr 2.2427e-06 
07/28/2021 12:20:15 - INFO - volta.train_utils -   [NLVR2]: iter 32260 Ep: 11.95 loss 0.067 score 0.441 lr 2.23858e-06 
07/28/2021 12:20:40 - INFO - volta.train_utils -   [NLVR2]: iter 32300 Ep: 11.96 loss 0.065 score 0.437 lr 2.23447e-06 
07/28/2021 12:21:04 - INFO - volta.train_utils -   [NLVR2]: iter 32340 Ep: 11.98 loss 0.065 score 0.439 lr 2.23035e-06 
07/28/2021 12:21:27 - INFO - volta.train_utils -   [NLVR2]: iter 32380 Ep: 11.99 loss 0.071 score 0.428 lr 2.22623e-06 
07/28/2021 12:21:38 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  60%|██████    | 12/20 [6:37:43<4:24:34, 1984.27s/it]07/28/2021 12:28:23 - INFO - volta.train_utils -   Eval task TASK12 on iteration 32400 
07/28/2021 12:28:23 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.776 score 71.369 
07/28/2021 12:28:43 - INFO - volta.train_utils -   [NLVR2]: iter 32440 Ep: 12.01 loss 0.060 score 0.447 lr 2.22109e-06 
07/28/2021 12:29:03 - INFO - volta.train_utils -   [NLVR2]: iter 32480 Ep: 12.03 loss 0.064 score 0.444 lr 2.21595e-06 
07/28/2021 12:29:23 - INFO - volta.train_utils -   [NLVR2]: iter 32520 Ep: 12.04 loss 0.063 score 0.447 lr 2.21183e-06 
07/28/2021 12:29:44 - INFO - volta.train_utils -   [NLVR2]: iter 32560 Ep: 12.06 loss 0.066 score 0.442 lr 2.20772e-06 
07/28/2021 12:30:04 - INFO - volta.train_utils -   [NLVR2]: iter 32600 Ep: 12.07 loss 0.069 score 0.445 lr 2.2036e-06 
07/28/2021 12:30:24 - INFO - volta.train_utils -   [NLVR2]: iter 32640 Ep: 12.09 loss 0.066 score 0.441 lr 2.19949e-06 
07/28/2021 12:30:44 - INFO - volta.train_utils -   [NLVR2]: iter 32680 Ep: 12.10 loss 0.055 score 0.451 lr 2.19537e-06 
07/28/2021 12:31:07 - INFO - volta.train_utils -   [NLVR2]: iter 32720 Ep: 12.12 loss 0.067 score 0.440 lr 2.19126e-06 
07/28/2021 12:31:28 - INFO - volta.train_utils -   [NLVR2]: iter 32760 Ep: 12.13 loss 0.065 score 0.442 lr 2.18714e-06 
07/28/2021 12:31:49 - INFO - volta.train_utils -   [NLVR2]: iter 32800 Ep: 12.15 loss 0.056 score 0.443 lr 2.18302e-06 
07/28/2021 12:32:09 - INFO - volta.train_utils -   [NLVR2]: iter 32840 Ep: 12.16 loss 0.066 score 0.445 lr 2.17891e-06 
07/28/2021 12:32:30 - INFO - volta.train_utils -   [NLVR2]: iter 32880 Ep: 12.18 loss 0.062 score 0.439 lr 2.17479e-06 
07/28/2021 12:32:52 - INFO - volta.train_utils -   [NLVR2]: iter 32920 Ep: 12.19 loss 0.048 score 0.457 lr 2.17068e-06 
07/28/2021 12:33:15 - INFO - volta.train_utils -   [NLVR2]: iter 32960 Ep: 12.21 loss 0.061 score 0.445 lr 2.16656e-06 
07/28/2021 12:33:38 - INFO - volta.train_utils -   [NLVR2]: iter 33000 Ep: 12.22 loss 0.064 score 0.442 lr 2.16245e-06 
07/28/2021 12:33:58 - INFO - volta.train_utils -   [NLVR2]: iter 33040 Ep: 12.24 loss 0.058 score 0.439 lr 2.15833e-06 
07/28/2021 12:34:20 - INFO - volta.train_utils -   [NLVR2]: iter 33080 Ep: 12.25 loss 0.071 score 0.434 lr 2.15422e-06 
07/28/2021 12:34:41 - INFO - volta.train_utils -   [NLVR2]: iter 33120 Ep: 12.27 loss 0.069 score 0.444 lr 2.1501e-06 
07/28/2021 12:35:02 - INFO - volta.train_utils -   [NLVR2]: iter 33160 Ep: 12.28 loss 0.058 score 0.444 lr 2.14599e-06 
07/28/2021 12:35:25 - INFO - volta.train_utils -   [NLVR2]: iter 33200 Ep: 12.30 loss 0.060 score 0.443 lr 2.14187e-06 
07/28/2021 12:35:48 - INFO - volta.train_utils -   [NLVR2]: iter 33240 Ep: 12.31 loss 0.065 score 0.446 lr 2.13776e-06 
07/28/2021 12:36:09 - INFO - volta.train_utils -   [NLVR2]: iter 33280 Ep: 12.33 loss 0.072 score 0.432 lr 2.13364e-06 
07/28/2021 12:36:30 - INFO - volta.train_utils -   [NLVR2]: iter 33320 Ep: 12.34 loss 0.068 score 0.436 lr 2.12953e-06 
07/28/2021 12:36:53 - INFO - volta.train_utils -   [NLVR2]: iter 33360 Ep: 12.36 loss 0.066 score 0.442 lr 2.12541e-06 
07/28/2021 12:37:15 - INFO - volta.train_utils -   [NLVR2]: iter 33400 Ep: 12.37 loss 0.061 score 0.448 lr 2.1213e-06 
07/28/2021 12:37:36 - INFO - volta.train_utils -   [NLVR2]: iter 33440 Ep: 12.39 loss 0.064 score 0.438 lr 2.11718e-06 
07/28/2021 12:37:59 - INFO - volta.train_utils -   [NLVR2]: iter 33480 Ep: 12.40 loss 0.069 score 0.434 lr 2.11307e-06 
07/28/2021 12:38:20 - INFO - volta.train_utils -   [NLVR2]: iter 33520 Ep: 12.41 loss 0.066 score 0.445 lr 2.10895e-06 
07/28/2021 12:38:41 - INFO - volta.train_utils -   [NLVR2]: iter 33560 Ep: 12.43 loss 0.071 score 0.437 lr 2.10484e-06 
07/28/2021 12:39:04 - INFO - volta.train_utils -   [NLVR2]: iter 33600 Ep: 12.44 loss 0.064 score 0.437 lr 2.10072e-06 
07/28/2021 12:39:26 - INFO - volta.train_utils -   [NLVR2]: iter 33640 Ep: 12.46 loss 0.062 score 0.444 lr 2.0966e-06 
07/28/2021 12:39:48 - INFO - volta.train_utils -   [NLVR2]: iter 33680 Ep: 12.47 loss 0.057 score 0.438 lr 2.09249e-06 
07/28/2021 12:40:12 - INFO - volta.train_utils -   [NLVR2]: iter 33720 Ep: 12.49 loss 0.066 score 0.440 lr 2.08837e-06 
07/28/2021 12:40:35 - INFO - volta.train_utils -   [NLVR2]: iter 33760 Ep: 12.50 loss 0.060 score 0.439 lr 2.08426e-06 
07/28/2021 12:40:59 - INFO - volta.train_utils -   [NLVR2]: iter 33800 Ep: 12.52 loss 0.061 score 0.445 lr 2.08014e-06 
07/28/2021 12:41:22 - INFO - volta.train_utils -   [NLVR2]: iter 33840 Ep: 12.53 loss 0.065 score 0.436 lr 2.07603e-06 
07/28/2021 12:41:46 - INFO - volta.train_utils -   [NLVR2]: iter 33880 Ep: 12.55 loss 0.061 score 0.434 lr 2.07191e-06 
07/28/2021 12:42:09 - INFO - volta.train_utils -   [NLVR2]: iter 33920 Ep: 12.56 loss 0.059 score 0.441 lr 2.0678e-06 
07/28/2021 12:42:33 - INFO - volta.train_utils -   [NLVR2]: iter 33960 Ep: 12.58 loss 0.061 score 0.445 lr 2.06368e-06 
07/28/2021 12:42:56 - INFO - volta.train_utils -   [NLVR2]: iter 34000 Ep: 12.59 loss 0.076 score 0.433 lr 2.05957e-06 
07/28/2021 12:43:19 - INFO - volta.train_utils -   [NLVR2]: iter 34040 Ep: 12.61 loss 0.060 score 0.443 lr 2.05545e-06 
07/28/2021 12:43:40 - INFO - volta.train_utils -   [NLVR2]: iter 34080 Ep: 12.62 loss 0.068 score 0.444 lr 2.05134e-06 
07/28/2021 12:44:04 - INFO - volta.train_utils -   [NLVR2]: iter 34120 Ep: 12.64 loss 0.069 score 0.439 lr 2.04722e-06 
07/28/2021 12:44:27 - INFO - volta.train_utils -   [NLVR2]: iter 34160 Ep: 12.65 loss 0.069 score 0.442 lr 2.04311e-06 
07/28/2021 12:44:51 - INFO - volta.train_utils -   [NLVR2]: iter 34200 Ep: 12.67 loss 0.064 score 0.438 lr 2.03899e-06 
07/28/2021 12:45:12 - INFO - volta.train_utils -   [NLVR2]: iter 34240 Ep: 12.68 loss 0.063 score 0.447 lr 2.03488e-06 
07/28/2021 12:45:36 - INFO - volta.train_utils -   [NLVR2]: iter 34280 Ep: 12.70 loss 0.069 score 0.440 lr 2.03076e-06 
07/28/2021 12:45:59 - INFO - volta.train_utils -   [NLVR2]: iter 34320 Ep: 12.71 loss 0.069 score 0.430 lr 2.02665e-06 
07/28/2021 12:46:23 - INFO - volta.train_utils -   [NLVR2]: iter 34360 Ep: 12.73 loss 0.066 score 0.438 lr 2.02253e-06 
07/28/2021 12:46:44 - INFO - volta.train_utils -   [NLVR2]: iter 34400 Ep: 12.74 loss 0.071 score 0.436 lr 2.01842e-06 
07/28/2021 12:47:06 - INFO - volta.train_utils -   [NLVR2]: iter 34440 Ep: 12.76 loss 0.065 score 0.447 lr 2.0143e-06 
07/28/2021 12:47:29 - INFO - volta.train_utils -   [NLVR2]: iter 34480 Ep: 12.77 loss 0.068 score 0.439 lr 2.01019e-06 
07/28/2021 12:47:53 - INFO - volta.train_utils -   [NLVR2]: iter 34520 Ep: 12.79 loss 0.075 score 0.426 lr 2.00607e-06 
07/28/2021 12:48:16 - INFO - volta.train_utils -   [NLVR2]: iter 34560 Ep: 12.80 loss 0.067 score 0.438 lr 2.00195e-06 
07/28/2021 12:48:40 - INFO - volta.train_utils -   [NLVR2]: iter 34600 Ep: 12.81 loss 0.064 score 0.447 lr 1.99784e-06 
07/28/2021 12:49:03 - INFO - volta.train_utils -   [NLVR2]: iter 34640 Ep: 12.83 loss 0.069 score 0.440 lr 1.99372e-06 
07/28/2021 12:49:29 - INFO - volta.train_utils -   [NLVR2]: iter 34680 Ep: 12.84 loss 0.061 score 0.448 lr 1.98961e-06 
07/28/2021 12:49:51 - INFO - volta.train_utils -   [NLVR2]: iter 34720 Ep: 12.86 loss 0.066 score 0.434 lr 1.98549e-06 
07/28/2021 12:50:15 - INFO - volta.train_utils -   [NLVR2]: iter 34760 Ep: 12.87 loss 0.059 score 0.444 lr 1.98138e-06 
07/28/2021 12:50:38 - INFO - volta.train_utils -   [NLVR2]: iter 34800 Ep: 12.89 loss 0.068 score 0.437 lr 1.97726e-06 
07/28/2021 12:51:03 - INFO - volta.train_utils -   [NLVR2]: iter 34840 Ep: 12.90 loss 0.062 score 0.443 lr 1.97315e-06 
07/28/2021 12:51:26 - INFO - volta.train_utils -   [NLVR2]: iter 34880 Ep: 12.92 loss 0.064 score 0.441 lr 1.96903e-06 
07/28/2021 12:51:49 - INFO - volta.train_utils -   [NLVR2]: iter 34920 Ep: 12.93 loss 0.062 score 0.445 lr 1.96492e-06 
07/28/2021 12:52:12 - INFO - volta.train_utils -   [NLVR2]: iter 34960 Ep: 12.95 loss 0.060 score 0.443 lr 1.9608e-06 
07/28/2021 12:52:36 - INFO - volta.train_utils -   [NLVR2]: iter 35000 Ep: 12.96 loss 0.063 score 0.445 lr 1.95669e-06 
07/28/2021 12:52:59 - INFO - volta.train_utils -   [NLVR2]: iter 35040 Ep: 12.98 loss 0.065 score 0.436 lr 1.95257e-06 
07/28/2021 12:53:23 - INFO - volta.train_utils -   [NLVR2]: iter 35080 Ep: 12.99 loss 0.070 score 0.441 lr 1.94846e-06 
07/28/2021 12:53:33 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  65%|██████▌   | 13/20 [7:09:39<3:49:06, 1963.83s/it]07/28/2021 13:00:22 - INFO - volta.train_utils -   Eval task TASK12 on iteration 35100 
07/28/2021 13:00:22 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.786 score 71.441 
07/28/2021 13:00:42 - INFO - volta.train_utils -   [NLVR2]: iter 35140 Ep: 13.01 loss 0.057 score 0.450 lr 1.94331e-06 
07/28/2021 13:01:02 - INFO - volta.train_utils -   [NLVR2]: iter 35180 Ep: 13.03 loss 0.064 score 0.448 lr 1.93817e-06 
07/28/2021 13:01:22 - INFO - volta.train_utils -   [NLVR2]: iter 35220 Ep: 13.04 loss 0.061 score 0.442 lr 1.93405e-06 
07/28/2021 13:01:42 - INFO - volta.train_utils -   [NLVR2]: iter 35260 Ep: 13.06 loss 0.063 score 0.445 lr 1.92994e-06 
07/28/2021 13:02:02 - INFO - volta.train_utils -   [NLVR2]: iter 35300 Ep: 13.07 loss 0.055 score 0.454 lr 1.92582e-06 
07/28/2021 13:02:23 - INFO - volta.train_utils -   [NLVR2]: iter 35340 Ep: 13.09 loss 0.068 score 0.440 lr 1.92171e-06 
07/28/2021 13:02:43 - INFO - volta.train_utils -   [NLVR2]: iter 35380 Ep: 13.10 loss 0.057 score 0.451 lr 1.91759e-06 
07/28/2021 13:03:09 - INFO - volta.train_utils -   [NLVR2]: iter 35420 Ep: 13.12 loss 0.058 score 0.446 lr 1.91348e-06 
07/28/2021 13:03:29 - INFO - volta.train_utils -   [NLVR2]: iter 35460 Ep: 13.13 loss 0.057 score 0.444 lr 1.90936e-06 
07/28/2021 13:03:50 - INFO - volta.train_utils -   [NLVR2]: iter 35500 Ep: 13.15 loss 0.063 score 0.450 lr 1.90525e-06 
07/28/2021 13:04:12 - INFO - volta.train_utils -   [NLVR2]: iter 35540 Ep: 13.16 loss 0.064 score 0.447 lr 1.90113e-06 
07/28/2021 13:04:35 - INFO - volta.train_utils -   [NLVR2]: iter 35580 Ep: 13.18 loss 0.059 score 0.451 lr 1.89702e-06 
07/28/2021 13:04:56 - INFO - volta.train_utils -   [NLVR2]: iter 35620 Ep: 13.19 loss 0.063 score 0.446 lr 1.8929e-06 
07/28/2021 13:05:19 - INFO - volta.train_utils -   [NLVR2]: iter 35660 Ep: 13.21 loss 0.053 score 0.452 lr 1.88879e-06 
07/28/2021 13:05:44 - INFO - volta.train_utils -   [NLVR2]: iter 35700 Ep: 13.22 loss 0.057 score 0.448 lr 1.88467e-06 
07/28/2021 13:06:05 - INFO - volta.train_utils -   [NLVR2]: iter 35740 Ep: 13.24 loss 0.060 score 0.445 lr 1.88056e-06 
07/28/2021 13:06:26 - INFO - volta.train_utils -   [NLVR2]: iter 35780 Ep: 13.25 loss 0.070 score 0.443 lr 1.87644e-06 
07/28/2021 13:06:46 - INFO - volta.train_utils -   [NLVR2]: iter 35820 Ep: 13.27 loss 0.070 score 0.439 lr 1.87233e-06 
07/28/2021 13:07:06 - INFO - volta.train_utils -   [NLVR2]: iter 35860 Ep: 13.28 loss 0.064 score 0.440 lr 1.86821e-06 
07/28/2021 13:07:28 - INFO - volta.train_utils -   [NLVR2]: iter 35900 Ep: 13.30 loss 0.051 score 0.452 lr 1.86409e-06 
07/28/2021 13:07:49 - INFO - volta.train_utils -   [NLVR2]: iter 35940 Ep: 13.31 loss 0.054 score 0.443 lr 1.85998e-06 
07/28/2021 13:08:11 - INFO - volta.train_utils -   [NLVR2]: iter 35980 Ep: 13.33 loss 0.055 score 0.450 lr 1.85586e-06 
07/28/2021 13:08:33 - INFO - volta.train_utils -   [NLVR2]: iter 36020 Ep: 13.34 loss 0.067 score 0.445 lr 1.85175e-06 
07/28/2021 13:08:55 - INFO - volta.train_utils -   [NLVR2]: iter 36060 Ep: 13.36 loss 0.061 score 0.445 lr 1.84763e-06 
07/28/2021 13:09:17 - INFO - volta.train_utils -   [NLVR2]: iter 36100 Ep: 13.37 loss 0.061 score 0.444 lr 1.84352e-06 
07/28/2021 13:09:41 - INFO - volta.train_utils -   [NLVR2]: iter 36140 Ep: 13.39 loss 0.050 score 0.457 lr 1.8394e-06 
07/28/2021 13:10:02 - INFO - volta.train_utils -   [NLVR2]: iter 36180 Ep: 13.40 loss 0.060 score 0.444 lr 1.83529e-06 
07/28/2021 13:10:27 - INFO - volta.train_utils -   [NLVR2]: iter 36220 Ep: 13.41 loss 0.063 score 0.445 lr 1.83117e-06 
07/28/2021 13:10:48 - INFO - volta.train_utils -   [NLVR2]: iter 36260 Ep: 13.43 loss 0.051 score 0.451 lr 1.82706e-06 
07/28/2021 13:11:12 - INFO - volta.train_utils -   [NLVR2]: iter 36300 Ep: 13.44 loss 0.062 score 0.446 lr 1.82294e-06 
07/28/2021 13:11:34 - INFO - volta.train_utils -   [NLVR2]: iter 36340 Ep: 13.46 loss 0.066 score 0.440 lr 1.81883e-06 
07/28/2021 13:11:56 - INFO - volta.train_utils -   [NLVR2]: iter 36380 Ep: 13.47 loss 0.060 score 0.453 lr 1.81471e-06 
07/28/2021 13:12:19 - INFO - volta.train_utils -   [NLVR2]: iter 36420 Ep: 13.49 loss 0.067 score 0.443 lr 1.8106e-06 
07/28/2021 13:12:43 - INFO - volta.train_utils -   [NLVR2]: iter 36460 Ep: 13.50 loss 0.068 score 0.441 lr 1.80648e-06 
07/28/2021 13:13:05 - INFO - volta.train_utils -   [NLVR2]: iter 36500 Ep: 13.52 loss 0.057 score 0.448 lr 1.80237e-06 
07/28/2021 13:13:30 - INFO - volta.train_utils -   [NLVR2]: iter 36540 Ep: 13.53 loss 0.059 score 0.448 lr 1.79825e-06 
07/28/2021 13:13:52 - INFO - volta.train_utils -   [NLVR2]: iter 36580 Ep: 13.55 loss 0.057 score 0.452 lr 1.79414e-06 
07/28/2021 13:14:16 - INFO - volta.train_utils -   [NLVR2]: iter 36620 Ep: 13.56 loss 0.061 score 0.448 lr 1.79002e-06 
07/28/2021 13:14:39 - INFO - volta.train_utils -   [NLVR2]: iter 36660 Ep: 13.58 loss 0.064 score 0.444 lr 1.78591e-06 
07/28/2021 13:15:04 - INFO - volta.train_utils -   [NLVR2]: iter 36700 Ep: 13.59 loss 0.071 score 0.443 lr 1.78179e-06 
07/28/2021 13:15:26 - INFO - volta.train_utils -   [NLVR2]: iter 36740 Ep: 13.61 loss 0.056 score 0.450 lr 1.77767e-06 
07/28/2021 13:15:49 - INFO - volta.train_utils -   [NLVR2]: iter 36780 Ep: 13.62 loss 0.056 score 0.445 lr 1.77356e-06 
07/28/2021 13:16:11 - INFO - volta.train_utils -   [NLVR2]: iter 36820 Ep: 13.64 loss 0.070 score 0.435 lr 1.76944e-06 
07/28/2021 13:16:37 - INFO - volta.train_utils -   [NLVR2]: iter 36860 Ep: 13.65 loss 0.067 score 0.445 lr 1.76533e-06 
07/28/2021 13:17:00 - INFO - volta.train_utils -   [NLVR2]: iter 36900 Ep: 13.67 loss 0.060 score 0.443 lr 1.76121e-06 
07/28/2021 13:17:23 - INFO - volta.train_utils -   [NLVR2]: iter 36940 Ep: 13.68 loss 0.069 score 0.439 lr 1.7571e-06 
07/28/2021 13:17:45 - INFO - volta.train_utils -   [NLVR2]: iter 36980 Ep: 13.70 loss 0.060 score 0.448 lr 1.75298e-06 
07/28/2021 13:18:08 - INFO - volta.train_utils -   [NLVR2]: iter 37020 Ep: 13.71 loss 0.068 score 0.439 lr 1.74887e-06 
07/28/2021 13:18:31 - INFO - volta.train_utils -   [NLVR2]: iter 37060 Ep: 13.73 loss 0.063 score 0.440 lr 1.74475e-06 
07/28/2021 13:18:54 - INFO - volta.train_utils -   [NLVR2]: iter 37100 Ep: 13.74 loss 0.062 score 0.441 lr 1.74064e-06 
07/28/2021 13:19:17 - INFO - volta.train_utils -   [NLVR2]: iter 37140 Ep: 13.76 loss 0.058 score 0.446 lr 1.73652e-06 
07/28/2021 13:19:42 - INFO - volta.train_utils -   [NLVR2]: iter 37180 Ep: 13.77 loss 0.058 score 0.450 lr 1.73241e-06 
07/28/2021 13:20:05 - INFO - volta.train_utils -   [NLVR2]: iter 37220 Ep: 13.79 loss 0.055 score 0.451 lr 1.72829e-06 
07/28/2021 13:20:29 - INFO - volta.train_utils -   [NLVR2]: iter 37260 Ep: 13.80 loss 0.058 score 0.452 lr 1.72418e-06 
07/28/2021 13:20:51 - INFO - volta.train_utils -   [NLVR2]: iter 37300 Ep: 13.81 loss 0.059 score 0.445 lr 1.72006e-06 
07/28/2021 13:21:17 - INFO - volta.train_utils -   [NLVR2]: iter 37340 Ep: 13.83 loss 0.067 score 0.444 lr 1.71595e-06 
07/28/2021 13:21:39 - INFO - volta.train_utils -   [NLVR2]: iter 37380 Ep: 13.84 loss 0.061 score 0.446 lr 1.71183e-06 
07/28/2021 13:22:02 - INFO - volta.train_utils -   [NLVR2]: iter 37420 Ep: 13.86 loss 0.061 score 0.443 lr 1.70772e-06 
07/28/2021 13:22:23 - INFO - volta.train_utils -   [NLVR2]: iter 37460 Ep: 13.87 loss 0.054 score 0.450 lr 1.7036e-06 
07/28/2021 13:22:47 - INFO - volta.train_utils -   [NLVR2]: iter 37500 Ep: 13.89 loss 0.070 score 0.442 lr 1.69949e-06 
07/28/2021 13:23:10 - INFO - volta.train_utils -   [NLVR2]: iter 37540 Ep: 13.90 loss 0.062 score 0.446 lr 1.69537e-06 
07/28/2021 13:23:35 - INFO - volta.train_utils -   [NLVR2]: iter 37580 Ep: 13.92 loss 0.054 score 0.452 lr 1.69126e-06 
07/28/2021 13:23:57 - INFO - volta.train_utils -   [NLVR2]: iter 37620 Ep: 13.93 loss 0.059 score 0.451 lr 1.68714e-06 
07/28/2021 13:24:21 - INFO - volta.train_utils -   [NLVR2]: iter 37660 Ep: 13.95 loss 0.070 score 0.443 lr 1.68302e-06 
07/28/2021 13:24:45 - INFO - volta.train_utils -   [NLVR2]: iter 37700 Ep: 13.96 loss 0.051 score 0.445 lr 1.67891e-06 
07/28/2021 13:25:10 - INFO - volta.train_utils -   [NLVR2]: iter 37740 Ep: 13.98 loss 0.062 score 0.449 lr 1.67479e-06 
07/28/2021 13:25:33 - INFO - volta.train_utils -   [NLVR2]: iter 37780 Ep: 13.99 loss 0.067 score 0.445 lr 1.67068e-06 
07/28/2021 13:25:44 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  70%|███████   | 14/20 [7:41:52<3:15:26, 1954.35s/it]07/28/2021 13:32:20 - INFO - volta.train_utils -   Eval task TASK12 on iteration 37800 
07/28/2021 13:32:20 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.852 score 71.598 
07/28/2021 13:32:40 - INFO - volta.train_utils -   [NLVR2]: iter 37840 Ep: 14.01 loss 0.048 score 0.457 lr 1.66553e-06 
07/28/2021 13:33:00 - INFO - volta.train_utils -   [NLVR2]: iter 37880 Ep: 14.03 loss 0.059 score 0.450 lr 1.66039e-06 
07/28/2021 13:33:20 - INFO - volta.train_utils -   [NLVR2]: iter 37920 Ep: 14.04 loss 0.056 score 0.453 lr 1.65628e-06 
07/28/2021 13:33:41 - INFO - volta.train_utils -   [NLVR2]: iter 37960 Ep: 14.06 loss 0.045 score 0.454 lr 1.65216e-06 
07/28/2021 13:34:01 - INFO - volta.train_utils -   [NLVR2]: iter 38000 Ep: 14.07 loss 0.054 score 0.455 lr 1.64805e-06 
07/28/2021 13:34:21 - INFO - volta.train_utils -   [NLVR2]: iter 38040 Ep: 14.09 loss 0.051 score 0.455 lr 1.64393e-06 
07/28/2021 13:34:42 - INFO - volta.train_utils -   [NLVR2]: iter 38080 Ep: 14.10 loss 0.056 score 0.454 lr 1.63981e-06 
07/28/2021 13:35:07 - INFO - volta.train_utils -   [NLVR2]: iter 38120 Ep: 14.12 loss 0.057 score 0.449 lr 1.6357e-06 
07/28/2021 13:35:28 - INFO - volta.train_utils -   [NLVR2]: iter 38160 Ep: 14.13 loss 0.055 score 0.456 lr 1.63158e-06 
07/28/2021 13:35:48 - INFO - volta.train_utils -   [NLVR2]: iter 38200 Ep: 14.15 loss 0.058 score 0.448 lr 1.62747e-06 
07/28/2021 13:36:09 - INFO - volta.train_utils -   [NLVR2]: iter 38240 Ep: 14.16 loss 0.060 score 0.445 lr 1.62335e-06 
07/28/2021 13:36:29 - INFO - volta.train_utils -   [NLVR2]: iter 38280 Ep: 14.18 loss 0.053 score 0.454 lr 1.61924e-06 
07/28/2021 13:36:49 - INFO - volta.train_utils -   [NLVR2]: iter 38320 Ep: 14.19 loss 0.054 score 0.448 lr 1.61512e-06 
07/28/2021 13:37:11 - INFO - volta.train_utils -   [NLVR2]: iter 38360 Ep: 14.21 loss 0.058 score 0.446 lr 1.61101e-06 
07/28/2021 13:37:32 - INFO - volta.train_utils -   [NLVR2]: iter 38400 Ep: 14.22 loss 0.055 score 0.451 lr 1.60689e-06 
07/28/2021 13:37:53 - INFO - volta.train_utils -   [NLVR2]: iter 38440 Ep: 14.24 loss 0.051 score 0.452 lr 1.60278e-06 
07/28/2021 13:38:16 - INFO - volta.train_utils -   [NLVR2]: iter 38480 Ep: 14.25 loss 0.057 score 0.450 lr 1.59866e-06 
07/28/2021 13:38:36 - INFO - volta.train_utils -   [NLVR2]: iter 38520 Ep: 14.27 loss 0.046 score 0.456 lr 1.59455e-06 
07/28/2021 13:38:57 - INFO - volta.train_utils -   [NLVR2]: iter 38560 Ep: 14.28 loss 0.059 score 0.449 lr 1.59043e-06 
07/28/2021 13:39:19 - INFO - volta.train_utils -   [NLVR2]: iter 38600 Ep: 14.30 loss 0.052 score 0.458 lr 1.58632e-06 
07/28/2021 13:39:44 - INFO - volta.train_utils -   [NLVR2]: iter 38640 Ep: 14.31 loss 0.053 score 0.459 lr 1.5822e-06 
07/28/2021 13:40:04 - INFO - volta.train_utils -   [NLVR2]: iter 38680 Ep: 14.33 loss 0.056 score 0.456 lr 1.57809e-06 
07/28/2021 13:40:26 - INFO - volta.train_utils -   [NLVR2]: iter 38720 Ep: 14.34 loss 0.055 score 0.448 lr 1.57397e-06 
07/28/2021 13:40:47 - INFO - volta.train_utils -   [NLVR2]: iter 38760 Ep: 14.36 loss 0.058 score 0.449 lr 1.56986e-06 
07/28/2021 13:41:08 - INFO - volta.train_utils -   [NLVR2]: iter 38800 Ep: 14.37 loss 0.063 score 0.444 lr 1.56574e-06 
07/28/2021 13:41:29 - INFO - volta.train_utils -   [NLVR2]: iter 38840 Ep: 14.39 loss 0.058 score 0.449 lr 1.56163e-06 
07/28/2021 13:41:51 - INFO - volta.train_utils -   [NLVR2]: iter 38880 Ep: 14.40 loss 0.056 score 0.447 lr 1.55751e-06 
07/28/2021 13:42:14 - INFO - volta.train_utils -   [NLVR2]: iter 38920 Ep: 14.41 loss 0.055 score 0.452 lr 1.5534e-06 
07/28/2021 13:42:36 - INFO - volta.train_utils -   [NLVR2]: iter 38960 Ep: 14.43 loss 0.041 score 0.452 lr 1.54928e-06 
07/28/2021 13:42:59 - INFO - volta.train_utils -   [NLVR2]: iter 39000 Ep: 14.44 loss 0.061 score 0.441 lr 1.54516e-06 
07/28/2021 13:43:20 - INFO - volta.train_utils -   [NLVR2]: iter 39040 Ep: 14.46 loss 0.060 score 0.450 lr 1.54105e-06 
07/28/2021 13:43:43 - INFO - volta.train_utils -   [NLVR2]: iter 39080 Ep: 14.47 loss 0.061 score 0.439 lr 1.53693e-06 
07/28/2021 13:44:06 - INFO - volta.train_utils -   [NLVR2]: iter 39120 Ep: 14.49 loss 0.059 score 0.443 lr 1.53282e-06 
07/28/2021 13:44:31 - INFO - volta.train_utils -   [NLVR2]: iter 39160 Ep: 14.50 loss 0.058 score 0.443 lr 1.5287e-06 
07/28/2021 13:44:54 - INFO - volta.train_utils -   [NLVR2]: iter 39200 Ep: 14.52 loss 0.052 score 0.454 lr 1.52459e-06 
07/28/2021 13:45:17 - INFO - volta.train_utils -   [NLVR2]: iter 39240 Ep: 14.53 loss 0.065 score 0.443 lr 1.52047e-06 
07/28/2021 13:45:40 - INFO - volta.train_utils -   [NLVR2]: iter 39280 Ep: 14.55 loss 0.057 score 0.451 lr 1.51636e-06 
07/28/2021 13:46:03 - INFO - volta.train_utils -   [NLVR2]: iter 39320 Ep: 14.56 loss 0.058 score 0.450 lr 1.51224e-06 
07/28/2021 13:46:27 - INFO - volta.train_utils -   [NLVR2]: iter 39360 Ep: 14.58 loss 0.052 score 0.454 lr 1.50813e-06 
07/28/2021 13:46:51 - INFO - volta.train_utils -   [NLVR2]: iter 39400 Ep: 14.59 loss 0.056 score 0.455 lr 1.50401e-06 
07/28/2021 13:47:12 - INFO - volta.train_utils -   [NLVR2]: iter 39440 Ep: 14.61 loss 0.053 score 0.447 lr 1.4999e-06 
07/28/2021 13:47:35 - INFO - volta.train_utils -   [NLVR2]: iter 39480 Ep: 14.62 loss 0.062 score 0.454 lr 1.49578e-06 
07/28/2021 13:47:56 - INFO - volta.train_utils -   [NLVR2]: iter 39520 Ep: 14.64 loss 0.064 score 0.451 lr 1.49167e-06 
07/28/2021 13:48:20 - INFO - volta.train_utils -   [NLVR2]: iter 39560 Ep: 14.65 loss 0.062 score 0.444 lr 1.48755e-06 
07/28/2021 13:48:44 - INFO - volta.train_utils -   [NLVR2]: iter 39600 Ep: 14.67 loss 0.055 score 0.453 lr 1.48344e-06 
07/28/2021 13:49:07 - INFO - volta.train_utils -   [NLVR2]: iter 39640 Ep: 14.68 loss 0.059 score 0.451 lr 1.47932e-06 
07/28/2021 13:49:32 - INFO - volta.train_utils -   [NLVR2]: iter 39680 Ep: 14.70 loss 0.051 score 0.453 lr 1.47521e-06 
07/28/2021 13:49:53 - INFO - volta.train_utils -   [NLVR2]: iter 39720 Ep: 14.71 loss 0.062 score 0.450 lr 1.47109e-06 
07/28/2021 13:50:17 - INFO - volta.train_utils -   [NLVR2]: iter 39760 Ep: 14.73 loss 0.060 score 0.447 lr 1.46698e-06 
07/28/2021 13:50:40 - INFO - volta.train_utils -   [NLVR2]: iter 39800 Ep: 14.74 loss 0.056 score 0.438 lr 1.46286e-06 
07/28/2021 13:51:03 - INFO - volta.train_utils -   [NLVR2]: iter 39840 Ep: 14.76 loss 0.064 score 0.449 lr 1.45874e-06 
07/28/2021 13:51:27 - INFO - volta.train_utils -   [NLVR2]: iter 39880 Ep: 14.77 loss 0.053 score 0.452 lr 1.45463e-06 
07/28/2021 13:51:51 - INFO - volta.train_utils -   [NLVR2]: iter 39920 Ep: 14.79 loss 0.060 score 0.452 lr 1.45051e-06 
07/28/2021 13:52:13 - INFO - volta.train_utils -   [NLVR2]: iter 39960 Ep: 14.80 loss 0.062 score 0.449 lr 1.4464e-06 
07/28/2021 13:52:36 - INFO - volta.train_utils -   [NLVR2]: iter 40000 Ep: 14.81 loss 0.048 score 0.455 lr 1.44228e-06 
07/28/2021 13:53:00 - INFO - volta.train_utils -   [NLVR2]: iter 40040 Ep: 14.83 loss 0.058 score 0.453 lr 1.43817e-06 
07/28/2021 13:53:22 - INFO - volta.train_utils -   [NLVR2]: iter 40080 Ep: 14.84 loss 0.057 score 0.450 lr 1.43405e-06 
07/28/2021 13:53:44 - INFO - volta.train_utils -   [NLVR2]: iter 40120 Ep: 14.86 loss 0.054 score 0.447 lr 1.42994e-06 
07/28/2021 13:54:07 - INFO - volta.train_utils -   [NLVR2]: iter 40160 Ep: 14.87 loss 0.060 score 0.455 lr 1.42582e-06 
07/28/2021 13:54:32 - INFO - volta.train_utils -   [NLVR2]: iter 40200 Ep: 14.89 loss 0.056 score 0.449 lr 1.42171e-06 
07/28/2021 13:54:55 - INFO - volta.train_utils -   [NLVR2]: iter 40240 Ep: 14.90 loss 0.057 score 0.446 lr 1.41759e-06 
07/28/2021 13:55:18 - INFO - volta.train_utils -   [NLVR2]: iter 40280 Ep: 14.92 loss 0.062 score 0.439 lr 1.41348e-06 
07/28/2021 13:55:41 - INFO - volta.train_utils -   [NLVR2]: iter 40320 Ep: 14.93 loss 0.055 score 0.450 lr 1.40936e-06 
07/28/2021 13:56:04 - INFO - volta.train_utils -   [NLVR2]: iter 40360 Ep: 14.95 loss 0.059 score 0.446 lr 1.40525e-06 
07/28/2021 13:56:28 - INFO - volta.train_utils -   [NLVR2]: iter 40400 Ep: 14.96 loss 0.048 score 0.456 lr 1.40113e-06 
07/28/2021 13:56:52 - INFO - volta.train_utils -   [NLVR2]: iter 40440 Ep: 14.98 loss 0.066 score 0.448 lr 1.39702e-06 
07/28/2021 13:57:15 - INFO - volta.train_utils -   [NLVR2]: iter 40480 Ep: 14.99 loss 0.053 score 0.452 lr 1.3929e-06 
07/28/2021 13:57:26 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  75%|███████▌  | 15/20 [8:13:31<2:41:29, 1937.96s/it]07/28/2021 14:03:59 - INFO - volta.train_utils -   Eval task TASK12 on iteration 40500 
07/28/2021 14:03:59 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.860 score 71.498 
07/28/2021 14:04:19 - INFO - volta.train_utils -   [NLVR2]: iter 40540 Ep: 15.01 loss 0.057 score 0.447 lr 1.38776e-06 
07/28/2021 14:04:40 - INFO - volta.train_utils -   [NLVR2]: iter 40580 Ep: 15.03 loss 0.049 score 0.459 lr 1.38261e-06 
07/28/2021 14:05:00 - INFO - volta.train_utils -   [NLVR2]: iter 40620 Ep: 15.04 loss 0.055 score 0.451 lr 1.3785e-06 
07/28/2021 14:05:20 - INFO - volta.train_utils -   [NLVR2]: iter 40660 Ep: 15.06 loss 0.047 score 0.463 lr 1.37438e-06 
07/28/2021 14:05:40 - INFO - volta.train_utils -   [NLVR2]: iter 40700 Ep: 15.07 loss 0.052 score 0.451 lr 1.37027e-06 
07/28/2021 14:06:00 - INFO - volta.train_utils -   [NLVR2]: iter 40740 Ep: 15.09 loss 0.053 score 0.454 lr 1.36615e-06 
07/28/2021 14:06:21 - INFO - volta.train_utils -   [NLVR2]: iter 40780 Ep: 15.10 loss 0.055 score 0.451 lr 1.36204e-06 
07/28/2021 14:06:45 - INFO - volta.train_utils -   [NLVR2]: iter 40820 Ep: 15.12 loss 0.045 score 0.463 lr 1.35792e-06 
07/28/2021 14:07:05 - INFO - volta.train_utils -   [NLVR2]: iter 40860 Ep: 15.13 loss 0.041 score 0.457 lr 1.35381e-06 
07/28/2021 14:07:26 - INFO - volta.train_utils -   [NLVR2]: iter 40900 Ep: 15.15 loss 0.054 score 0.451 lr 1.34969e-06 
07/28/2021 14:07:47 - INFO - volta.train_utils -   [NLVR2]: iter 40940 Ep: 15.16 loss 0.048 score 0.455 lr 1.34558e-06 
07/28/2021 14:08:08 - INFO - volta.train_utils -   [NLVR2]: iter 40980 Ep: 15.18 loss 0.053 score 0.456 lr 1.34146e-06 
07/28/2021 14:08:30 - INFO - volta.train_utils -   [NLVR2]: iter 41020 Ep: 15.19 loss 0.053 score 0.457 lr 1.33735e-06 
07/28/2021 14:08:51 - INFO - volta.train_utils -   [NLVR2]: iter 41060 Ep: 15.21 loss 0.043 score 0.456 lr 1.33323e-06 
07/28/2021 14:09:12 - INFO - volta.train_utils -   [NLVR2]: iter 41100 Ep: 15.22 loss 0.052 score 0.450 lr 1.32912e-06 
07/28/2021 14:09:33 - INFO - volta.train_utils -   [NLVR2]: iter 41140 Ep: 15.24 loss 0.058 score 0.456 lr 1.325e-06 
07/28/2021 14:09:54 - INFO - volta.train_utils -   [NLVR2]: iter 41180 Ep: 15.25 loss 0.049 score 0.458 lr 1.32088e-06 
07/28/2021 14:10:14 - INFO - volta.train_utils -   [NLVR2]: iter 41220 Ep: 15.27 loss 0.052 score 0.454 lr 1.31677e-06 
07/28/2021 14:10:35 - INFO - volta.train_utils -   [NLVR2]: iter 41260 Ep: 15.28 loss 0.053 score 0.453 lr 1.31265e-06 
07/28/2021 14:10:55 - INFO - volta.train_utils -   [NLVR2]: iter 41300 Ep: 15.30 loss 0.056 score 0.455 lr 1.30854e-06 
07/28/2021 14:11:17 - INFO - volta.train_utils -   [NLVR2]: iter 41340 Ep: 15.31 loss 0.059 score 0.450 lr 1.30442e-06 
07/28/2021 14:11:39 - INFO - volta.train_utils -   [NLVR2]: iter 41380 Ep: 15.33 loss 0.051 score 0.457 lr 1.30031e-06 
07/28/2021 14:12:00 - INFO - volta.train_utils -   [NLVR2]: iter 41420 Ep: 15.34 loss 0.046 score 0.453 lr 1.29619e-06 
07/28/2021 14:12:22 - INFO - volta.train_utils -   [NLVR2]: iter 41460 Ep: 15.36 loss 0.049 score 0.455 lr 1.29208e-06 
07/28/2021 14:12:44 - INFO - volta.train_utils -   [NLVR2]: iter 41500 Ep: 15.37 loss 0.050 score 0.449 lr 1.28796e-06 
07/28/2021 14:13:04 - INFO - volta.train_utils -   [NLVR2]: iter 41540 Ep: 15.39 loss 0.054 score 0.450 lr 1.28385e-06 
07/28/2021 14:13:26 - INFO - volta.train_utils -   [NLVR2]: iter 41580 Ep: 15.40 loss 0.058 score 0.455 lr 1.27973e-06 
07/28/2021 14:13:48 - INFO - volta.train_utils -   [NLVR2]: iter 41620 Ep: 15.41 loss 0.048 score 0.453 lr 1.27562e-06 
07/28/2021 14:14:11 - INFO - volta.train_utils -   [NLVR2]: iter 41660 Ep: 15.43 loss 0.057 score 0.451 lr 1.2715e-06 
07/28/2021 14:14:33 - INFO - volta.train_utils -   [NLVR2]: iter 41700 Ep: 15.44 loss 0.051 score 0.454 lr 1.26739e-06 
07/28/2021 14:14:55 - INFO - volta.train_utils -   [NLVR2]: iter 41740 Ep: 15.46 loss 0.053 score 0.460 lr 1.26327e-06 
07/28/2021 14:15:17 - INFO - volta.train_utils -   [NLVR2]: iter 41780 Ep: 15.47 loss 0.047 score 0.453 lr 1.25916e-06 
07/28/2021 14:15:41 - INFO - volta.train_utils -   [NLVR2]: iter 41820 Ep: 15.49 loss 0.050 score 0.454 lr 1.25504e-06 
07/28/2021 14:16:03 - INFO - volta.train_utils -   [NLVR2]: iter 41860 Ep: 15.50 loss 0.057 score 0.454 lr 1.25093e-06 
07/28/2021 14:16:26 - INFO - volta.train_utils -   [NLVR2]: iter 41900 Ep: 15.52 loss 0.057 score 0.445 lr 1.24681e-06 
07/28/2021 14:16:49 - INFO - volta.train_utils -   [NLVR2]: iter 41940 Ep: 15.53 loss 0.051 score 0.457 lr 1.2427e-06 
07/28/2021 14:17:12 - INFO - volta.train_utils -   [NLVR2]: iter 41980 Ep: 15.55 loss 0.049 score 0.454 lr 1.23858e-06 
07/28/2021 14:17:35 - INFO - volta.train_utils -   [NLVR2]: iter 42020 Ep: 15.56 loss 0.048 score 0.451 lr 1.23447e-06 
07/28/2021 14:17:58 - INFO - volta.train_utils -   [NLVR2]: iter 42060 Ep: 15.58 loss 0.056 score 0.449 lr 1.23035e-06 
07/28/2021 14:18:20 - INFO - volta.train_utils -   [NLVR2]: iter 42100 Ep: 15.59 loss 0.053 score 0.457 lr 1.22623e-06 
07/28/2021 14:18:43 - INFO - volta.train_utils -   [NLVR2]: iter 42140 Ep: 15.61 loss 0.055 score 0.457 lr 1.22212e-06 
07/28/2021 14:19:06 - INFO - volta.train_utils -   [NLVR2]: iter 42180 Ep: 15.62 loss 0.053 score 0.454 lr 1.218e-06 
07/28/2021 14:19:28 - INFO - volta.train_utils -   [NLVR2]: iter 42220 Ep: 15.64 loss 0.052 score 0.457 lr 1.21389e-06 
07/28/2021 14:19:51 - INFO - volta.train_utils -   [NLVR2]: iter 42260 Ep: 15.65 loss 0.060 score 0.452 lr 1.20977e-06 
07/28/2021 14:20:14 - INFO - volta.train_utils -   [NLVR2]: iter 42300 Ep: 15.67 loss 0.052 score 0.455 lr 1.20566e-06 
07/28/2021 14:20:37 - INFO - volta.train_utils -   [NLVR2]: iter 42340 Ep: 15.68 loss 0.064 score 0.446 lr 1.20154e-06 
07/28/2021 14:21:02 - INFO - volta.train_utils -   [NLVR2]: iter 42380 Ep: 15.70 loss 0.054 score 0.454 lr 1.19743e-06 
07/28/2021 14:21:24 - INFO - volta.train_utils -   [NLVR2]: iter 42420 Ep: 15.71 loss 0.060 score 0.451 lr 1.19331e-06 
07/28/2021 14:21:48 - INFO - volta.train_utils -   [NLVR2]: iter 42460 Ep: 15.73 loss 0.056 score 0.452 lr 1.1892e-06 
07/28/2021 14:22:11 - INFO - volta.train_utils -   [NLVR2]: iter 42500 Ep: 15.74 loss 0.051 score 0.452 lr 1.18508e-06 
07/28/2021 14:22:35 - INFO - volta.train_utils -   [NLVR2]: iter 42540 Ep: 15.76 loss 0.050 score 0.455 lr 1.18097e-06 
07/28/2021 14:22:55 - INFO - volta.train_utils -   [NLVR2]: iter 42580 Ep: 15.77 loss 0.053 score 0.454 lr 1.17685e-06 
07/28/2021 14:23:19 - INFO - volta.train_utils -   [NLVR2]: iter 42620 Ep: 15.79 loss 0.051 score 0.452 lr 1.17274e-06 
07/28/2021 14:23:42 - INFO - volta.train_utils -   [NLVR2]: iter 42660 Ep: 15.80 loss 0.059 score 0.452 lr 1.16862e-06 
07/28/2021 14:24:07 - INFO - volta.train_utils -   [NLVR2]: iter 42700 Ep: 15.81 loss 0.047 score 0.454 lr 1.16451e-06 
07/28/2021 14:24:29 - INFO - volta.train_utils -   [NLVR2]: iter 42740 Ep: 15.83 loss 0.050 score 0.458 lr 1.16039e-06 
07/28/2021 14:24:53 - INFO - volta.train_utils -   [NLVR2]: iter 42780 Ep: 15.84 loss 0.057 score 0.455 lr 1.15628e-06 
07/28/2021 14:25:16 - INFO - volta.train_utils -   [NLVR2]: iter 42820 Ep: 15.86 loss 0.045 score 0.450 lr 1.15216e-06 
07/28/2021 14:25:40 - INFO - volta.train_utils -   [NLVR2]: iter 42860 Ep: 15.87 loss 0.047 score 0.456 lr 1.14805e-06 
07/28/2021 14:26:04 - INFO - volta.train_utils -   [NLVR2]: iter 42900 Ep: 15.89 loss 0.057 score 0.448 lr 1.14393e-06 
07/28/2021 14:26:29 - INFO - volta.train_utils -   [NLVR2]: iter 42940 Ep: 15.90 loss 0.054 score 0.448 lr 1.13981e-06 
07/28/2021 14:26:51 - INFO - volta.train_utils -   [NLVR2]: iter 42980 Ep: 15.92 loss 0.056 score 0.456 lr 1.1357e-06 
07/28/2021 14:27:14 - INFO - volta.train_utils -   [NLVR2]: iter 43020 Ep: 15.93 loss 0.049 score 0.457 lr 1.13158e-06 
07/28/2021 14:27:38 - INFO - volta.train_utils -   [NLVR2]: iter 43060 Ep: 15.95 loss 0.051 score 0.452 lr 1.12747e-06 
07/28/2021 14:28:01 - INFO - volta.train_utils -   [NLVR2]: iter 43100 Ep: 15.96 loss 0.052 score 0.455 lr 1.12335e-06 
07/28/2021 14:28:25 - INFO - volta.train_utils -   [NLVR2]: iter 43140 Ep: 15.98 loss 0.057 score 0.456 lr 1.11924e-06 
07/28/2021 14:28:49 - INFO - volta.train_utils -   [NLVR2]: iter 43180 Ep: 15.99 loss 0.049 score 0.448 lr 1.11512e-06 
07/28/2021 14:29:00 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  80%|████████  | 16/20 [8:45:06<2:08:19, 1924.95s/it]07/28/2021 14:35:34 - INFO - volta.train_utils -   Eval task TASK12 on iteration 43200 
07/28/2021 14:35:34 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.876 score 71.469 
07/28/2021 14:35:54 - INFO - volta.train_utils -   [NLVR2]: iter 43240 Ep: 16.01 loss 0.053 score 0.456 lr 1.10998e-06 
07/28/2021 14:36:15 - INFO - volta.train_utils -   [NLVR2]: iter 43280 Ep: 16.03 loss 0.049 score 0.456 lr 1.10484e-06 
07/28/2021 14:36:35 - INFO - volta.train_utils -   [NLVR2]: iter 43320 Ep: 16.04 loss 0.055 score 0.454 lr 1.10072e-06 
07/28/2021 14:36:55 - INFO - volta.train_utils -   [NLVR2]: iter 43360 Ep: 16.06 loss 0.051 score 0.463 lr 1.0966e-06 
07/28/2021 14:37:15 - INFO - volta.train_utils -   [NLVR2]: iter 43400 Ep: 16.07 loss 0.052 score 0.453 lr 1.09249e-06 
07/28/2021 14:37:35 - INFO - volta.train_utils -   [NLVR2]: iter 43440 Ep: 16.09 loss 0.050 score 0.456 lr 1.08837e-06 
07/28/2021 14:37:55 - INFO - volta.train_utils -   [NLVR2]: iter 43480 Ep: 16.10 loss 0.044 score 0.459 lr 1.08426e-06 
07/28/2021 14:38:18 - INFO - volta.train_utils -   [NLVR2]: iter 43520 Ep: 16.12 loss 0.049 score 0.458 lr 1.08014e-06 
07/28/2021 14:38:39 - INFO - volta.train_utils -   [NLVR2]: iter 43560 Ep: 16.13 loss 0.053 score 0.455 lr 1.07603e-06 
07/28/2021 14:39:00 - INFO - volta.train_utils -   [NLVR2]: iter 43600 Ep: 16.15 loss 0.050 score 0.462 lr 1.07191e-06 
07/28/2021 14:39:20 - INFO - volta.train_utils -   [NLVR2]: iter 43640 Ep: 16.16 loss 0.057 score 0.452 lr 1.0678e-06 
07/28/2021 14:39:41 - INFO - volta.train_utils -   [NLVR2]: iter 43680 Ep: 16.18 loss 0.054 score 0.454 lr 1.06368e-06 
07/28/2021 14:40:02 - INFO - volta.train_utils -   [NLVR2]: iter 43720 Ep: 16.19 loss 0.047 score 0.456 lr 1.05957e-06 
07/28/2021 14:40:22 - INFO - volta.train_utils -   [NLVR2]: iter 43760 Ep: 16.21 loss 0.046 score 0.452 lr 1.05545e-06 
07/28/2021 14:40:44 - INFO - volta.train_utils -   [NLVR2]: iter 43800 Ep: 16.22 loss 0.047 score 0.459 lr 1.05134e-06 
07/28/2021 14:41:05 - INFO - volta.train_utils -   [NLVR2]: iter 43840 Ep: 16.24 loss 0.052 score 0.457 lr 1.04722e-06 
07/28/2021 14:41:26 - INFO - volta.train_utils -   [NLVR2]: iter 43880 Ep: 16.25 loss 0.050 score 0.459 lr 1.04311e-06 
07/28/2021 14:41:47 - INFO - volta.train_utils -   [NLVR2]: iter 43920 Ep: 16.27 loss 0.051 score 0.453 lr 1.03899e-06 
07/28/2021 14:42:08 - INFO - volta.train_utils -   [NLVR2]: iter 43960 Ep: 16.28 loss 0.054 score 0.459 lr 1.03488e-06 
07/28/2021 14:42:31 - INFO - volta.train_utils -   [NLVR2]: iter 44000 Ep: 16.30 loss 0.058 score 0.457 lr 1.03076e-06 
07/28/2021 14:42:52 - INFO - volta.train_utils -   [NLVR2]: iter 44040 Ep: 16.31 loss 0.048 score 0.460 lr 1.02665e-06 
07/28/2021 14:43:13 - INFO - volta.train_utils -   [NLVR2]: iter 44080 Ep: 16.33 loss 0.058 score 0.449 lr 1.02253e-06 
07/28/2021 14:43:34 - INFO - volta.train_utils -   [NLVR2]: iter 44120 Ep: 16.34 loss 0.056 score 0.452 lr 1.01842e-06 
07/28/2021 14:43:56 - INFO - volta.train_utils -   [NLVR2]: iter 44160 Ep: 16.36 loss 0.043 score 0.463 lr 1.0143e-06 
07/28/2021 14:44:18 - INFO - volta.train_utils -   [NLVR2]: iter 44200 Ep: 16.37 loss 0.044 score 0.462 lr 1.01019e-06 
07/28/2021 14:44:42 - INFO - volta.train_utils -   [NLVR2]: iter 44240 Ep: 16.39 loss 0.048 score 0.456 lr 1.00607e-06 
07/28/2021 14:45:04 - INFO - volta.train_utils -   [NLVR2]: iter 44280 Ep: 16.40 loss 0.048 score 0.458 lr 1.00195e-06 
07/28/2021 14:45:26 - INFO - volta.train_utils -   [NLVR2]: iter 44320 Ep: 16.41 loss 0.045 score 0.463 lr 9.9784e-07 
07/28/2021 14:45:49 - INFO - volta.train_utils -   [NLVR2]: iter 44360 Ep: 16.43 loss 0.053 score 0.455 lr 9.93724e-07 
07/28/2021 14:46:11 - INFO - volta.train_utils -   [NLVR2]: iter 44400 Ep: 16.44 loss 0.057 score 0.450 lr 9.89609e-07 
07/28/2021 14:46:32 - INFO - volta.train_utils -   [NLVR2]: iter 44440 Ep: 16.46 loss 0.054 score 0.454 lr 9.85494e-07 
07/28/2021 14:46:55 - INFO - volta.train_utils -   [NLVR2]: iter 44480 Ep: 16.47 loss 0.049 score 0.455 lr 9.81379e-07 
07/28/2021 14:47:17 - INFO - volta.train_utils -   [NLVR2]: iter 44520 Ep: 16.49 loss 0.053 score 0.459 lr 9.77263e-07 
07/28/2021 14:47:40 - INFO - volta.train_utils -   [NLVR2]: iter 44560 Ep: 16.50 loss 0.040 score 0.462 lr 9.73148e-07 
07/28/2021 14:48:02 - INFO - volta.train_utils -   [NLVR2]: iter 44600 Ep: 16.52 loss 0.050 score 0.457 lr 9.69033e-07 
07/28/2021 14:48:24 - INFO - volta.train_utils -   [NLVR2]: iter 44640 Ep: 16.53 loss 0.044 score 0.462 lr 9.64918e-07 
07/28/2021 14:48:47 - INFO - volta.train_utils -   [NLVR2]: iter 44680 Ep: 16.55 loss 0.051 score 0.458 lr 9.60802e-07 
07/28/2021 14:49:11 - INFO - volta.train_utils -   [NLVR2]: iter 44720 Ep: 16.56 loss 0.044 score 0.463 lr 9.56687e-07 
07/28/2021 14:49:33 - INFO - volta.train_utils -   [NLVR2]: iter 44760 Ep: 16.58 loss 0.049 score 0.465 lr 9.52572e-07 
07/28/2021 14:49:55 - INFO - volta.train_utils -   [NLVR2]: iter 44800 Ep: 16.59 loss 0.047 score 0.467 lr 9.48457e-07 
07/28/2021 14:50:17 - INFO - volta.train_utils -   [NLVR2]: iter 44840 Ep: 16.61 loss 0.054 score 0.454 lr 9.44342e-07 
07/28/2021 14:50:41 - INFO - volta.train_utils -   [NLVR2]: iter 44880 Ep: 16.62 loss 0.053 score 0.452 lr 9.40226e-07 
07/28/2021 14:51:03 - INFO - volta.train_utils -   [NLVR2]: iter 44920 Ep: 16.64 loss 0.052 score 0.456 lr 9.36111e-07 
07/28/2021 14:51:28 - INFO - volta.train_utils -   [NLVR2]: iter 44960 Ep: 16.65 loss 0.053 score 0.459 lr 9.31996e-07 
07/28/2021 14:51:50 - INFO - volta.train_utils -   [NLVR2]: iter 45000 Ep: 16.67 loss 0.048 score 0.463 lr 9.27881e-07 
07/28/2021 14:52:13 - INFO - volta.train_utils -   [NLVR2]: iter 45040 Ep: 16.68 loss 0.049 score 0.459 lr 9.23765e-07 
07/28/2021 14:52:36 - INFO - volta.train_utils -   [NLVR2]: iter 45080 Ep: 16.70 loss 0.042 score 0.462 lr 9.1965e-07 
07/28/2021 14:52:59 - INFO - volta.train_utils -   [NLVR2]: iter 45120 Ep: 16.71 loss 0.053 score 0.457 lr 9.15535e-07 
07/28/2021 14:53:21 - INFO - volta.train_utils -   [NLVR2]: iter 45160 Ep: 16.73 loss 0.041 score 0.456 lr 9.1142e-07 
07/28/2021 14:53:44 - INFO - volta.train_utils -   [NLVR2]: iter 45200 Ep: 16.74 loss 0.055 score 0.455 lr 9.07305e-07 
07/28/2021 14:54:08 - INFO - volta.train_utils -   [NLVR2]: iter 45240 Ep: 16.76 loss 0.058 score 0.454 lr 9.03189e-07 
07/28/2021 14:54:30 - INFO - volta.train_utils -   [NLVR2]: iter 45280 Ep: 16.77 loss 0.054 score 0.455 lr 8.99074e-07 
07/28/2021 14:54:53 - INFO - volta.train_utils -   [NLVR2]: iter 45320 Ep: 16.79 loss 0.049 score 0.457 lr 8.94959e-07 
07/28/2021 14:55:17 - INFO - volta.train_utils -   [NLVR2]: iter 45360 Ep: 16.80 loss 0.048 score 0.466 lr 8.90844e-07 
07/28/2021 14:55:40 - INFO - volta.train_utils -   [NLVR2]: iter 45400 Ep: 16.81 loss 0.049 score 0.452 lr 8.86728e-07 
07/28/2021 14:56:03 - INFO - volta.train_utils -   [NLVR2]: iter 45440 Ep: 16.83 loss 0.052 score 0.457 lr 8.82613e-07 
07/28/2021 14:56:27 - INFO - volta.train_utils -   [NLVR2]: iter 45480 Ep: 16.84 loss 0.048 score 0.456 lr 8.78498e-07 
07/28/2021 14:56:51 - INFO - volta.train_utils -   [NLVR2]: iter 45520 Ep: 16.86 loss 0.044 score 0.462 lr 8.74383e-07 
07/28/2021 14:57:14 - INFO - volta.train_utils -   [NLVR2]: iter 45560 Ep: 16.87 loss 0.040 score 0.458 lr 8.70267e-07 
07/28/2021 14:57:38 - INFO - volta.train_utils -   [NLVR2]: iter 45600 Ep: 16.89 loss 0.054 score 0.457 lr 8.66152e-07 
07/28/2021 14:58:02 - INFO - volta.train_utils -   [NLVR2]: iter 45640 Ep: 16.90 loss 0.048 score 0.455 lr 8.62037e-07 
07/28/2021 14:58:25 - INFO - volta.train_utils -   [NLVR2]: iter 45680 Ep: 16.92 loss 0.051 score 0.459 lr 8.57922e-07 
07/28/2021 14:58:49 - INFO - volta.train_utils -   [NLVR2]: iter 45720 Ep: 16.93 loss 0.054 score 0.456 lr 8.53807e-07 
07/28/2021 14:59:12 - INFO - volta.train_utils -   [NLVR2]: iter 45760 Ep: 16.95 loss 0.057 score 0.453 lr 8.49691e-07 
07/28/2021 14:59:34 - INFO - volta.train_utils -   [NLVR2]: iter 45800 Ep: 16.96 loss 0.050 score 0.454 lr 8.45576e-07 
07/28/2021 14:59:58 - INFO - volta.train_utils -   [NLVR2]: iter 45840 Ep: 16.98 loss 0.050 score 0.457 lr 8.41461e-07 
07/28/2021 15:00:21 - INFO - volta.train_utils -   [NLVR2]: iter 45880 Ep: 16.99 loss 0.048 score 0.454 lr 8.37346e-07 
07/28/2021 15:00:31 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  85%|████████▌ | 17/20 [9:16:37<1:35:44, 1914.89s/it]07/28/2021 15:07:11 - INFO - volta.train_utils -   Eval task TASK12 on iteration 45900 
07/28/2021 15:07:11 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.903 score 71.484 
07/28/2021 15:07:32 - INFO - volta.train_utils -   [NLVR2]: iter 45940 Ep: 17.01 loss 0.044 score 0.462 lr 8.32202e-07 
07/28/2021 15:07:52 - INFO - volta.train_utils -   [NLVR2]: iter 45980 Ep: 17.03 loss 0.045 score 0.464 lr 8.27058e-07 
07/28/2021 15:08:12 - INFO - volta.train_utils -   [NLVR2]: iter 46020 Ep: 17.04 loss 0.046 score 0.458 lr 8.22942e-07 
07/28/2021 15:08:32 - INFO - volta.train_utils -   [NLVR2]: iter 46060 Ep: 17.06 loss 0.045 score 0.466 lr 8.18827e-07 
07/28/2021 15:08:52 - INFO - volta.train_utils -   [NLVR2]: iter 46100 Ep: 17.07 loss 0.048 score 0.461 lr 8.14712e-07 
07/28/2021 15:09:12 - INFO - volta.train_utils -   [NLVR2]: iter 46140 Ep: 17.09 loss 0.048 score 0.460 lr 8.10597e-07 
07/28/2021 15:09:33 - INFO - volta.train_utils -   [NLVR2]: iter 46180 Ep: 17.10 loss 0.051 score 0.456 lr 8.06481e-07 
07/28/2021 15:09:55 - INFO - volta.train_utils -   [NLVR2]: iter 46220 Ep: 17.12 loss 0.047 score 0.468 lr 8.02366e-07 
07/28/2021 15:10:16 - INFO - volta.train_utils -   [NLVR2]: iter 46260 Ep: 17.13 loss 0.049 score 0.463 lr 7.98251e-07 
07/28/2021 15:10:38 - INFO - volta.train_utils -   [NLVR2]: iter 46300 Ep: 17.15 loss 0.052 score 0.457 lr 7.94136e-07 
07/28/2021 15:10:59 - INFO - volta.train_utils -   [NLVR2]: iter 46340 Ep: 17.16 loss 0.047 score 0.464 lr 7.90021e-07 
07/28/2021 15:11:19 - INFO - volta.train_utils -   [NLVR2]: iter 46380 Ep: 17.18 loss 0.042 score 0.463 lr 7.85905e-07 
07/28/2021 15:11:40 - INFO - volta.train_utils -   [NLVR2]: iter 46420 Ep: 17.19 loss 0.042 score 0.465 lr 7.8179e-07 
07/28/2021 15:12:03 - INFO - volta.train_utils -   [NLVR2]: iter 46460 Ep: 17.21 loss 0.046 score 0.464 lr 7.77675e-07 
07/28/2021 15:12:24 - INFO - volta.train_utils -   [NLVR2]: iter 46500 Ep: 17.22 loss 0.041 score 0.462 lr 7.7356e-07 
07/28/2021 15:12:45 - INFO - volta.train_utils -   [NLVR2]: iter 46540 Ep: 17.24 loss 0.049 score 0.462 lr 7.69444e-07 
07/28/2021 15:13:06 - INFO - volta.train_utils -   [NLVR2]: iter 46580 Ep: 17.25 loss 0.056 score 0.454 lr 7.65329e-07 
07/28/2021 15:13:27 - INFO - volta.train_utils -   [NLVR2]: iter 46620 Ep: 17.27 loss 0.050 score 0.460 lr 7.61214e-07 
07/28/2021 15:13:49 - INFO - volta.train_utils -   [NLVR2]: iter 46660 Ep: 17.28 loss 0.052 score 0.459 lr 7.57099e-07 
07/28/2021 15:14:10 - INFO - volta.train_utils -   [NLVR2]: iter 46700 Ep: 17.30 loss 0.048 score 0.458 lr 7.52984e-07 
07/28/2021 15:14:33 - INFO - volta.train_utils -   [NLVR2]: iter 46740 Ep: 17.31 loss 0.049 score 0.457 lr 7.48868e-07 
07/28/2021 15:14:54 - INFO - volta.train_utils -   [NLVR2]: iter 46780 Ep: 17.33 loss 0.048 score 0.459 lr 7.44753e-07 
07/28/2021 15:15:16 - INFO - volta.train_utils -   [NLVR2]: iter 46820 Ep: 17.34 loss 0.040 score 0.467 lr 7.40638e-07 
07/28/2021 15:15:38 - INFO - volta.train_utils -   [NLVR2]: iter 46860 Ep: 17.36 loss 0.045 score 0.463 lr 7.36523e-07 
07/28/2021 15:16:00 - INFO - volta.train_utils -   [NLVR2]: iter 46900 Ep: 17.37 loss 0.049 score 0.457 lr 7.32407e-07 
07/28/2021 15:16:22 - INFO - volta.train_utils -   [NLVR2]: iter 46940 Ep: 17.39 loss 0.047 score 0.461 lr 7.28292e-07 
07/28/2021 15:16:45 - INFO - volta.train_utils -   [NLVR2]: iter 46980 Ep: 17.40 loss 0.043 score 0.468 lr 7.24177e-07 
07/28/2021 15:17:07 - INFO - volta.train_utils -   [NLVR2]: iter 47020 Ep: 17.41 loss 0.041 score 0.458 lr 7.20062e-07 
07/28/2021 15:17:30 - INFO - volta.train_utils -   [NLVR2]: iter 47060 Ep: 17.43 loss 0.048 score 0.459 lr 7.15947e-07 
07/28/2021 15:17:52 - INFO - volta.train_utils -   [NLVR2]: iter 47100 Ep: 17.44 loss 0.046 score 0.449 lr 7.11831e-07 
07/28/2021 15:18:15 - INFO - volta.train_utils -   [NLVR2]: iter 47140 Ep: 17.46 loss 0.051 score 0.456 lr 7.07716e-07 
07/28/2021 15:18:39 - INFO - volta.train_utils -   [NLVR2]: iter 47180 Ep: 17.47 loss 0.048 score 0.461 lr 7.03601e-07 
07/28/2021 15:19:02 - INFO - volta.train_utils -   [NLVR2]: iter 47220 Ep: 17.49 loss 0.049 score 0.456 lr 6.99486e-07 
07/28/2021 15:19:25 - INFO - volta.train_utils -   [NLVR2]: iter 47260 Ep: 17.50 loss 0.054 score 0.455 lr 6.9537e-07 
07/28/2021 15:19:49 - INFO - volta.train_utils -   [NLVR2]: iter 47300 Ep: 17.52 loss 0.046 score 0.462 lr 6.91255e-07 
07/28/2021 15:20:11 - INFO - volta.train_utils -   [NLVR2]: iter 47340 Ep: 17.53 loss 0.046 score 0.458 lr 6.8714e-07 
07/28/2021 15:20:35 - INFO - volta.train_utils -   [NLVR2]: iter 47380 Ep: 17.55 loss 0.050 score 0.454 lr 6.83025e-07 
07/28/2021 15:20:56 - INFO - volta.train_utils -   [NLVR2]: iter 47420 Ep: 17.56 loss 0.040 score 0.458 lr 6.78909e-07 
07/28/2021 15:21:20 - INFO - volta.train_utils -   [NLVR2]: iter 47460 Ep: 17.58 loss 0.046 score 0.457 lr 6.74794e-07 
07/28/2021 15:21:42 - INFO - volta.train_utils -   [NLVR2]: iter 47500 Ep: 17.59 loss 0.051 score 0.455 lr 6.70679e-07 
07/28/2021 15:22:06 - INFO - volta.train_utils -   [NLVR2]: iter 47540 Ep: 17.61 loss 0.053 score 0.454 lr 6.66564e-07 
07/28/2021 15:22:29 - INFO - volta.train_utils -   [NLVR2]: iter 47580 Ep: 17.62 loss 0.048 score 0.455 lr 6.62449e-07 
07/28/2021 15:22:52 - INFO - volta.train_utils -   [NLVR2]: iter 47620 Ep: 17.64 loss 0.056 score 0.452 lr 6.58333e-07 
07/28/2021 15:23:15 - INFO - volta.train_utils -   [NLVR2]: iter 47660 Ep: 17.65 loss 0.045 score 0.461 lr 6.54218e-07 
07/28/2021 15:23:39 - INFO - volta.train_utils -   [NLVR2]: iter 47700 Ep: 17.67 loss 0.039 score 0.463 lr 6.50103e-07 
07/28/2021 15:24:02 - INFO - volta.train_utils -   [NLVR2]: iter 47740 Ep: 17.68 loss 0.047 score 0.457 lr 6.45988e-07 
07/28/2021 15:24:24 - INFO - volta.train_utils -   [NLVR2]: iter 47780 Ep: 17.70 loss 0.050 score 0.457 lr 6.41872e-07 
07/28/2021 15:24:48 - INFO - volta.train_utils -   [NLVR2]: iter 47820 Ep: 17.71 loss 0.048 score 0.457 lr 6.37757e-07 
07/28/2021 15:25:11 - INFO - volta.train_utils -   [NLVR2]: iter 47860 Ep: 17.73 loss 0.045 score 0.463 lr 6.33642e-07 
07/28/2021 15:25:36 - INFO - volta.train_utils -   [NLVR2]: iter 47900 Ep: 17.74 loss 0.048 score 0.459 lr 6.29527e-07 
07/28/2021 15:25:59 - INFO - volta.train_utils -   [NLVR2]: iter 47940 Ep: 17.76 loss 0.046 score 0.461 lr 6.25412e-07 
07/28/2021 15:26:22 - INFO - volta.train_utils -   [NLVR2]: iter 47980 Ep: 17.77 loss 0.050 score 0.454 lr 6.21296e-07 
07/28/2021 15:26:45 - INFO - volta.train_utils -   [NLVR2]: iter 48020 Ep: 17.79 loss 0.052 score 0.457 lr 6.17181e-07 
07/28/2021 15:27:09 - INFO - volta.train_utils -   [NLVR2]: iter 48060 Ep: 17.80 loss 0.049 score 0.463 lr 6.13066e-07 
07/28/2021 15:27:33 - INFO - volta.train_utils -   [NLVR2]: iter 48100 Ep: 17.81 loss 0.052 score 0.452 lr 6.08951e-07 
07/28/2021 15:27:57 - INFO - volta.train_utils -   [NLVR2]: iter 48140 Ep: 17.83 loss 0.051 score 0.457 lr 6.04835e-07 
07/28/2021 15:28:19 - INFO - volta.train_utils -   [NLVR2]: iter 48180 Ep: 17.84 loss 0.047 score 0.463 lr 6.0072e-07 
07/28/2021 15:28:43 - INFO - volta.train_utils -   [NLVR2]: iter 48220 Ep: 17.86 loss 0.042 score 0.462 lr 5.96605e-07 
07/28/2021 15:29:06 - INFO - volta.train_utils -   [NLVR2]: iter 48260 Ep: 17.87 loss 0.051 score 0.459 lr 5.9249e-07 
07/28/2021 15:29:30 - INFO - volta.train_utils -   [NLVR2]: iter 48300 Ep: 17.89 loss 0.046 score 0.461 lr 5.88374e-07 
07/28/2021 15:29:54 - INFO - volta.train_utils -   [NLVR2]: iter 48340 Ep: 17.90 loss 0.053 score 0.457 lr 5.84259e-07 
07/28/2021 15:30:17 - INFO - volta.train_utils -   [NLVR2]: iter 48380 Ep: 17.92 loss 0.046 score 0.462 lr 5.80144e-07 
07/28/2021 15:30:40 - INFO - volta.train_utils -   [NLVR2]: iter 48420 Ep: 17.93 loss 0.048 score 0.461 lr 5.76029e-07 
07/28/2021 15:31:04 - INFO - volta.train_utils -   [NLVR2]: iter 48460 Ep: 17.95 loss 0.045 score 0.453 lr 5.71914e-07 
07/28/2021 15:31:27 - INFO - volta.train_utils -   [NLVR2]: iter 48500 Ep: 17.96 loss 0.047 score 0.454 lr 5.67798e-07 
07/28/2021 15:31:52 - INFO - volta.train_utils -   [NLVR2]: iter 48540 Ep: 17.98 loss 0.045 score 0.465 lr 5.63683e-07 
07/28/2021 15:32:14 - INFO - volta.train_utils -   [NLVR2]: iter 48580 Ep: 17.99 loss 0.043 score 0.461 lr 5.59568e-07 
07/28/2021 15:32:24 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  90%|█████████ | 18/20 [9:48:30<1:03:48, 1914.18s/it]07/28/2021 15:39:04 - INFO - volta.train_utils -   Eval task TASK12 on iteration 48600 
07/28/2021 15:39:04 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.932 score 71.512 
07/28/2021 15:39:24 - INFO - volta.train_utils -   [NLVR2]: iter 48640 Ep: 18.01 loss 0.046 score 0.466 lr 5.54424e-07 
07/28/2021 15:39:44 - INFO - volta.train_utils -   [NLVR2]: iter 48680 Ep: 18.03 loss 0.044 score 0.457 lr 5.4928e-07 
07/28/2021 15:40:04 - INFO - volta.train_utils -   [NLVR2]: iter 48720 Ep: 18.04 loss 0.047 score 0.463 lr 5.45165e-07 
07/28/2021 15:40:24 - INFO - volta.train_utils -   [NLVR2]: iter 48760 Ep: 18.06 loss 0.040 score 0.459 lr 5.41049e-07 
07/28/2021 15:40:45 - INFO - volta.train_utils -   [NLVR2]: iter 48800 Ep: 18.07 loss 0.052 score 0.452 lr 5.36934e-07 
07/28/2021 15:41:05 - INFO - volta.train_utils -   [NLVR2]: iter 48840 Ep: 18.09 loss 0.041 score 0.459 lr 5.32819e-07 
07/28/2021 15:41:25 - INFO - volta.train_utils -   [NLVR2]: iter 48880 Ep: 18.10 loss 0.052 score 0.458 lr 5.28704e-07 
07/28/2021 15:41:50 - INFO - volta.train_utils -   [NLVR2]: iter 48920 Ep: 18.12 loss 0.044 score 0.469 lr 5.24588e-07 
07/28/2021 15:42:10 - INFO - volta.train_utils -   [NLVR2]: iter 48960 Ep: 18.13 loss 0.044 score 0.454 lr 5.20473e-07 
07/28/2021 15:42:30 - INFO - volta.train_utils -   [NLVR2]: iter 49000 Ep: 18.15 loss 0.042 score 0.465 lr 5.16358e-07 
07/28/2021 15:42:51 - INFO - volta.train_utils -   [NLVR2]: iter 49040 Ep: 18.16 loss 0.039 score 0.467 lr 5.12243e-07 
07/28/2021 15:43:13 - INFO - volta.train_utils -   [NLVR2]: iter 49080 Ep: 18.18 loss 0.048 score 0.465 lr 5.08128e-07 
07/28/2021 15:43:34 - INFO - volta.train_utils -   [NLVR2]: iter 49120 Ep: 18.19 loss 0.049 score 0.458 lr 5.04012e-07 
07/28/2021 15:43:56 - INFO - volta.train_utils -   [NLVR2]: iter 49160 Ep: 18.21 loss 0.046 score 0.459 lr 4.99897e-07 
07/28/2021 15:44:19 - INFO - volta.train_utils -   [NLVR2]: iter 49200 Ep: 18.22 loss 0.042 score 0.470 lr 4.95782e-07 
07/28/2021 15:44:40 - INFO - volta.train_utils -   [NLVR2]: iter 49240 Ep: 18.24 loss 0.052 score 0.459 lr 4.91667e-07 
07/28/2021 15:45:02 - INFO - volta.train_utils -   [NLVR2]: iter 49280 Ep: 18.25 loss 0.047 score 0.463 lr 4.87551e-07 
07/28/2021 15:45:22 - INFO - volta.train_utils -   [NLVR2]: iter 49320 Ep: 18.27 loss 0.052 score 0.461 lr 4.83436e-07 
07/28/2021 15:45:43 - INFO - volta.train_utils -   [NLVR2]: iter 49360 Ep: 18.28 loss 0.049 score 0.462 lr 4.79321e-07 
07/28/2021 15:46:05 - INFO - volta.train_utils -   [NLVR2]: iter 49400 Ep: 18.30 loss 0.046 score 0.462 lr 4.75206e-07 
07/28/2021 15:46:28 - INFO - volta.train_utils -   [NLVR2]: iter 49440 Ep: 18.31 loss 0.051 score 0.459 lr 4.71091e-07 
07/28/2021 15:46:49 - INFO - volta.train_utils -   [NLVR2]: iter 49480 Ep: 18.33 loss 0.040 score 0.461 lr 4.66975e-07 
07/28/2021 15:47:11 - INFO - volta.train_utils -   [NLVR2]: iter 49520 Ep: 18.34 loss 0.050 score 0.455 lr 4.6286e-07 
07/28/2021 15:47:32 - INFO - volta.train_utils -   [NLVR2]: iter 49560 Ep: 18.36 loss 0.048 score 0.456 lr 4.58745e-07 
07/28/2021 15:47:53 - INFO - volta.train_utils -   [NLVR2]: iter 49600 Ep: 18.37 loss 0.044 score 0.460 lr 4.5463e-07 
07/28/2021 15:48:16 - INFO - volta.train_utils -   [NLVR2]: iter 49640 Ep: 18.39 loss 0.042 score 0.461 lr 4.50514e-07 
07/28/2021 15:48:38 - INFO - volta.train_utils -   [NLVR2]: iter 49680 Ep: 18.40 loss 0.039 score 0.466 lr 4.46399e-07 
07/28/2021 15:49:00 - INFO - volta.train_utils -   [NLVR2]: iter 49720 Ep: 18.41 loss 0.046 score 0.468 lr 4.42284e-07 
07/28/2021 15:49:23 - INFO - volta.train_utils -   [NLVR2]: iter 49760 Ep: 18.43 loss 0.045 score 0.467 lr 4.38169e-07 
07/28/2021 15:49:46 - INFO - volta.train_utils -   [NLVR2]: iter 49800 Ep: 18.44 loss 0.049 score 0.458 lr 4.34053e-07 
07/28/2021 15:50:08 - INFO - volta.train_utils -   [NLVR2]: iter 49840 Ep: 18.46 loss 0.048 score 0.459 lr 4.29938e-07 
07/28/2021 15:50:29 - INFO - volta.train_utils -   [NLVR2]: iter 49880 Ep: 18.47 loss 0.045 score 0.465 lr 4.25823e-07 
07/28/2021 15:50:53 - INFO - volta.train_utils -   [NLVR2]: iter 49920 Ep: 18.49 loss 0.044 score 0.462 lr 4.21708e-07 
07/28/2021 15:51:15 - INFO - volta.train_utils -   [NLVR2]: iter 49960 Ep: 18.50 loss 0.046 score 0.459 lr 4.17593e-07 
07/28/2021 15:51:36 - INFO - volta.train_utils -   [NLVR2]: iter 50000 Ep: 18.52 loss 0.044 score 0.463 lr 4.13477e-07 
07/28/2021 15:51:59 - INFO - volta.train_utils -   [NLVR2]: iter 50040 Ep: 18.53 loss 0.037 score 0.465 lr 4.09362e-07 
07/28/2021 15:52:23 - INFO - volta.train_utils -   [NLVR2]: iter 50080 Ep: 18.55 loss 0.039 score 0.466 lr 4.05247e-07 
07/28/2021 15:52:43 - INFO - volta.train_utils -   [NLVR2]: iter 50120 Ep: 18.56 loss 0.044 score 0.463 lr 4.01132e-07 
07/28/2021 15:53:07 - INFO - volta.train_utils -   [NLVR2]: iter 50160 Ep: 18.58 loss 0.042 score 0.465 lr 3.97016e-07 
07/28/2021 15:53:31 - INFO - volta.train_utils -   [NLVR2]: iter 50200 Ep: 18.59 loss 0.049 score 0.464 lr 3.92901e-07 
07/28/2021 15:53:54 - INFO - volta.train_utils -   [NLVR2]: iter 50240 Ep: 18.61 loss 0.038 score 0.460 lr 3.88786e-07 
07/28/2021 15:54:16 - INFO - volta.train_utils -   [NLVR2]: iter 50280 Ep: 18.62 loss 0.046 score 0.461 lr 3.84671e-07 
07/28/2021 15:54:40 - INFO - volta.train_utils -   [NLVR2]: iter 50320 Ep: 18.64 loss 0.051 score 0.459 lr 3.80556e-07 
07/28/2021 15:55:04 - INFO - volta.train_utils -   [NLVR2]: iter 50360 Ep: 18.65 loss 0.052 score 0.455 lr 3.7644e-07 
07/28/2021 15:55:28 - INFO - volta.train_utils -   [NLVR2]: iter 50400 Ep: 18.67 loss 0.045 score 0.468 lr 3.72325e-07 
07/28/2021 15:55:51 - INFO - volta.train_utils -   [NLVR2]: iter 50440 Ep: 18.68 loss 0.037 score 0.466 lr 3.6821e-07 
07/28/2021 15:56:14 - INFO - volta.train_utils -   [NLVR2]: iter 50480 Ep: 18.70 loss 0.040 score 0.458 lr 3.64095e-07 
07/28/2021 15:56:36 - INFO - volta.train_utils -   [NLVR2]: iter 50520 Ep: 18.71 loss 0.043 score 0.464 lr 3.59979e-07 
07/28/2021 15:56:59 - INFO - volta.train_utils -   [NLVR2]: iter 50560 Ep: 18.73 loss 0.045 score 0.461 lr 3.55864e-07 
07/28/2021 15:57:22 - INFO - volta.train_utils -   [NLVR2]: iter 50600 Ep: 18.74 loss 0.038 score 0.461 lr 3.51749e-07 
07/28/2021 15:57:45 - INFO - volta.train_utils -   [NLVR2]: iter 50640 Ep: 18.76 loss 0.046 score 0.457 lr 3.47634e-07 
07/28/2021 15:58:08 - INFO - volta.train_utils -   [NLVR2]: iter 50680 Ep: 18.77 loss 0.044 score 0.466 lr 3.43519e-07 
07/28/2021 15:58:33 - INFO - volta.train_utils -   [NLVR2]: iter 50720 Ep: 18.79 loss 0.049 score 0.460 lr 3.39403e-07 
07/28/2021 15:58:55 - INFO - volta.train_utils -   [NLVR2]: iter 50760 Ep: 18.80 loss 0.049 score 0.457 lr 3.35288e-07 
07/28/2021 15:59:19 - INFO - volta.train_utils -   [NLVR2]: iter 50800 Ep: 18.81 loss 0.046 score 0.460 lr 3.31173e-07 
07/28/2021 15:59:41 - INFO - volta.train_utils -   [NLVR2]: iter 50840 Ep: 18.83 loss 0.042 score 0.458 lr 3.27058e-07 
07/28/2021 16:00:05 - INFO - volta.train_utils -   [NLVR2]: iter 50880 Ep: 18.84 loss 0.048 score 0.454 lr 3.22942e-07 
07/28/2021 16:00:28 - INFO - volta.train_utils -   [NLVR2]: iter 50920 Ep: 18.86 loss 0.048 score 0.461 lr 3.18827e-07 
07/28/2021 16:00:51 - INFO - volta.train_utils -   [NLVR2]: iter 50960 Ep: 18.87 loss 0.051 score 0.460 lr 3.14712e-07 
07/28/2021 16:01:14 - INFO - volta.train_utils -   [NLVR2]: iter 51000 Ep: 18.89 loss 0.044 score 0.462 lr 3.10597e-07 
07/28/2021 16:01:38 - INFO - volta.train_utils -   [NLVR2]: iter 51040 Ep: 18.90 loss 0.043 score 0.462 lr 3.06481e-07 
07/28/2021 16:02:00 - INFO - volta.train_utils -   [NLVR2]: iter 51080 Ep: 18.92 loss 0.042 score 0.464 lr 3.02366e-07 
07/28/2021 16:02:23 - INFO - volta.train_utils -   [NLVR2]: iter 51120 Ep: 18.93 loss 0.044 score 0.463 lr 2.98251e-07 
07/28/2021 16:02:46 - INFO - volta.train_utils -   [NLVR2]: iter 51160 Ep: 18.95 loss 0.041 score 0.459 lr 2.94136e-07 
07/28/2021 16:03:10 - INFO - volta.train_utils -   [NLVR2]: iter 51200 Ep: 18.96 loss 0.045 score 0.458 lr 2.90021e-07 
07/28/2021 16:03:33 - INFO - volta.train_utils -   [NLVR2]: iter 51240 Ep: 18.98 loss 0.049 score 0.460 lr 2.85905e-07 
07/28/2021 16:03:56 - INFO - volta.train_utils -   [NLVR2]: iter 51280 Ep: 18.99 loss 0.047 score 0.459 lr 2.8179e-07 
07/28/2021 16:04:07 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch:  95%|█████████▌| 19/20 [10:20:13<31:50, 1910.77s/it] 07/28/2021 16:10:52 - INFO - volta.train_utils -   Eval task TASK12 on iteration 51300 
07/28/2021 16:10:52 - INFO - volta.train_utils -   Validation [NLVR2]: loss 0.938 score 71.527 
07/28/2021 16:11:12 - INFO - volta.train_utils -   [NLVR2]: iter 51340 Ep: 19.01 loss 0.042 score 0.463 lr 2.76646e-07 
07/28/2021 16:11:32 - INFO - volta.train_utils -   [NLVR2]: iter 51380 Ep: 19.03 loss 0.045 score 0.459 lr 2.71502e-07 
07/28/2021 16:11:52 - INFO - volta.train_utils -   [NLVR2]: iter 51420 Ep: 19.04 loss 0.045 score 0.457 lr 2.67387e-07 
07/28/2021 16:12:12 - INFO - volta.train_utils -   [NLVR2]: iter 51460 Ep: 19.06 loss 0.043 score 0.467 lr 2.63272e-07 
07/28/2021 16:12:32 - INFO - volta.train_utils -   [NLVR2]: iter 51500 Ep: 19.07 loss 0.047 score 0.463 lr 2.59156e-07 
07/28/2021 16:12:53 - INFO - volta.train_utils -   [NLVR2]: iter 51540 Ep: 19.09 loss 0.045 score 0.457 lr 2.55041e-07 
07/28/2021 16:13:13 - INFO - volta.train_utils -   [NLVR2]: iter 51580 Ep: 19.10 loss 0.047 score 0.460 lr 2.50926e-07 
07/28/2021 16:13:37 - INFO - volta.train_utils -   [NLVR2]: iter 51620 Ep: 19.12 loss 0.042 score 0.461 lr 2.46811e-07 
07/28/2021 16:13:58 - INFO - volta.train_utils -   [NLVR2]: iter 51660 Ep: 19.13 loss 0.047 score 0.466 lr 2.42695e-07 
07/28/2021 16:14:18 - INFO - volta.train_utils -   [NLVR2]: iter 51700 Ep: 19.15 loss 0.048 score 0.461 lr 2.3858e-07 
07/28/2021 16:14:38 - INFO - volta.train_utils -   [NLVR2]: iter 51740 Ep: 19.16 loss 0.039 score 0.464 lr 2.34465e-07 
07/28/2021 16:14:58 - INFO - volta.train_utils -   [NLVR2]: iter 51780 Ep: 19.18 loss 0.045 score 0.464 lr 2.3035e-07 
07/28/2021 16:15:19 - INFO - volta.train_utils -   [NLVR2]: iter 51820 Ep: 19.19 loss 0.042 score 0.463 lr 2.26235e-07 
07/28/2021 16:15:42 - INFO - volta.train_utils -   [NLVR2]: iter 51860 Ep: 19.21 loss 0.041 score 0.462 lr 2.22119e-07 
07/28/2021 16:16:03 - INFO - volta.train_utils -   [NLVR2]: iter 51900 Ep: 19.22 loss 0.044 score 0.461 lr 2.18004e-07 
07/28/2021 16:16:23 - INFO - volta.train_utils -   [NLVR2]: iter 51940 Ep: 19.24 loss 0.046 score 0.460 lr 2.13889e-07 
07/28/2021 16:16:44 - INFO - volta.train_utils -   [NLVR2]: iter 51980 Ep: 19.25 loss 0.042 score 0.464 lr 2.09774e-07 
07/28/2021 16:17:04 - INFO - volta.train_utils -   [NLVR2]: iter 52020 Ep: 19.27 loss 0.045 score 0.459 lr 2.05658e-07 
07/28/2021 16:17:25 - INFO - volta.train_utils -   [NLVR2]: iter 52060 Ep: 19.28 loss 0.040 score 0.468 lr 2.01543e-07 
07/28/2021 16:17:47 - INFO - volta.train_utils -   [NLVR2]: iter 52100 Ep: 19.30 loss 0.045 score 0.464 lr 1.97428e-07 
07/28/2021 16:18:09 - INFO - volta.train_utils -   [NLVR2]: iter 52140 Ep: 19.31 loss 0.039 score 0.470 lr 1.93313e-07 
07/28/2021 16:18:32 - INFO - volta.train_utils -   [NLVR2]: iter 52180 Ep: 19.33 loss 0.046 score 0.464 lr 1.89198e-07 
07/28/2021 16:18:55 - INFO - volta.train_utils -   [NLVR2]: iter 52220 Ep: 19.34 loss 0.042 score 0.463 lr 1.85082e-07 
07/28/2021 16:19:15 - INFO - volta.train_utils -   [NLVR2]: iter 52260 Ep: 19.36 loss 0.050 score 0.464 lr 1.80967e-07 
07/28/2021 16:19:37 - INFO - volta.train_utils -   [NLVR2]: iter 52300 Ep: 19.37 loss 0.040 score 0.463 lr 1.76852e-07 
07/28/2021 16:20:00 - INFO - volta.train_utils -   [NLVR2]: iter 52340 Ep: 19.39 loss 0.037 score 0.463 lr 1.72737e-07 
07/28/2021 16:20:21 - INFO - volta.train_utils -   [NLVR2]: iter 52380 Ep: 19.40 loss 0.048 score 0.460 lr 1.68621e-07 
07/28/2021 16:20:44 - INFO - volta.train_utils -   [NLVR2]: iter 52420 Ep: 19.41 loss 0.040 score 0.467 lr 1.64506e-07 
07/28/2021 16:21:06 - INFO - volta.train_utils -   [NLVR2]: iter 52460 Ep: 19.43 loss 0.042 score 0.463 lr 1.60391e-07 
07/28/2021 16:21:30 - INFO - volta.train_utils -   [NLVR2]: iter 52500 Ep: 19.44 loss 0.048 score 0.462 lr 1.56276e-07 
07/28/2021 16:21:51 - INFO - volta.train_utils -   [NLVR2]: iter 52540 Ep: 19.46 loss 0.043 score 0.459 lr 1.5216e-07 
07/28/2021 16:22:15 - INFO - volta.train_utils -   [NLVR2]: iter 52580 Ep: 19.47 loss 0.045 score 0.470 lr 1.48045e-07 
07/28/2021 16:22:36 - INFO - volta.train_utils -   [NLVR2]: iter 52620 Ep: 19.49 loss 0.047 score 0.457 lr 1.4393e-07 
07/28/2021 16:22:59 - INFO - volta.train_utils -   [NLVR2]: iter 52660 Ep: 19.50 loss 0.048 score 0.461 lr 1.39815e-07 
07/28/2021 16:23:21 - INFO - volta.train_utils -   [NLVR2]: iter 52700 Ep: 19.52 loss 0.037 score 0.464 lr 1.357e-07 
07/28/2021 16:23:46 - INFO - volta.train_utils -   [NLVR2]: iter 52740 Ep: 19.53 loss 0.041 score 0.465 lr 1.31584e-07 
07/28/2021 16:24:08 - INFO - volta.train_utils -   [NLVR2]: iter 52780 Ep: 19.55 loss 0.046 score 0.460 lr 1.27469e-07 
07/28/2021 16:24:31 - INFO - volta.train_utils -   [NLVR2]: iter 52820 Ep: 19.56 loss 0.046 score 0.460 lr 1.23354e-07 
07/28/2021 16:24:54 - INFO - volta.train_utils -   [NLVR2]: iter 52860 Ep: 19.58 loss 0.048 score 0.463 lr 1.19239e-07 
07/28/2021 16:25:18 - INFO - volta.train_utils -   [NLVR2]: iter 52900 Ep: 19.59 loss 0.050 score 0.456 lr 1.15123e-07 
07/28/2021 16:25:41 - INFO - volta.train_utils -   [NLVR2]: iter 52940 Ep: 19.61 loss 0.041 score 0.461 lr 1.11008e-07 
07/28/2021 16:26:05 - INFO - volta.train_utils -   [NLVR2]: iter 52980 Ep: 19.62 loss 0.043 score 0.464 lr 1.06893e-07 
07/28/2021 16:26:27 - INFO - volta.train_utils -   [NLVR2]: iter 53020 Ep: 19.64 loss 0.040 score 0.462 lr 1.02778e-07 
07/28/2021 16:26:51 - INFO - volta.train_utils -   [NLVR2]: iter 53060 Ep: 19.65 loss 0.044 score 0.463 lr 9.86626e-08 
07/28/2021 16:27:14 - INFO - volta.train_utils -   [NLVR2]: iter 53100 Ep: 19.67 loss 0.037 score 0.468 lr 9.45473e-08 
07/28/2021 16:27:37 - INFO - volta.train_utils -   [NLVR2]: iter 53140 Ep: 19.68 loss 0.038 score 0.464 lr 9.04321e-08 
07/28/2021 16:27:59 - INFO - volta.train_utils -   [NLVR2]: iter 53180 Ep: 19.70 loss 0.042 score 0.468 lr 8.63169e-08 
07/28/2021 16:28:22 - INFO - volta.train_utils -   [NLVR2]: iter 53220 Ep: 19.71 loss 0.046 score 0.461 lr 8.22016e-08 
07/28/2021 16:28:45 - INFO - volta.train_utils -   [NLVR2]: iter 53260 Ep: 19.73 loss 0.046 score 0.459 lr 7.80864e-08 
07/28/2021 16:29:10 - INFO - volta.train_utils -   [NLVR2]: iter 53300 Ep: 19.74 loss 0.042 score 0.466 lr 7.39712e-08 
07/28/2021 16:29:32 - INFO - volta.train_utils -   [NLVR2]: iter 53340 Ep: 19.76 loss 0.044 score 0.467 lr 6.9856e-08 
07/28/2021 16:29:56 - INFO - volta.train_utils -   [NLVR2]: iter 53380 Ep: 19.77 loss 0.044 score 0.463 lr 6.57407e-08 
07/28/2021 16:30:18 - INFO - volta.train_utils -   [NLVR2]: iter 53420 Ep: 19.79 loss 0.044 score 0.462 lr 6.16255e-08 
07/28/2021 16:30:43 - INFO - volta.train_utils -   [NLVR2]: iter 53460 Ep: 19.80 loss 0.046 score 0.456 lr 5.75103e-08 
07/28/2021 16:31:05 - INFO - volta.train_utils -   [NLVR2]: iter 53500 Ep: 19.81 loss 0.040 score 0.469 lr 5.33951e-08 
07/28/2021 16:31:28 - INFO - volta.train_utils -   [NLVR2]: iter 53540 Ep: 19.83 loss 0.047 score 0.463 lr 4.92798e-08 
07/28/2021 16:31:50 - INFO - volta.train_utils -   [NLVR2]: iter 53580 Ep: 19.84 loss 0.045 score 0.468 lr 4.51646e-08 
07/28/2021 16:32:14 - INFO - volta.train_utils -   [NLVR2]: iter 53620 Ep: 19.86 loss 0.043 score 0.463 lr 4.10494e-08 
07/28/2021 16:32:37 - INFO - volta.train_utils -   [NLVR2]: iter 53660 Ep: 19.87 loss 0.049 score 0.464 lr 3.69342e-08 
07/28/2021 16:33:01 - INFO - volta.train_utils -   [NLVR2]: iter 53700 Ep: 19.89 loss 0.033 score 0.464 lr 3.28189e-08 
07/28/2021 16:33:24 - INFO - volta.train_utils -   [NLVR2]: iter 53740 Ep: 19.90 loss 0.049 score 0.466 lr 2.87037e-08 
07/28/2021 16:33:47 - INFO - volta.train_utils -   [NLVR2]: iter 53780 Ep: 19.92 loss 0.042 score 0.461 lr 2.45885e-08 
07/28/2021 16:34:10 - INFO - volta.train_utils -   [NLVR2]: iter 53820 Ep: 19.93 loss 0.044 score 0.461 lr 2.04733e-08 
07/28/2021 16:34:34 - INFO - volta.train_utils -   [NLVR2]: iter 53860 Ep: 19.95 loss 0.041 score 0.462 lr 1.6358e-08 
07/28/2021 16:34:57 - INFO - volta.train_utils -   [NLVR2]: iter 53900 Ep: 19.96 loss 0.048 score 0.455 lr 1.22428e-08 
07/28/2021 16:35:22 - INFO - volta.train_utils -   [NLVR2]: iter 53940 Ep: 19.98 loss 0.044 score 0.465 lr 8.12757e-09 
07/28/2021 16:35:44 - INFO - volta.train_utils -   [NLVR2]: iter 53980 Ep: 19.99 loss 0.049 score 0.460 lr 4.01235e-09 
07/28/2021 16:35:54 - INFO - __main__ -   ** ** * Saving model * ** ** 

Epoch: 100%|██████████| 20/20 [10:52:00<00:00, 1909.74s/it]
